{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "Qbi9QzDayqaz",
        "outputId": "7b4a680c-8341-4886-e71e-723c86697b15"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4b2d78f8-f005-4a8f-8250-753ebac24c0f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4b2d78f8-f005-4a8f-8250-753ebac24c0f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"ansh1601\",\"key\":\"89a23d3b9d9732d82169bc93bd28134c\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "I01jSik1zYAi"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qq4uapmi0LsD",
        "outputId": "6e0f3b2e-6ce2-40fa-a76b-d1ee109f4916"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading deep-learning-for-msc-2022-23.zip to /content\n",
            " 93% 208M/224M [00:00<00:00, 243MB/s]\n",
            "100% 224M/224M [00:01<00:00, 229MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c deep-learning-for-msc-2022-23"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEa5T2sV0ioj",
        "outputId": "1135d52f-c1d1-4570-f14f-35729a445da2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "  inflating: train/3302.png          \n",
            "  inflating: train/3303.png          \n",
            "  inflating: train/3304.png          \n",
            "  inflating: train/3305.png          \n",
            "  inflating: train/3306.png          \n",
            "  inflating: train/3307.png          \n",
            "  inflating: train/3308.png          \n",
            "  inflating: train/3309.png          \n",
            "  inflating: train/331.png           \n",
            "  inflating: train/3310.png          \n",
            "  inflating: train/3311.png          \n",
            "  inflating: train/3312.png          \n",
            "  inflating: train/3313.png          \n",
            "  inflating: train/3314.png          \n",
            "  inflating: train/3315.png          \n",
            "  inflating: train/3316.png          \n",
            "  inflating: train/3317.png          \n",
            "  inflating: train/3318.png          \n",
            "  inflating: train/3319.png          \n",
            "  inflating: train/332.png           \n",
            "  inflating: train/3320.png          \n",
            "  inflating: train/3321.png          \n",
            "  inflating: train/3322.png          \n",
            "  inflating: train/3323.png          \n",
            "  inflating: train/3324.png          \n",
            "  inflating: train/3325.png          \n",
            "  inflating: train/3326.png          \n",
            "  inflating: train/3327.png          \n",
            "  inflating: train/3328.png          \n",
            "  inflating: train/3329.png          \n",
            "  inflating: train/333.png           \n",
            "  inflating: train/3330.png          \n",
            "  inflating: train/3331.png          \n",
            "  inflating: train/3332.png          \n",
            "  inflating: train/3333.png          \n",
            "  inflating: train/3334.png          \n",
            "  inflating: train/3335.png          \n",
            "  inflating: train/3336.png          \n",
            "  inflating: train/3337.png          \n",
            "  inflating: train/3338.png          \n",
            "  inflating: train/3339.png          \n",
            "  inflating: train/334.png           \n",
            "  inflating: train/3340.png          \n",
            "  inflating: train/3341.png          \n",
            "  inflating: train/3342.png          \n",
            "  inflating: train/3343.png          \n",
            "  inflating: train/3344.png          \n",
            "  inflating: train/3345.png          \n",
            "  inflating: train/3346.png          \n",
            "  inflating: train/3347.png          \n",
            "  inflating: train/3348.png          \n",
            "  inflating: train/3349.png          \n",
            "  inflating: train/335.png           \n",
            "  inflating: train/3350.png          \n",
            "  inflating: train/3351.png          \n",
            "  inflating: train/3352.png          \n",
            "  inflating: train/3353.png          \n",
            "  inflating: train/3354.png          \n",
            "  inflating: train/3355.png          \n",
            "  inflating: train/3356.png          \n",
            "  inflating: train/3357.png          \n",
            "  inflating: train/3358.png          \n",
            "  inflating: train/3359.png          \n",
            "  inflating: train/336.png           \n",
            "  inflating: train/3360.png          \n",
            "  inflating: train/3361.png          \n",
            "  inflating: train/3362.png          \n",
            "  inflating: train/3363.png          \n",
            "  inflating: train/3364.png          \n",
            "  inflating: train/3365.png          \n",
            "  inflating: train/3366.png          \n",
            "  inflating: train/3367.png          \n",
            "  inflating: train/3368.png          \n",
            "  inflating: train/3369.png          \n",
            "  inflating: train/337.png           \n",
            "  inflating: train/3370.png          \n",
            "  inflating: train/3371.png          \n",
            "  inflating: train/3372.png          \n",
            "  inflating: train/3373.png          \n",
            "  inflating: train/3374.png          \n",
            "  inflating: train/3375.png          \n",
            "  inflating: train/3376.png          \n",
            "  inflating: train/3377.png          \n",
            "  inflating: train/3378.png          \n",
            "  inflating: train/3379.png          \n",
            "  inflating: train/338.png           \n",
            "  inflating: train/3380.png          \n",
            "  inflating: train/3381.png          \n",
            "  inflating: train/3382.png          \n",
            "  inflating: train/3383.png          \n",
            "  inflating: train/3384.png          \n",
            "  inflating: train/3385.png          \n",
            "  inflating: train/3386.png          \n",
            "  inflating: train/3387.png          \n",
            "  inflating: train/3388.png          \n",
            "  inflating: train/3389.png          \n",
            "  inflating: train/339.png           \n",
            "  inflating: train/3390.png          \n",
            "  inflating: train/3391.png          \n",
            "  inflating: train/3392.png          \n",
            "  inflating: train/3393.png          \n",
            "  inflating: train/3394.png          \n",
            "  inflating: train/3395.png          \n",
            "  inflating: train/3396.png          \n",
            "  inflating: train/3397.png          \n",
            "  inflating: train/3398.png          \n",
            "  inflating: train/3399.png          \n",
            "  inflating: train/34.png            \n",
            "  inflating: train/340.png           \n",
            "  inflating: train/3400.png          \n",
            "  inflating: train/3401.png          \n",
            "  inflating: train/3402.png          \n",
            "  inflating: train/3403.png          \n",
            "  inflating: train/3404.png          \n",
            "  inflating: train/3405.png          \n",
            "  inflating: train/3406.png          \n",
            "  inflating: train/3407.png          \n",
            "  inflating: train/3408.png          \n",
            "  inflating: train/3409.png          \n",
            "  inflating: train/341.png           \n",
            "  inflating: train/3410.png          \n",
            "  inflating: train/3411.png          \n",
            "  inflating: train/3412.png          \n",
            "  inflating: train/3413.png          \n",
            "  inflating: train/3414.png          \n",
            "  inflating: train/3415.png          \n",
            "  inflating: train/3416.png          \n",
            "  inflating: train/3417.png          \n",
            "  inflating: train/3418.png          \n",
            "  inflating: train/3419.png          \n",
            "  inflating: train/342.png           \n",
            "  inflating: train/3420.png          \n",
            "  inflating: train/3421.png          \n",
            "  inflating: train/3422.png          \n",
            "  inflating: train/3423.png          \n",
            "  inflating: train/3424.png          \n",
            "  inflating: train/3425.png          \n",
            "  inflating: train/3426.png          \n",
            "  inflating: train/3427.png          \n",
            "  inflating: train/3428.png          \n",
            "  inflating: train/3429.png          \n",
            "  inflating: train/343.png           \n",
            "  inflating: train/3430.png          \n",
            "  inflating: train/3431.png          \n",
            "  inflating: train/3432.png          \n",
            "  inflating: train/3433.png          \n",
            "  inflating: train/3434.png          \n",
            "  inflating: train/3435.png          \n",
            "  inflating: train/3436.png          \n",
            "  inflating: train/3437.png          \n",
            "  inflating: train/3438.png          \n",
            "  inflating: train/3439.png          \n",
            "  inflating: train/344.png           \n",
            "  inflating: train/3440.png          \n",
            "  inflating: train/3441.png          \n",
            "  inflating: train/3442.png          \n",
            "  inflating: train/3443.png          \n",
            "  inflating: train/3444.png          \n",
            "  inflating: train/3445.png          \n",
            "  inflating: train/3446.png          \n",
            "  inflating: train/3447.png          \n",
            "  inflating: train/3448.png          \n",
            "  inflating: train/3449.png          \n",
            "  inflating: train/345.png           \n",
            "  inflating: train/3450.png          \n",
            "  inflating: train/3451.png          \n",
            "  inflating: train/3452.png          \n",
            "  inflating: train/3453.png          \n",
            "  inflating: train/3454.png          \n",
            "  inflating: train/3455.png          \n",
            "  inflating: train/3456.png          \n",
            "  inflating: train/3457.png          \n",
            "  inflating: train/3458.png          \n",
            "  inflating: train/3459.png          \n",
            "  inflating: train/346.png           \n",
            "  inflating: train/3460.png          \n",
            "  inflating: train/3461.png          \n",
            "  inflating: train/3462.png          \n",
            "  inflating: train/3463.png          \n",
            "  inflating: train/3464.png          \n",
            "  inflating: train/3465.png          \n",
            "  inflating: train/3466.png          \n",
            "  inflating: train/3467.png          \n",
            "  inflating: train/3468.png          \n",
            "  inflating: train/3469.png          \n",
            "  inflating: train/347.png           \n",
            "  inflating: train/3470.png          \n",
            "  inflating: train/3471.png          \n",
            "  inflating: train/3472.png          \n",
            "  inflating: train/3473.png          \n",
            "  inflating: train/3474.png          \n",
            "  inflating: train/3475.png          \n",
            "  inflating: train/3476.png          \n",
            "  inflating: train/3477.png          \n",
            "  inflating: train/3478.png          \n",
            "  inflating: train/3479.png          \n",
            "  inflating: train/348.png           \n",
            "  inflating: train/3480.png          \n",
            "  inflating: train/3481.png          \n",
            "  inflating: train/3482.png          \n",
            "  inflating: train/3483.png          \n",
            "  inflating: train/3484.png          \n",
            "  inflating: train/3485.png          \n",
            "  inflating: train/3486.png          \n",
            "  inflating: train/3487.png          \n",
            "  inflating: train/3488.png          \n",
            "  inflating: train/3489.png          \n",
            "  inflating: train/349.png           \n",
            "  inflating: train/3490.png          \n",
            "  inflating: train/3491.png          \n",
            "  inflating: train/3492.png          \n",
            "  inflating: train/3493.png          \n",
            "  inflating: train/3494.png          \n",
            "  inflating: train/3495.png          \n",
            "  inflating: train/3496.png          \n",
            "  inflating: train/3497.png          \n",
            "  inflating: train/3498.png          \n",
            "  inflating: train/3499.png          \n",
            "  inflating: train/35.png            \n",
            "  inflating: train/350.png           \n",
            "  inflating: train/3500.png          \n",
            "  inflating: train/3501.png          \n",
            "  inflating: train/3502.png          \n",
            "  inflating: train/3503.png          \n",
            "  inflating: train/3504.png          \n",
            "  inflating: train/3505.png          \n",
            "  inflating: train/3506.png          \n",
            "  inflating: train/3507.png          \n",
            "  inflating: train/3508.png          \n",
            "  inflating: train/3509.png          \n",
            "  inflating: train/351.png           \n",
            "  inflating: train/3510.png          \n",
            "  inflating: train/3511.png          \n",
            "  inflating: train/3512.png          \n",
            "  inflating: train/3513.png          \n",
            "  inflating: train/3514.png          \n",
            "  inflating: train/3515.png          \n",
            "  inflating: train/3516.png          \n",
            "  inflating: train/3517.png          \n",
            "  inflating: train/3518.png          \n",
            "  inflating: train/3519.png          \n",
            "  inflating: train/352.png           \n",
            "  inflating: train/3520.png          \n",
            "  inflating: train/3521.png          \n",
            "  inflating: train/3522.png          \n",
            "  inflating: train/3523.png          \n",
            "  inflating: train/3524.png          \n",
            "  inflating: train/3525.png          \n",
            "  inflating: train/3526.png          \n",
            "  inflating: train/3527.png          \n",
            "  inflating: train/3528.png          \n",
            "  inflating: train/3529.png          \n",
            "  inflating: train/353.png           \n",
            "  inflating: train/3530.png          \n",
            "  inflating: train/3531.png          \n",
            "  inflating: train/3532.png          \n",
            "  inflating: train/3533.png          \n",
            "  inflating: train/3534.png          \n",
            "  inflating: train/3535.png          \n",
            "  inflating: train/3536.png          \n",
            "  inflating: train/3537.png          \n",
            "  inflating: train/3538.png          \n",
            "  inflating: train/3539.png          \n",
            "  inflating: train/354.png           \n",
            "  inflating: train/3540.png          \n",
            "  inflating: train/3541.png          \n",
            "  inflating: train/3542.png          \n",
            "  inflating: train/3543.png          \n",
            "  inflating: train/3544.png          \n",
            "  inflating: train/3545.png          \n",
            "  inflating: train/3546.png          \n",
            "  inflating: train/3547.png          \n",
            "  inflating: train/3548.png          \n",
            "  inflating: train/3549.png          \n",
            "  inflating: train/355.png           \n",
            "  inflating: train/3550.png          \n",
            "  inflating: train/3551.png          \n",
            "  inflating: train/3552.png          \n",
            "  inflating: train/3553.png          \n",
            "  inflating: train/3554.png          \n",
            "  inflating: train/3555.png          \n",
            "  inflating: train/3556.png          \n",
            "  inflating: train/3557.png          \n",
            "  inflating: train/3558.png          \n",
            "  inflating: train/3559.png          \n",
            "  inflating: train/356.png           \n",
            "  inflating: train/3560.png          \n",
            "  inflating: train/3561.png          \n",
            "  inflating: train/3562.png          \n",
            "  inflating: train/3563.png          \n",
            "  inflating: train/3564.png          \n",
            "  inflating: train/3565.png          \n",
            "  inflating: train/3566.png          \n",
            "  inflating: train/3567.png          \n",
            "  inflating: train/3568.png          \n",
            "  inflating: train/3569.png          \n",
            "  inflating: train/357.png           \n",
            "  inflating: train/3570.png          \n",
            "  inflating: train/3571.png          \n",
            "  inflating: train/3572.png          \n",
            "  inflating: train/3573.png          \n",
            "  inflating: train/3574.png          \n",
            "  inflating: train/3575.png          \n",
            "  inflating: train/3576.png          \n",
            "  inflating: train/3577.png          \n",
            "  inflating: train/3578.png          \n",
            "  inflating: train/3579.png          \n",
            "  inflating: train/358.png           \n",
            "  inflating: train/3580.png          \n",
            "  inflating: train/3581.png          \n",
            "  inflating: train/3582.png          \n",
            "  inflating: train/3583.png          \n",
            "  inflating: train/3584.png          \n",
            "  inflating: train/3585.png          \n",
            "  inflating: train/3586.png          \n",
            "  inflating: train/3587.png          \n",
            "  inflating: train/3588.png          \n",
            "  inflating: train/3589.png          \n",
            "  inflating: train/359.png           \n",
            "  inflating: train/3590.png          \n",
            "  inflating: train/3591.png          \n",
            "  inflating: train/3592.png          \n",
            "  inflating: train/3593.png          \n",
            "  inflating: train/3594.png          \n",
            "  inflating: train/3595.png          \n",
            "  inflating: train/3596.png          \n",
            "  inflating: train/3597.png          \n",
            "  inflating: train/3598.png          \n",
            "  inflating: train/3599.png          \n",
            "  inflating: train/36.png            \n",
            "  inflating: train/360.png           \n",
            "  inflating: train/3600.png          \n",
            "  inflating: train/3601.png          \n",
            "  inflating: train/3602.png          \n",
            "  inflating: train/3603.png          \n",
            "  inflating: train/3604.png          \n",
            "  inflating: train/3605.png          \n",
            "  inflating: train/3606.png          \n",
            "  inflating: train/3607.png          \n",
            "  inflating: train/3608.png          \n",
            "  inflating: train/3609.png          \n",
            "  inflating: train/361.png           \n",
            "  inflating: train/3610.png          \n",
            "  inflating: train/3611.png          \n",
            "  inflating: train/3612.png          \n",
            "  inflating: train/3613.png          \n",
            "  inflating: train/3614.png          \n",
            "  inflating: train/3615.png          \n",
            "  inflating: train/3616.png          \n",
            "  inflating: train/3617.png          \n",
            "  inflating: train/3618.png          \n",
            "  inflating: train/3619.png          \n",
            "  inflating: train/362.png           \n",
            "  inflating: train/3620.png          \n",
            "  inflating: train/3621.png          \n",
            "  inflating: train/3622.png          \n",
            "  inflating: train/3623.png          \n",
            "  inflating: train/3624.png          \n",
            "  inflating: train/3625.png          \n",
            "  inflating: train/3626.png          \n",
            "  inflating: train/3627.png          \n",
            "  inflating: train/3628.png          \n",
            "  inflating: train/3629.png          \n",
            "  inflating: train/363.png           \n",
            "  inflating: train/3630.png          \n",
            "  inflating: train/3631.png          \n",
            "  inflating: train/3632.png          \n",
            "  inflating: train/3633.png          \n",
            "  inflating: train/3634.png          \n",
            "  inflating: train/3635.png          \n",
            "  inflating: train/3636.png          \n",
            "  inflating: train/3637.png          \n",
            "  inflating: train/3638.png          \n",
            "  inflating: train/3639.png          \n",
            "  inflating: train/364.png           \n",
            "  inflating: train/3640.png          \n",
            "  inflating: train/3641.png          \n",
            "  inflating: train/3642.png          \n",
            "  inflating: train/3643.png          \n",
            "  inflating: train/3644.png          \n",
            "  inflating: train/3645.png          \n",
            "  inflating: train/3646.png          \n",
            "  inflating: train/3647.png          \n",
            "  inflating: train/3648.png          \n",
            "  inflating: train/3649.png          \n",
            "  inflating: train/365.png           \n",
            "  inflating: train/3650.png          \n",
            "  inflating: train/3651.png          \n",
            "  inflating: train/3652.png          \n",
            "  inflating: train/3653.png          \n",
            "  inflating: train/3654.png          \n",
            "  inflating: train/3655.png          \n",
            "  inflating: train/3656.png          \n",
            "  inflating: train/3657.png          \n",
            "  inflating: train/3658.png          \n",
            "  inflating: train/3659.png          \n",
            "  inflating: train/366.png           \n",
            "  inflating: train/3660.png          \n",
            "  inflating: train/3661.png          \n",
            "  inflating: train/3662.png          \n",
            "  inflating: train/3663.png          \n",
            "  inflating: train/3664.png          \n",
            "  inflating: train/3665.png          \n",
            "  inflating: train/3666.png          \n",
            "  inflating: train/3667.png          \n",
            "  inflating: train/3668.png          \n",
            "  inflating: train/3669.png          \n",
            "  inflating: train/367.png           \n",
            "  inflating: train/3670.png          \n",
            "  inflating: train/3671.png          \n",
            "  inflating: train/3672.png          \n",
            "  inflating: train/3673.png          \n",
            "  inflating: train/3674.png          \n",
            "  inflating: train/3675.png          \n",
            "  inflating: train/3676.png          \n",
            "  inflating: train/3677.png          \n",
            "  inflating: train/3678.png          \n",
            "  inflating: train/3679.png          \n",
            "  inflating: train/368.png           \n",
            "  inflating: train/3680.png          \n",
            "  inflating: train/3681.png          \n",
            "  inflating: train/3682.png          \n",
            "  inflating: train/3683.png          \n",
            "  inflating: train/3684.png          \n",
            "  inflating: train/3685.png          \n",
            "  inflating: train/3686.png          \n",
            "  inflating: train/3687.png          \n",
            "  inflating: train/3688.png          \n",
            "  inflating: train/3689.png          \n",
            "  inflating: train/369.png           \n",
            "  inflating: train/3690.png          \n",
            "  inflating: train/3691.png          \n",
            "  inflating: train/3692.png          \n",
            "  inflating: train/3693.png          \n",
            "  inflating: train/3694.png          \n",
            "  inflating: train/3695.png          \n",
            "  inflating: train/3696.png          \n",
            "  inflating: train/3697.png          \n",
            "  inflating: train/3698.png          \n",
            "  inflating: train/3699.png          \n",
            "  inflating: train/37.png            \n",
            "  inflating: train/370.png           \n",
            "  inflating: train/3700.png          \n",
            "  inflating: train/3701.png          \n",
            "  inflating: train/3702.png          \n",
            "  inflating: train/3703.png          \n",
            "  inflating: train/3704.png          \n",
            "  inflating: train/3705.png          \n",
            "  inflating: train/3706.png          \n",
            "  inflating: train/3707.png          \n",
            "  inflating: train/3708.png          \n",
            "  inflating: train/3709.png          \n",
            "  inflating: train/371.png           \n",
            "  inflating: train/3710.png          \n",
            "  inflating: train/3711.png          \n",
            "  inflating: train/3712.png          \n",
            "  inflating: train/3713.png          \n",
            "  inflating: train/3714.png          \n",
            "  inflating: train/3715.png          \n",
            "  inflating: train/3716.png          \n",
            "  inflating: train/3717.png          \n",
            "  inflating: train/3718.png          \n",
            "  inflating: train/3719.png          \n",
            "  inflating: train/372.png           \n",
            "  inflating: train/3720.png          \n",
            "  inflating: train/3721.png          \n",
            "  inflating: train/3722.png          \n",
            "  inflating: train/3723.png          \n",
            "  inflating: train/3724.png          \n",
            "  inflating: train/3725.png          \n",
            "  inflating: train/3726.png          \n",
            "  inflating: train/3727.png          \n",
            "  inflating: train/3728.png          \n",
            "  inflating: train/3729.png          \n",
            "  inflating: train/373.png           \n",
            "  inflating: train/3730.png          \n",
            "  inflating: train/3731.png          \n",
            "  inflating: train/3732.png          \n",
            "  inflating: train/3733.png          \n",
            "  inflating: train/3734.png          \n",
            "  inflating: train/3735.png          \n",
            "  inflating: train/3736.png          \n",
            "  inflating: train/3737.png          \n",
            "  inflating: train/3738.png          \n",
            "  inflating: train/3739.png          \n",
            "  inflating: train/374.png           \n",
            "  inflating: train/3740.png          \n",
            "  inflating: train/3741.png          \n",
            "  inflating: train/3742.png          \n",
            "  inflating: train/3743.png          \n",
            "  inflating: train/3744.png          \n",
            "  inflating: train/3745.png          \n",
            "  inflating: train/3746.png          \n",
            "  inflating: train/3747.png          \n",
            "  inflating: train/3748.png          \n",
            "  inflating: train/3749.png          \n",
            "  inflating: train/375.png           \n",
            "  inflating: train/3750.png          \n",
            "  inflating: train/3751.png          \n",
            "  inflating: train/3752.png          \n",
            "  inflating: train/3753.png          \n",
            "  inflating: train/3754.png          \n",
            "  inflating: train/3755.png          \n",
            "  inflating: train/3756.png          \n",
            "  inflating: train/3757.png          \n",
            "  inflating: train/3758.png          \n",
            "  inflating: train/3759.png          \n",
            "  inflating: train/376.png           \n",
            "  inflating: train/3760.png          \n",
            "  inflating: train/3761.png          \n",
            "  inflating: train/3762.png          \n",
            "  inflating: train/3763.png          \n",
            "  inflating: train/3764.png          \n",
            "  inflating: train/3765.png          \n",
            "  inflating: train/3766.png          \n",
            "  inflating: train/3767.png          \n",
            "  inflating: train/3768.png          \n",
            "  inflating: train/3769.png          \n",
            "  inflating: train/377.png           \n",
            "  inflating: train/3770.png          \n",
            "  inflating: train/3771.png          \n",
            "  inflating: train/3772.png          \n",
            "  inflating: train/3773.png          \n",
            "  inflating: train/3774.png          \n",
            "  inflating: train/3775.png          \n",
            "  inflating: train/3776.png          \n",
            "  inflating: train/3777.png          \n",
            "  inflating: train/3778.png          \n",
            "  inflating: train/3779.png          \n",
            "  inflating: train/378.png           \n",
            "  inflating: train/3780.png          \n",
            "  inflating: train/3781.png          \n",
            "  inflating: train/3782.png          \n",
            "  inflating: train/3783.png          \n",
            "  inflating: train/3784.png          \n",
            "  inflating: train/3785.png          \n",
            "  inflating: train/3786.png          \n",
            "  inflating: train/3787.png          \n",
            "  inflating: train/3788.png          \n",
            "  inflating: train/3789.png          \n",
            "  inflating: train/379.png           \n",
            "  inflating: train/3790.png          \n",
            "  inflating: train/3791.png          \n",
            "  inflating: train/3792.png          \n",
            "  inflating: train/3793.png          \n",
            "  inflating: train/3794.png          \n",
            "  inflating: train/3795.png          \n",
            "  inflating: train/3796.png          \n",
            "  inflating: train/3797.png          \n",
            "  inflating: train/3798.png          \n",
            "  inflating: train/3799.png          \n",
            "  inflating: train/38.png            \n",
            "  inflating: train/380.png           \n",
            "  inflating: train/3800.png          \n",
            "  inflating: train/3801.png          \n",
            "  inflating: train/3802.png          \n",
            "  inflating: train/3803.png          \n",
            "  inflating: train/3804.png          \n",
            "  inflating: train/3805.png          \n",
            "  inflating: train/3806.png          \n",
            "  inflating: train/3807.png          \n",
            "  inflating: train/3808.png          \n",
            "  inflating: train/3809.png          \n",
            "  inflating: train/381.png           \n",
            "  inflating: train/3810.png          \n",
            "  inflating: train/3811.png          \n",
            "  inflating: train/3812.png          \n",
            "  inflating: train/3813.png          \n",
            "  inflating: train/3814.png          \n",
            "  inflating: train/3815.png          \n",
            "  inflating: train/3816.png          \n",
            "  inflating: train/3817.png          \n",
            "  inflating: train/3818.png          \n",
            "  inflating: train/3819.png          \n",
            "  inflating: train/382.png           \n",
            "  inflating: train/3820.png          \n",
            "  inflating: train/3821.png          \n",
            "  inflating: train/3822.png          \n",
            "  inflating: train/3823.png          \n",
            "  inflating: train/3824.png          \n",
            "  inflating: train/3825.png          \n",
            "  inflating: train/3826.png          \n",
            "  inflating: train/3827.png          \n",
            "  inflating: train/3828.png          \n",
            "  inflating: train/3829.png          \n",
            "  inflating: train/383.png           \n",
            "  inflating: train/3830.png          \n",
            "  inflating: train/3831.png          \n",
            "  inflating: train/3832.png          \n",
            "  inflating: train/3833.png          \n",
            "  inflating: train/3834.png          \n",
            "  inflating: train/3835.png          \n",
            "  inflating: train/3836.png          \n",
            "  inflating: train/3837.png          \n",
            "  inflating: train/3838.png          \n",
            "  inflating: train/3839.png          \n",
            "  inflating: train/384.png           \n",
            "  inflating: train/3840.png          \n",
            "  inflating: train/3841.png          \n",
            "  inflating: train/3842.png          \n",
            "  inflating: train/3843.png          \n",
            "  inflating: train/3844.png          \n",
            "  inflating: train/3845.png          \n",
            "  inflating: train/3846.png          \n",
            "  inflating: train/3847.png          \n",
            "  inflating: train/3848.png          \n",
            "  inflating: train/3849.png          \n",
            "  inflating: train/385.png           \n",
            "  inflating: train/3850.png          \n",
            "  inflating: train/3851.png          \n",
            "  inflating: train/3852.png          \n",
            "  inflating: train/3853.png          \n",
            "  inflating: train/3854.png          \n",
            "  inflating: train/3855.png          \n",
            "  inflating: train/3856.png          \n",
            "  inflating: train/3857.png          \n",
            "  inflating: train/3858.png          \n",
            "  inflating: train/3859.png          \n",
            "  inflating: train/386.png           \n",
            "  inflating: train/3860.png          \n",
            "  inflating: train/3861.png          \n",
            "  inflating: train/3862.png          \n",
            "  inflating: train/3863.png          \n",
            "  inflating: train/3864.png          \n",
            "  inflating: train/3865.png          \n",
            "  inflating: train/3866.png          \n",
            "  inflating: train/3867.png          \n",
            "  inflating: train/3868.png          \n",
            "  inflating: train/3869.png          \n",
            "  inflating: train/387.png           \n",
            "  inflating: train/3870.png          \n",
            "  inflating: train/3871.png          \n",
            "  inflating: train/3872.png          \n",
            "  inflating: train/3873.png          \n",
            "  inflating: train/3874.png          \n",
            "  inflating: train/3875.png          \n",
            "  inflating: train/3876.png          \n",
            "  inflating: train/3877.png          \n",
            "  inflating: train/3878.png          \n",
            "  inflating: train/3879.png          \n",
            "  inflating: train/388.png           \n",
            "  inflating: train/3880.png          \n",
            "  inflating: train/3881.png          \n",
            "  inflating: train/3882.png          \n",
            "  inflating: train/3883.png          \n",
            "  inflating: train/3884.png          \n",
            "  inflating: train/3885.png          \n",
            "  inflating: train/3886.png          \n",
            "  inflating: train/3887.png          \n",
            "  inflating: train/3888.png          \n",
            "  inflating: train/3889.png          \n",
            "  inflating: train/389.png           \n",
            "  inflating: train/3890.png          \n",
            "  inflating: train/3891.png          \n",
            "  inflating: train/3892.png          \n",
            "  inflating: train/3893.png          \n",
            "  inflating: train/3894.png          \n",
            "  inflating: train/3895.png          \n",
            "  inflating: train/3896.png          \n",
            "  inflating: train/3897.png          \n",
            "  inflating: train/3898.png          \n",
            "  inflating: train/3899.png          \n",
            "  inflating: train/39.png            \n",
            "  inflating: train/390.png           \n",
            "  inflating: train/3900.png          \n",
            "  inflating: train/3901.png          \n",
            "  inflating: train/3902.png          \n",
            "  inflating: train/3903.png          \n",
            "  inflating: train/3904.png          \n",
            "  inflating: train/3905.png          \n",
            "  inflating: train/3906.png          \n",
            "  inflating: train/3907.png          \n",
            "  inflating: train/3908.png          \n",
            "  inflating: train/3909.png          \n",
            "  inflating: train/391.png           \n",
            "  inflating: train/3910.png          \n",
            "  inflating: train/3911.png          \n",
            "  inflating: train/3912.png          \n",
            "  inflating: train/3913.png          \n",
            "  inflating: train/3914.png          \n",
            "  inflating: train/3915.png          \n",
            "  inflating: train/3916.png          \n",
            "  inflating: train/3917.png          \n",
            "  inflating: train/3918.png          \n",
            "  inflating: train/3919.png          \n",
            "  inflating: train/392.png           \n",
            "  inflating: train/3920.png          \n",
            "  inflating: train/3921.png          \n",
            "  inflating: train/3922.png          \n",
            "  inflating: train/3923.png          \n",
            "  inflating: train/3924.png          \n",
            "  inflating: train/3925.png          \n",
            "  inflating: train/3926.png          \n",
            "  inflating: train/3927.png          \n",
            "  inflating: train/3928.png          \n",
            "  inflating: train/3929.png          \n",
            "  inflating: train/393.png           \n",
            "  inflating: train/3930.png          \n",
            "  inflating: train/3931.png          \n",
            "  inflating: train/3932.png          \n",
            "  inflating: train/3933.png          \n",
            "  inflating: train/3934.png          \n",
            "  inflating: train/3935.png          \n",
            "  inflating: train/3936.png          \n",
            "  inflating: train/3937.png          \n",
            "  inflating: train/3938.png          \n",
            "  inflating: train/3939.png          \n",
            "  inflating: train/394.png           \n",
            "  inflating: train/3940.png          \n",
            "  inflating: train/3941.png          \n",
            "  inflating: train/3942.png          \n",
            "  inflating: train/3943.png          \n",
            "  inflating: train/3944.png          \n",
            "  inflating: train/3945.png          \n",
            "  inflating: train/3946.png          \n",
            "  inflating: train/3947.png          \n",
            "  inflating: train/3948.png          \n",
            "  inflating: train/3949.png          \n",
            "  inflating: train/395.png           \n",
            "  inflating: train/3950.png          \n",
            "  inflating: train/3951.png          \n",
            "  inflating: train/3952.png          \n",
            "  inflating: train/3953.png          \n",
            "  inflating: train/3954.png          \n",
            "  inflating: train/3955.png          \n",
            "  inflating: train/3956.png          \n",
            "  inflating: train/3957.png          \n",
            "  inflating: train/3958.png          \n",
            "  inflating: train/3959.png          \n",
            "  inflating: train/396.png           \n",
            "  inflating: train/3960.png          \n",
            "  inflating: train/3961.png          \n",
            "  inflating: train/3962.png          \n",
            "  inflating: train/3963.png          \n",
            "  inflating: train/3964.png          \n",
            "  inflating: train/3965.png          \n",
            "  inflating: train/3966.png          \n",
            "  inflating: train/3967.png          \n",
            "  inflating: train/3968.png          \n",
            "  inflating: train/3969.png          \n",
            "  inflating: train/397.png           \n",
            "  inflating: train/3970.png          \n",
            "  inflating: train/3971.png          \n",
            "  inflating: train/3972.png          \n",
            "  inflating: train/3973.png          \n",
            "  inflating: train/3974.png          \n",
            "  inflating: train/3975.png          \n",
            "  inflating: train/3976.png          \n",
            "  inflating: train/3977.png          \n",
            "  inflating: train/3978.png          \n",
            "  inflating: train/3979.png          \n",
            "  inflating: train/398.png           \n",
            "  inflating: train/3980.png          \n",
            "  inflating: train/3981.png          \n",
            "  inflating: train/3982.png          \n",
            "  inflating: train/3983.png          \n",
            "  inflating: train/3984.png          \n",
            "  inflating: train/3985.png          \n",
            "  inflating: train/3986.png          \n",
            "  inflating: train/3987.png          \n",
            "  inflating: train/3988.png          \n",
            "  inflating: train/3989.png          \n",
            "  inflating: train/399.png           \n",
            "  inflating: train/3990.png          \n",
            "  inflating: train/3991.png          \n",
            "  inflating: train/3992.png          \n",
            "  inflating: train/3993.png          \n",
            "  inflating: train/3994.png          \n",
            "  inflating: train/3995.png          \n",
            "  inflating: train/3996.png          \n",
            "  inflating: train/3997.png          \n",
            "  inflating: train/3998.png          \n",
            "  inflating: train/3999.png          \n",
            "  inflating: train/4.png             \n",
            "  inflating: train/40.png            \n",
            "  inflating: train/400.png           \n",
            "  inflating: train/4000.png          \n",
            "  inflating: train/4001.png          \n",
            "  inflating: train/4002.png          \n",
            "  inflating: train/4003.png          \n",
            "  inflating: train/4004.png          \n",
            "  inflating: train/4005.png          \n",
            "  inflating: train/4006.png          \n",
            "  inflating: train/4007.png          \n",
            "  inflating: train/4008.png          \n",
            "  inflating: train/4009.png          \n",
            "  inflating: train/401.png           \n",
            "  inflating: train/4010.png          \n",
            "  inflating: train/4011.png          \n",
            "  inflating: train/4012.png          \n",
            "  inflating: train/4013.png          \n",
            "  inflating: train/4014.png          \n",
            "  inflating: train/4015.png          \n",
            "  inflating: train/4016.png          \n",
            "  inflating: train/4017.png          \n",
            "  inflating: train/4018.png          \n",
            "  inflating: train/4019.png          \n",
            "  inflating: train/402.png           \n",
            "  inflating: train/4020.png          \n",
            "  inflating: train/4021.png          \n",
            "  inflating: train/4022.png          \n",
            "  inflating: train/4023.png          \n",
            "  inflating: train/4024.png          \n",
            "  inflating: train/4025.png          \n",
            "  inflating: train/4026.png          \n",
            "  inflating: train/4027.png          \n",
            "  inflating: train/4028.png          \n",
            "  inflating: train/4029.png          \n",
            "  inflating: train/403.png           \n",
            "  inflating: train/4030.png          \n",
            "  inflating: train/4031.png          \n",
            "  inflating: train/4032.png          \n",
            "  inflating: train/4033.png          \n",
            "  inflating: train/4034.png          \n",
            "  inflating: train/4035.png          \n",
            "  inflating: train/4036.png          \n",
            "  inflating: train/4037.png          \n",
            "  inflating: train/4038.png          \n",
            "  inflating: train/4039.png          \n",
            "  inflating: train/404.png           \n",
            "  inflating: train/4040.png          \n",
            "  inflating: train/4041.png          \n",
            "  inflating: train/4042.png          \n",
            "  inflating: train/4043.png          \n",
            "  inflating: train/4044.png          \n",
            "  inflating: train/4045.png          \n",
            "  inflating: train/4046.png          \n",
            "  inflating: train/4047.png          \n",
            "  inflating: train/4048.png          \n",
            "  inflating: train/4049.png          \n",
            "  inflating: train/405.png           \n",
            "  inflating: train/4050.png          \n",
            "  inflating: train/4051.png          \n",
            "  inflating: train/4052.png          \n",
            "  inflating: train/4053.png          \n",
            "  inflating: train/4054.png          \n",
            "  inflating: train/4055.png          \n",
            "  inflating: train/4056.png          \n",
            "  inflating: train/4057.png          \n",
            "  inflating: train/4058.png          \n",
            "  inflating: train/4059.png          \n",
            "  inflating: train/406.png           \n",
            "  inflating: train/4060.png          \n",
            "  inflating: train/4061.png          \n",
            "  inflating: train/4062.png          \n",
            "  inflating: train/4063.png          \n",
            "  inflating: train/4064.png          \n",
            "  inflating: train/4065.png          \n",
            "  inflating: train/4066.png          \n",
            "  inflating: train/4067.png          \n",
            "  inflating: train/4068.png          \n",
            "  inflating: train/4069.png          \n",
            "  inflating: train/407.png           \n",
            "  inflating: train/4070.png          \n",
            "  inflating: train/4071.png          \n",
            "  inflating: train/4072.png          \n",
            "  inflating: train/4073.png          \n",
            "  inflating: train/4074.png          \n",
            "  inflating: train/4075.png          \n",
            "  inflating: train/4076.png          \n",
            "  inflating: train/4077.png          \n",
            "  inflating: train/4078.png          \n",
            "  inflating: train/4079.png          \n",
            "  inflating: train/408.png           \n",
            "  inflating: train/4080.png          \n",
            "  inflating: train/4081.png          \n",
            "  inflating: train/4082.png          \n",
            "  inflating: train/4083.png          \n",
            "  inflating: train/4084.png          \n",
            "  inflating: train/4085.png          \n",
            "  inflating: train/4086.png          \n",
            "  inflating: train/4087.png          \n",
            "  inflating: train/4088.png          \n",
            "  inflating: train/4089.png          \n",
            "  inflating: train/409.png           \n",
            "  inflating: train/4090.png          \n",
            "  inflating: train/4091.png          \n",
            "  inflating: train/4092.png          \n",
            "  inflating: train/4093.png          \n",
            "  inflating: train/4094.png          \n",
            "  inflating: train/4095.png          \n",
            "  inflating: train/4096.png          \n",
            "  inflating: train/4097.png          \n",
            "  inflating: train/4098.png          \n",
            "  inflating: train/4099.png          \n",
            "  inflating: train/41.png            \n",
            "  inflating: train/410.png           \n",
            "  inflating: train/4100.png          \n",
            "  inflating: train/4101.png          \n",
            "  inflating: train/4102.png          \n",
            "  inflating: train/4103.png          \n",
            "  inflating: train/4104.png          \n",
            "  inflating: train/4105.png          \n",
            "  inflating: train/4106.png          \n",
            "  inflating: train/4107.png          \n",
            "  inflating: train/4108.png          \n",
            "  inflating: train/4109.png          \n",
            "  inflating: train/411.png           \n",
            "  inflating: train/4110.png          \n",
            "  inflating: train/4111.png          \n",
            "  inflating: train/4112.png          \n",
            "  inflating: train/4113.png          \n",
            "  inflating: train/4114.png          \n",
            "  inflating: train/4115.png          \n",
            "  inflating: train/4116.png          \n",
            "  inflating: train/4117.png          \n",
            "  inflating: train/4118.png          \n",
            "  inflating: train/4119.png          \n",
            "  inflating: train/412.png           \n",
            "  inflating: train/4120.png          \n",
            "  inflating: train/4121.png          \n",
            "  inflating: train/4122.png          \n",
            "  inflating: train/4123.png          \n",
            "  inflating: train/4124.png          \n",
            "  inflating: train/4125.png          \n",
            "  inflating: train/4126.png          \n",
            "  inflating: train/4127.png          \n",
            "  inflating: train/4128.png          \n",
            "  inflating: train/4129.png          \n",
            "  inflating: train/413.png           \n",
            "  inflating: train/4130.png          \n",
            "  inflating: train/4131.png          \n",
            "  inflating: train/4132.png          \n",
            "  inflating: train/4133.png          \n",
            "  inflating: train/4134.png          \n",
            "  inflating: train/4135.png          \n",
            "  inflating: train/4136.png          \n",
            "  inflating: train/4137.png          \n",
            "  inflating: train/4138.png          \n",
            "  inflating: train/4139.png          \n",
            "  inflating: train/414.png           \n",
            "  inflating: train/4140.png          \n",
            "  inflating: train/4141.png          \n",
            "  inflating: train/4142.png          \n",
            "  inflating: train/4143.png          \n",
            "  inflating: train/4144.png          \n",
            "  inflating: train/4145.png          \n",
            "  inflating: train/4146.png          \n",
            "  inflating: train/4147.png          \n",
            "  inflating: train/4148.png          \n",
            "  inflating: train/4149.png          \n",
            "  inflating: train/415.png           \n",
            "  inflating: train/4150.png          \n",
            "  inflating: train/4151.png          \n",
            "  inflating: train/4152.png          \n",
            "  inflating: train/4153.png          \n",
            "  inflating: train/4154.png          \n",
            "  inflating: train/4155.png          \n",
            "  inflating: train/4156.png          \n",
            "  inflating: train/4157.png          \n",
            "  inflating: train/4158.png          \n",
            "  inflating: train/4159.png          \n",
            "  inflating: train/416.png           \n",
            "  inflating: train/4160.png          \n",
            "  inflating: train/4161.png          \n",
            "  inflating: train/4162.png          \n",
            "  inflating: train/4163.png          \n",
            "  inflating: train/4164.png          \n",
            "  inflating: train/4165.png          \n",
            "  inflating: train/4166.png          \n",
            "  inflating: train/4167.png          \n",
            "  inflating: train/4168.png          \n",
            "  inflating: train/4169.png          \n",
            "  inflating: train/417.png           \n",
            "  inflating: train/4170.png          \n",
            "  inflating: train/4171.png          \n",
            "  inflating: train/4172.png          \n",
            "  inflating: train/4173.png          \n",
            "  inflating: train/4174.png          \n",
            "  inflating: train/4175.png          \n",
            "  inflating: train/4176.png          \n",
            "  inflating: train/4177.png          \n",
            "  inflating: train/4178.png          \n",
            "  inflating: train/4179.png          \n",
            "  inflating: train/418.png           \n",
            "  inflating: train/4180.png          \n",
            "  inflating: train/4181.png          \n",
            "  inflating: train/4182.png          \n",
            "  inflating: train/4183.png          \n",
            "  inflating: train/4184.png          \n",
            "  inflating: train/4185.png          \n",
            "  inflating: train/4186.png          \n",
            "  inflating: train/4187.png          \n",
            "  inflating: train/4188.png          \n",
            "  inflating: train/4189.png          \n",
            "  inflating: train/419.png           \n",
            "  inflating: train/4190.png          \n",
            "  inflating: train/4191.png          \n",
            "  inflating: train/4192.png          \n",
            "  inflating: train/4193.png          \n",
            "  inflating: train/4194.png          \n",
            "  inflating: train/4195.png          \n",
            "  inflating: train/4196.png          \n",
            "  inflating: train/4197.png          \n",
            "  inflating: train/4198.png          \n",
            "  inflating: train/4199.png          \n",
            "  inflating: train/42.png            \n",
            "  inflating: train/420.png           \n",
            "  inflating: train/4200.png          \n",
            "  inflating: train/4201.png          \n",
            "  inflating: train/4202.png          \n",
            "  inflating: train/4203.png          \n",
            "  inflating: train/4204.png          \n",
            "  inflating: train/4205.png          \n",
            "  inflating: train/4206.png          \n",
            "  inflating: train/4207.png          \n",
            "  inflating: train/4208.png          \n",
            "  inflating: train/4209.png          \n",
            "  inflating: train/421.png           \n",
            "  inflating: train/4210.png          \n",
            "  inflating: train/4211.png          \n",
            "  inflating: train/4212.png          \n",
            "  inflating: train/4213.png          \n",
            "  inflating: train/4214.png          \n",
            "  inflating: train/4215.png          \n",
            "  inflating: train/4216.png          \n",
            "  inflating: train/4217.png          \n",
            "  inflating: train/4218.png          \n",
            "  inflating: train/4219.png          \n",
            "  inflating: train/422.png           \n",
            "  inflating: train/4220.png          \n",
            "  inflating: train/4221.png          \n",
            "  inflating: train/4222.png          \n",
            "  inflating: train/4223.png          \n",
            "  inflating: train/4224.png          \n",
            "  inflating: train/4225.png          \n",
            "  inflating: train/4226.png          \n",
            "  inflating: train/4227.png          \n",
            "  inflating: train/4228.png          \n",
            "  inflating: train/4229.png          \n",
            "  inflating: train/423.png           \n",
            "  inflating: train/4230.png          \n",
            "  inflating: train/4231.png          \n",
            "  inflating: train/4232.png          \n",
            "  inflating: train/4233.png          \n",
            "  inflating: train/4234.png          \n",
            "  inflating: train/4235.png          \n",
            "  inflating: train/4236.png          \n",
            "  inflating: train/4237.png          \n",
            "  inflating: train/4238.png          \n",
            "  inflating: train/4239.png          \n",
            "  inflating: train/424.png           \n",
            "  inflating: train/4240.png          \n",
            "  inflating: train/4241.png          \n",
            "  inflating: train/4242.png          \n",
            "  inflating: train/4243.png          \n",
            "  inflating: train/4244.png          \n",
            "  inflating: train/4245.png          \n",
            "  inflating: train/4246.png          \n",
            "  inflating: train/4247.png          \n",
            "  inflating: train/4248.png          \n",
            "  inflating: train/4249.png          \n",
            "  inflating: train/425.png           \n",
            "  inflating: train/4250.png          \n",
            "  inflating: train/4251.png          \n",
            "  inflating: train/4252.png          \n",
            "  inflating: train/4253.png          \n",
            "  inflating: train/4254.png          \n",
            "  inflating: train/4255.png          \n",
            "  inflating: train/4256.png          \n",
            "  inflating: train/4257.png          \n",
            "  inflating: train/4258.png          \n",
            "  inflating: train/4259.png          \n",
            "  inflating: train/426.png           \n",
            "  inflating: train/4260.png          \n",
            "  inflating: train/4261.png          \n",
            "  inflating: train/4262.png          \n",
            "  inflating: train/4263.png          \n",
            "  inflating: train/4264.png          \n",
            "  inflating: train/4265.png          \n",
            "  inflating: train/4266.png          \n",
            "  inflating: train/4267.png          \n",
            "  inflating: train/4268.png          \n",
            "  inflating: train/4269.png          \n",
            "  inflating: train/427.png           \n",
            "  inflating: train/4270.png          \n",
            "  inflating: train/4271.png          \n",
            "  inflating: train/4272.png          \n",
            "  inflating: train/4273.png          \n",
            "  inflating: train/4274.png          \n",
            "  inflating: train/4275.png          \n",
            "  inflating: train/4276.png          \n",
            "  inflating: train/4277.png          \n",
            "  inflating: train/4278.png          \n",
            "  inflating: train/4279.png          \n",
            "  inflating: train/428.png           \n",
            "  inflating: train/4280.png          \n",
            "  inflating: train/4281.png          \n",
            "  inflating: train/4282.png          \n",
            "  inflating: train/4283.png          \n",
            "  inflating: train/4284.png          \n",
            "  inflating: train/4285.png          \n",
            "  inflating: train/4286.png          \n",
            "  inflating: train/4287.png          \n",
            "  inflating: train/4288.png          \n",
            "  inflating: train/4289.png          \n",
            "  inflating: train/429.png           \n",
            "  inflating: train/4290.png          \n",
            "  inflating: train/4291.png          \n",
            "  inflating: train/4292.png          \n",
            "  inflating: train/4293.png          \n",
            "  inflating: train/4294.png          \n",
            "  inflating: train/4295.png          \n",
            "  inflating: train/4296.png          \n",
            "  inflating: train/4297.png          \n",
            "  inflating: train/4298.png          \n",
            "  inflating: train/4299.png          \n",
            "  inflating: train/43.png            \n",
            "  inflating: train/430.png           \n",
            "  inflating: train/4300.png          \n",
            "  inflating: train/4301.png          \n",
            "  inflating: train/4302.png          \n",
            "  inflating: train/4303.png          \n",
            "  inflating: train/4304.png          \n",
            "  inflating: train/4305.png          \n",
            "  inflating: train/4306.png          \n",
            "  inflating: train/4307.png          \n",
            "  inflating: train/4308.png          \n",
            "  inflating: train/4309.png          \n",
            "  inflating: train/431.png           \n",
            "  inflating: train/4310.png          \n",
            "  inflating: train/4311.png          \n",
            "  inflating: train/4312.png          \n",
            "  inflating: train/4313.png          \n",
            "  inflating: train/4314.png          \n",
            "  inflating: train/4315.png          \n",
            "  inflating: train/4316.png          \n",
            "  inflating: train/4317.png          \n",
            "  inflating: train/4318.png          \n",
            "  inflating: train/4319.png          \n",
            "  inflating: train/432.png           \n",
            "  inflating: train/4320.png          \n",
            "  inflating: train/4321.png          \n",
            "  inflating: train/4322.png          \n",
            "  inflating: train/4323.png          \n",
            "  inflating: train/4324.png          \n",
            "  inflating: train/4325.png          \n",
            "  inflating: train/4326.png          \n",
            "  inflating: train/4327.png          \n",
            "  inflating: train/4328.png          \n",
            "  inflating: train/4329.png          \n",
            "  inflating: train/433.png           \n",
            "  inflating: train/4330.png          \n",
            "  inflating: train/4331.png          \n",
            "  inflating: train/4332.png          \n",
            "  inflating: train/4333.png          \n",
            "  inflating: train/4334.png          \n",
            "  inflating: train/4335.png          \n",
            "  inflating: train/4336.png          \n",
            "  inflating: train/4337.png          \n",
            "  inflating: train/4338.png          \n",
            "  inflating: train/4339.png          \n",
            "  inflating: train/434.png           \n",
            "  inflating: train/4340.png          \n",
            "  inflating: train/4341.png          \n",
            "  inflating: train/4342.png          \n",
            "  inflating: train/4343.png          \n",
            "  inflating: train/4344.png          \n",
            "  inflating: train/4345.png          \n",
            "  inflating: train/4346.png          \n",
            "  inflating: train/4347.png          \n",
            "  inflating: train/4348.png          \n",
            "  inflating: train/4349.png          \n",
            "  inflating: train/435.png           \n",
            "  inflating: train/4350.png          \n",
            "  inflating: train/4351.png          \n",
            "  inflating: train/4352.png          \n",
            "  inflating: train/4353.png          \n",
            "  inflating: train/4354.png          \n",
            "  inflating: train/4355.png          \n",
            "  inflating: train/4356.png          \n",
            "  inflating: train/4357.png          \n",
            "  inflating: train/4358.png          \n",
            "  inflating: train/4359.png          \n",
            "  inflating: train/436.png           \n",
            "  inflating: train/4360.png          \n",
            "  inflating: train/4361.png          \n",
            "  inflating: train/4362.png          \n",
            "  inflating: train/4363.png          \n",
            "  inflating: train/4364.png          \n",
            "  inflating: train/4365.png          \n",
            "  inflating: train/4366.png          \n",
            "  inflating: train/4367.png          \n",
            "  inflating: train/4368.png          \n",
            "  inflating: train/4369.png          \n",
            "  inflating: train/437.png           \n",
            "  inflating: train/4370.png          \n",
            "  inflating: train/4371.png          \n",
            "  inflating: train/4372.png          \n",
            "  inflating: train/4373.png          \n",
            "  inflating: train/4374.png          \n",
            "  inflating: train/4375.png          \n",
            "  inflating: train/4376.png          \n",
            "  inflating: train/4377.png          \n",
            "  inflating: train/4378.png          \n",
            "  inflating: train/4379.png          \n",
            "  inflating: train/438.png           \n",
            "  inflating: train/4380.png          \n",
            "  inflating: train/4381.png          \n",
            "  inflating: train/4382.png          \n",
            "  inflating: train/4383.png          \n",
            "  inflating: train/4384.png          \n",
            "  inflating: train/4385.png          \n",
            "  inflating: train/4386.png          \n",
            "  inflating: train/4387.png          \n",
            "  inflating: train/4388.png          \n",
            "  inflating: train/4389.png          \n",
            "  inflating: train/439.png           \n",
            "  inflating: train/4390.png          \n",
            "  inflating: train/4391.png          \n",
            "  inflating: train/4392.png          \n",
            "  inflating: train/4393.png          \n",
            "  inflating: train/4394.png          \n",
            "  inflating: train/4395.png          \n",
            "  inflating: train/4396.png          \n",
            "  inflating: train/4397.png          \n",
            "  inflating: train/4398.png          \n",
            "  inflating: train/4399.png          \n",
            "  inflating: train/44.png            \n",
            "  inflating: train/440.png           \n",
            "  inflating: train/4400.png          \n",
            "  inflating: train/4401.png          \n",
            "  inflating: train/4402.png          \n",
            "  inflating: train/4403.png          \n",
            "  inflating: train/4404.png          \n",
            "  inflating: train/4405.png          \n",
            "  inflating: train/4406.png          \n",
            "  inflating: train/4407.png          \n",
            "  inflating: train/4408.png          \n",
            "  inflating: train/4409.png          \n",
            "  inflating: train/441.png           \n",
            "  inflating: train/4410.png          \n",
            "  inflating: train/4411.png          \n",
            "  inflating: train/4412.png          \n",
            "  inflating: train/4413.png          \n",
            "  inflating: train/4414.png          \n",
            "  inflating: train/4415.png          \n",
            "  inflating: train/4416.png          \n",
            "  inflating: train/4417.png          \n",
            "  inflating: train/4418.png          \n",
            "  inflating: train/4419.png          \n",
            "  inflating: train/442.png           \n",
            "  inflating: train/4420.png          \n",
            "  inflating: train/4421.png          \n",
            "  inflating: train/4422.png          \n",
            "  inflating: train/4423.png          \n",
            "  inflating: train/4424.png          \n",
            "  inflating: train/4425.png          \n",
            "  inflating: train/4426.png          \n",
            "  inflating: train/4427.png          \n",
            "  inflating: train/4428.png          \n",
            "  inflating: train/4429.png          \n",
            "  inflating: train/443.png           \n",
            "  inflating: train/4430.png          \n",
            "  inflating: train/4431.png          \n",
            "  inflating: train/4432.png          \n",
            "  inflating: train/4433.png          \n",
            "  inflating: train/4434.png          \n",
            "  inflating: train/4435.png          \n",
            "  inflating: train/4436.png          \n",
            "  inflating: train/4437.png          \n",
            "  inflating: train/4438.png          \n",
            "  inflating: train/4439.png          \n",
            "  inflating: train/444.png           \n",
            "  inflating: train/4440.png          \n",
            "  inflating: train/4441.png          \n",
            "  inflating: train/4442.png          \n",
            "  inflating: train/4443.png          \n",
            "  inflating: train/4444.png          \n",
            "  inflating: train/4445.png          \n",
            "  inflating: train/4446.png          \n",
            "  inflating: train/4447.png          \n",
            "  inflating: train/4448.png          \n",
            "  inflating: train/4449.png          \n",
            "  inflating: train/445.png           \n",
            "  inflating: train/4450.png          \n",
            "  inflating: train/4451.png          \n",
            "  inflating: train/4452.png          \n",
            "  inflating: train/4453.png          \n",
            "  inflating: train/4454.png          \n",
            "  inflating: train/4455.png          \n",
            "  inflating: train/4456.png          \n",
            "  inflating: train/4457.png          \n",
            "  inflating: train/4458.png          \n",
            "  inflating: train/4459.png          \n",
            "  inflating: train/446.png           \n",
            "  inflating: train/4460.png          \n",
            "  inflating: train/4461.png          \n",
            "  inflating: train/4462.png          \n",
            "  inflating: train/4463.png          \n",
            "  inflating: train/4464.png          \n",
            "  inflating: train/4465.png          \n",
            "  inflating: train/4466.png          \n",
            "  inflating: train/4467.png          \n",
            "  inflating: train/4468.png          \n",
            "  inflating: train/4469.png          \n",
            "  inflating: train/447.png           \n",
            "  inflating: train/4470.png          \n",
            "  inflating: train/4471.png          \n",
            "  inflating: train/4472.png          \n",
            "  inflating: train/4473.png          \n",
            "  inflating: train/4474.png          \n",
            "  inflating: train/4475.png          \n",
            "  inflating: train/4476.png          \n",
            "  inflating: train/4477.png          \n",
            "  inflating: train/4478.png          \n",
            "  inflating: train/4479.png          \n",
            "  inflating: train/448.png           \n",
            "  inflating: train/4480.png          \n",
            "  inflating: train/4481.png          \n",
            "  inflating: train/4482.png          \n",
            "  inflating: train/4483.png          \n",
            "  inflating: train/4484.png          \n",
            "  inflating: train/4485.png          \n",
            "  inflating: train/4486.png          \n",
            "  inflating: train/4487.png          \n",
            "  inflating: train/4488.png          \n",
            "  inflating: train/4489.png          \n",
            "  inflating: train/449.png           \n",
            "  inflating: train/4490.png          \n",
            "  inflating: train/4491.png          \n",
            "  inflating: train/4492.png          \n",
            "  inflating: train/4493.png          \n",
            "  inflating: train/4494.png          \n",
            "  inflating: train/4495.png          \n",
            "  inflating: train/4496.png          \n",
            "  inflating: train/4497.png          \n",
            "  inflating: train/4498.png          \n",
            "  inflating: train/4499.png          \n",
            "  inflating: train/45.png            \n",
            "  inflating: train/450.png           \n",
            "  inflating: train/4500.png          \n",
            "  inflating: train/4501.png          \n",
            "  inflating: train/4502.png          \n",
            "  inflating: train/4503.png          \n",
            "  inflating: train/4504.png          \n",
            "  inflating: train/4505.png          \n",
            "  inflating: train/4506.png          \n",
            "  inflating: train/4507.png          \n",
            "  inflating: train/4508.png          \n",
            "  inflating: train/4509.png          \n",
            "  inflating: train/451.png           \n",
            "  inflating: train/4510.png          \n",
            "  inflating: train/4511.png          \n",
            "  inflating: train/4512.png          \n",
            "  inflating: train/4513.png          \n",
            "  inflating: train/4514.png          \n",
            "  inflating: train/4515.png          \n",
            "  inflating: train/4516.png          \n",
            "  inflating: train/4517.png          \n",
            "  inflating: train/4518.png          \n",
            "  inflating: train/4519.png          \n",
            "  inflating: train/452.png           \n",
            "  inflating: train/4520.png          \n",
            "  inflating: train/4521.png          \n",
            "  inflating: train/4522.png          \n",
            "  inflating: train/4523.png          \n",
            "  inflating: train/4524.png          \n",
            "  inflating: train/4525.png          \n",
            "  inflating: train/4526.png          \n",
            "  inflating: train/4527.png          \n",
            "  inflating: train/4528.png          \n",
            "  inflating: train/4529.png          \n",
            "  inflating: train/453.png           \n",
            "  inflating: train/4530.png          \n",
            "  inflating: train/4531.png          \n",
            "  inflating: train/4532.png          \n",
            "  inflating: train/4533.png          \n",
            "  inflating: train/4534.png          \n",
            "  inflating: train/4535.png          \n",
            "  inflating: train/4536.png          \n",
            "  inflating: train/4537.png          \n",
            "  inflating: train/4538.png          \n",
            "  inflating: train/4539.png          \n",
            "  inflating: train/454.png           \n",
            "  inflating: train/4540.png          \n",
            "  inflating: train/4541.png          \n",
            "  inflating: train/4542.png          \n",
            "  inflating: train/4543.png          \n",
            "  inflating: train/4544.png          \n",
            "  inflating: train/4545.png          \n",
            "  inflating: train/4546.png          \n",
            "  inflating: train/4547.png          \n",
            "  inflating: train/4548.png          \n",
            "  inflating: train/4549.png          \n",
            "  inflating: train/455.png           \n",
            "  inflating: train/4550.png          \n",
            "  inflating: train/4551.png          \n",
            "  inflating: train/4552.png          \n",
            "  inflating: train/4553.png          \n",
            "  inflating: train/4554.png          \n",
            "  inflating: train/4555.png          \n",
            "  inflating: train/4556.png          \n",
            "  inflating: train/4557.png          \n",
            "  inflating: train/4558.png          \n",
            "  inflating: train/4559.png          \n",
            "  inflating: train/456.png           \n",
            "  inflating: train/4560.png          \n",
            "  inflating: train/4561.png          \n",
            "  inflating: train/4562.png          \n",
            "  inflating: train/4563.png          \n",
            "  inflating: train/4564.png          \n",
            "  inflating: train/4565.png          \n",
            "  inflating: train/4566.png          \n",
            "  inflating: train/4567.png          \n",
            "  inflating: train/4568.png          \n",
            "  inflating: train/4569.png          \n",
            "  inflating: train/457.png           \n",
            "  inflating: train/4570.png          \n",
            "  inflating: train/4571.png          \n",
            "  inflating: train/4572.png          \n",
            "  inflating: train/4573.png          \n",
            "  inflating: train/4574.png          \n",
            "  inflating: train/4575.png          \n",
            "  inflating: train/4576.png          \n",
            "  inflating: train/4577.png          \n",
            "  inflating: train/4578.png          \n",
            "  inflating: train/4579.png          \n",
            "  inflating: train/458.png           \n",
            "  inflating: train/4580.png          \n",
            "  inflating: train/4581.png          \n",
            "  inflating: train/4582.png          \n",
            "  inflating: train/4583.png          \n",
            "  inflating: train/4584.png          \n",
            "  inflating: train/4585.png          \n",
            "  inflating: train/4586.png          \n",
            "  inflating: train/4587.png          \n",
            "  inflating: train/4588.png          \n",
            "  inflating: train/4589.png          \n",
            "  inflating: train/459.png           \n",
            "  inflating: train/4590.png          \n",
            "  inflating: train/4591.png          \n",
            "  inflating: train/4592.png          \n",
            "  inflating: train/4593.png          \n",
            "  inflating: train/4594.png          \n",
            "  inflating: train/4595.png          \n",
            "  inflating: train/4596.png          \n",
            "  inflating: train/4597.png          \n",
            "  inflating: train/4598.png          \n",
            "  inflating: train/4599.png          \n",
            "  inflating: train/46.png            \n",
            "  inflating: train/460.png           \n",
            "  inflating: train/4600.png          \n",
            "  inflating: train/4601.png          \n",
            "  inflating: train/4602.png          \n",
            "  inflating: train/4603.png          \n",
            "  inflating: train/4604.png          \n",
            "  inflating: train/4605.png          \n",
            "  inflating: train/4606.png          \n",
            "  inflating: train/4607.png          \n",
            "  inflating: train/4608.png          \n",
            "  inflating: train/4609.png          \n",
            "  inflating: train/461.png           \n",
            "  inflating: train/4610.png          \n",
            "  inflating: train/4611.png          \n",
            "  inflating: train/4612.png          \n",
            "  inflating: train/4613.png          \n",
            "  inflating: train/4614.png          \n",
            "  inflating: train/4615.png          \n",
            "  inflating: train/4616.png          \n",
            "  inflating: train/4617.png          \n",
            "  inflating: train/4618.png          \n",
            "  inflating: train/4619.png          \n",
            "  inflating: train/462.png           \n",
            "  inflating: train/4620.png          \n",
            "  inflating: train/4621.png          \n",
            "  inflating: train/4622.png          \n",
            "  inflating: train/4623.png          \n",
            "  inflating: train/4624.png          \n",
            "  inflating: train/4625.png          \n",
            "  inflating: train/4626.png          \n",
            "  inflating: train/4627.png          \n",
            "  inflating: train/4628.png          \n",
            "  inflating: train/4629.png          \n",
            "  inflating: train/463.png           \n",
            "  inflating: train/4630.png          \n",
            "  inflating: train/4631.png          \n",
            "  inflating: train/4632.png          \n",
            "  inflating: train/4633.png          \n",
            "  inflating: train/4634.png          \n",
            "  inflating: train/4635.png          \n",
            "  inflating: train/4636.png          \n",
            "  inflating: train/4637.png          \n",
            "  inflating: train/4638.png          \n",
            "  inflating: train/4639.png          \n",
            "  inflating: train/464.png           \n",
            "  inflating: train/4640.png          \n",
            "  inflating: train/4641.png          \n",
            "  inflating: train/4642.png          \n",
            "  inflating: train/4643.png          \n",
            "  inflating: train/4644.png          \n",
            "  inflating: train/4645.png          \n",
            "  inflating: train/4646.png          \n",
            "  inflating: train/4647.png          \n",
            "  inflating: train/4648.png          \n",
            "  inflating: train/4649.png          \n",
            "  inflating: train/465.png           \n",
            "  inflating: train/4650.png          \n",
            "  inflating: train/4651.png          \n",
            "  inflating: train/4652.png          \n",
            "  inflating: train/4653.png          \n",
            "  inflating: train/4654.png          \n",
            "  inflating: train/4655.png          \n",
            "  inflating: train/4656.png          \n",
            "  inflating: train/4657.png          \n",
            "  inflating: train/4658.png          \n",
            "  inflating: train/4659.png          \n",
            "  inflating: train/466.png           \n",
            "  inflating: train/4660.png          \n",
            "  inflating: train/4661.png          \n",
            "  inflating: train/4662.png          \n",
            "  inflating: train/4663.png          \n",
            "  inflating: train/4664.png          \n",
            "  inflating: train/4665.png          \n",
            "  inflating: train/4666.png          \n",
            "  inflating: train/4667.png          \n",
            "  inflating: train/4668.png          \n",
            "  inflating: train/4669.png          \n",
            "  inflating: train/467.png           \n",
            "  inflating: train/4670.png          \n",
            "  inflating: train/4671.png          \n",
            "  inflating: train/4672.png          \n",
            "  inflating: train/4673.png          \n",
            "  inflating: train/4674.png          \n",
            "  inflating: train/4675.png          \n",
            "  inflating: train/4676.png          \n",
            "  inflating: train/4677.png          \n",
            "  inflating: train/4678.png          \n",
            "  inflating: train/4679.png          \n",
            "  inflating: train/468.png           \n",
            "  inflating: train/4680.png          \n",
            "  inflating: train/4681.png          \n",
            "  inflating: train/4682.png          \n",
            "  inflating: train/4683.png          \n",
            "  inflating: train/4684.png          \n",
            "  inflating: train/4685.png          \n",
            "  inflating: train/4686.png          \n",
            "  inflating: train/4687.png          \n",
            "  inflating: train/4688.png          \n",
            "  inflating: train/4689.png          \n",
            "  inflating: train/469.png           \n",
            "  inflating: train/4690.png          \n",
            "  inflating: train/4691.png          \n",
            "  inflating: train/4692.png          \n",
            "  inflating: train/4693.png          \n",
            "  inflating: train/4694.png          \n",
            "  inflating: train/4695.png          \n",
            "  inflating: train/4696.png          \n",
            "  inflating: train/4697.png          \n",
            "  inflating: train/4698.png          \n",
            "  inflating: train/4699.png          \n",
            "  inflating: train/47.png            \n",
            "  inflating: train/470.png           \n",
            "  inflating: train/4700.png          \n",
            "  inflating: train/4701.png          \n",
            "  inflating: train/4702.png          \n",
            "  inflating: train/4703.png          \n",
            "  inflating: train/4704.png          \n",
            "  inflating: train/4705.png          \n",
            "  inflating: train/4706.png          \n",
            "  inflating: train/4707.png          \n",
            "  inflating: train/4708.png          \n",
            "  inflating: train/4709.png          \n",
            "  inflating: train/471.png           \n",
            "  inflating: train/4710.png          \n",
            "  inflating: train/4711.png          \n",
            "  inflating: train/4712.png          \n",
            "  inflating: train/4713.png          \n",
            "  inflating: train/4714.png          \n",
            "  inflating: train/4715.png          \n",
            "  inflating: train/4716.png          \n",
            "  inflating: train/4717.png          \n",
            "  inflating: train/4718.png          \n",
            "  inflating: train/4719.png          \n",
            "  inflating: train/472.png           \n",
            "  inflating: train/4720.png          \n",
            "  inflating: train/4721.png          \n",
            "  inflating: train/4722.png          \n",
            "  inflating: train/4723.png          \n",
            "  inflating: train/4724.png          \n",
            "  inflating: train/4725.png          \n",
            "  inflating: train/4726.png          \n",
            "  inflating: train/4727.png          \n",
            "  inflating: train/4728.png          \n",
            "  inflating: train/4729.png          \n",
            "  inflating: train/473.png           \n",
            "  inflating: train/4730.png          \n",
            "  inflating: train/4731.png          \n",
            "  inflating: train/4732.png          \n",
            "  inflating: train/4733.png          \n",
            "  inflating: train/4734.png          \n",
            "  inflating: train/4735.png          \n",
            "  inflating: train/4736.png          \n",
            "  inflating: train/4737.png          \n",
            "  inflating: train/4738.png          \n",
            "  inflating: train/4739.png          \n",
            "  inflating: train/474.png           \n",
            "  inflating: train/4740.png          \n",
            "  inflating: train/4741.png          \n",
            "  inflating: train/4742.png          \n",
            "  inflating: train/4743.png          \n",
            "  inflating: train/4744.png          \n",
            "  inflating: train/4745.png          \n",
            "  inflating: train/4746.png          \n",
            "  inflating: train/4747.png          \n",
            "  inflating: train/4748.png          \n",
            "  inflating: train/4749.png          \n",
            "  inflating: train/475.png           \n",
            "  inflating: train/4750.png          \n",
            "  inflating: train/4751.png          \n",
            "  inflating: train/4752.png          \n",
            "  inflating: train/4753.png          \n",
            "  inflating: train/4754.png          \n",
            "  inflating: train/4755.png          \n",
            "  inflating: train/4756.png          \n",
            "  inflating: train/4757.png          \n",
            "  inflating: train/4758.png          \n",
            "  inflating: train/4759.png          \n",
            "  inflating: train/476.png           \n",
            "  inflating: train/4760.png          \n",
            "  inflating: train/4761.png          \n",
            "  inflating: train/4762.png          \n",
            "  inflating: train/4763.png          \n",
            "  inflating: train/4764.png          \n",
            "  inflating: train/4765.png          \n",
            "  inflating: train/4766.png          \n",
            "  inflating: train/4767.png          \n",
            "  inflating: train/4768.png          \n",
            "  inflating: train/4769.png          \n",
            "  inflating: train/477.png           \n",
            "  inflating: train/4770.png          \n",
            "  inflating: train/4771.png          \n",
            "  inflating: train/4772.png          \n",
            "  inflating: train/4773.png          \n",
            "  inflating: train/4774.png          \n",
            "  inflating: train/4775.png          \n",
            "  inflating: train/4776.png          \n",
            "  inflating: train/4777.png          \n",
            "  inflating: train/4778.png          \n",
            "  inflating: train/4779.png          \n",
            "  inflating: train/478.png           \n",
            "  inflating: train/4780.png          \n",
            "  inflating: train/4781.png          \n",
            "  inflating: train/4782.png          \n",
            "  inflating: train/4783.png          \n",
            "  inflating: train/4784.png          \n",
            "  inflating: train/4785.png          \n",
            "  inflating: train/4786.png          \n",
            "  inflating: train/4787.png          \n",
            "  inflating: train/4788.png          \n",
            "  inflating: train/4789.png          \n",
            "  inflating: train/479.png           \n",
            "  inflating: train/4790.png          \n",
            "  inflating: train/4791.png          \n",
            "  inflating: train/4792.png          \n",
            "  inflating: train/4793.png          \n",
            "  inflating: train/4794.png          \n",
            "  inflating: train/4795.png          \n",
            "  inflating: train/4796.png          \n",
            "  inflating: train/4797.png          \n",
            "  inflating: train/4798.png          \n",
            "  inflating: train/4799.png          \n",
            "  inflating: train/48.png            \n",
            "  inflating: train/480.png           \n",
            "  inflating: train/4800.png          \n",
            "  inflating: train/4801.png          \n",
            "  inflating: train/4802.png          \n",
            "  inflating: train/4803.png          \n",
            "  inflating: train/4804.png          \n",
            "  inflating: train/4805.png          \n",
            "  inflating: train/4806.png          \n",
            "  inflating: train/4807.png          \n",
            "  inflating: train/4808.png          \n",
            "  inflating: train/4809.png          \n",
            "  inflating: train/481.png           \n",
            "  inflating: train/4810.png          \n",
            "  inflating: train/4811.png          \n",
            "  inflating: train/4812.png          \n",
            "  inflating: train/4813.png          \n",
            "  inflating: train/4814.png          \n",
            "  inflating: train/4815.png          \n",
            "  inflating: train/4816.png          \n",
            "  inflating: train/4817.png          \n",
            "  inflating: train/4818.png          \n",
            "  inflating: train/4819.png          \n",
            "  inflating: train/482.png           \n",
            "  inflating: train/4820.png          \n",
            "  inflating: train/4821.png          \n",
            "  inflating: train/4822.png          \n",
            "  inflating: train/4823.png          \n",
            "  inflating: train/4824.png          \n",
            "  inflating: train/4825.png          \n",
            "  inflating: train/4826.png          \n",
            "  inflating: train/4827.png          \n",
            "  inflating: train/4828.png          \n",
            "  inflating: train/4829.png          \n",
            "  inflating: train/483.png           \n",
            "  inflating: train/4830.png          \n",
            "  inflating: train/4831.png          \n",
            "  inflating: train/4832.png          \n",
            "  inflating: train/4833.png          \n",
            "  inflating: train/4834.png          \n",
            "  inflating: train/4835.png          \n",
            "  inflating: train/4836.png          \n",
            "  inflating: train/4837.png          \n",
            "  inflating: train/4838.png          \n",
            "  inflating: train/4839.png          \n",
            "  inflating: train/484.png           \n",
            "  inflating: train/4840.png          \n",
            "  inflating: train/4841.png          \n",
            "  inflating: train/4842.png          \n",
            "  inflating: train/4843.png          \n",
            "  inflating: train/4844.png          \n",
            "  inflating: train/4845.png          \n",
            "  inflating: train/4846.png          \n",
            "  inflating: train/4847.png          \n",
            "  inflating: train/4848.png          \n",
            "  inflating: train/4849.png          \n",
            "  inflating: train/485.png           \n",
            "  inflating: train/4850.png          \n",
            "  inflating: train/4851.png          \n",
            "  inflating: train/4852.png          \n",
            "  inflating: train/4853.png          \n",
            "  inflating: train/4854.png          \n",
            "  inflating: train/4855.png          \n",
            "  inflating: train/4856.png          \n",
            "  inflating: train/4857.png          \n",
            "  inflating: train/4858.png          \n",
            "  inflating: train/4859.png          \n",
            "  inflating: train/486.png           \n",
            "  inflating: train/4860.png          \n",
            "  inflating: train/4861.png          \n",
            "  inflating: train/4862.png          \n",
            "  inflating: train/4863.png          \n",
            "  inflating: train/4864.png          \n",
            "  inflating: train/4865.png          \n",
            "  inflating: train/4866.png          \n",
            "  inflating: train/4867.png          \n",
            "  inflating: train/4868.png          \n",
            "  inflating: train/4869.png          \n",
            "  inflating: train/487.png           \n",
            "  inflating: train/4870.png          \n",
            "  inflating: train/4871.png          \n",
            "  inflating: train/4872.png          \n",
            "  inflating: train/4873.png          \n",
            "  inflating: train/4874.png          \n",
            "  inflating: train/4875.png          \n",
            "  inflating: train/4876.png          \n",
            "  inflating: train/4877.png          \n",
            "  inflating: train/4878.png          \n",
            "  inflating: train/4879.png          \n",
            "  inflating: train/488.png           \n",
            "  inflating: train/4880.png          \n",
            "  inflating: train/4881.png          \n",
            "  inflating: train/4882.png          \n",
            "  inflating: train/4883.png          \n",
            "  inflating: train/4884.png          \n",
            "  inflating: train/4885.png          \n",
            "  inflating: train/4886.png          \n",
            "  inflating: train/4887.png          \n",
            "  inflating: train/4888.png          \n",
            "  inflating: train/4889.png          \n",
            "  inflating: train/489.png           \n",
            "  inflating: train/4890.png          \n",
            "  inflating: train/4891.png          \n",
            "  inflating: train/4892.png          \n",
            "  inflating: train/4893.png          \n",
            "  inflating: train/4894.png          \n",
            "  inflating: train/4895.png          \n",
            "  inflating: train/4896.png          \n",
            "  inflating: train/4897.png          \n",
            "  inflating: train/4898.png          \n",
            "  inflating: train/4899.png          \n",
            "  inflating: train/49.png            \n",
            "  inflating: train/490.png           \n",
            "  inflating: train/4900.png          \n",
            "  inflating: train/4901.png          \n",
            "  inflating: train/4902.png          \n",
            "  inflating: train/4903.png          \n",
            "  inflating: train/4904.png          \n",
            "  inflating: train/4905.png          \n",
            "  inflating: train/4906.png          \n",
            "  inflating: train/4907.png          \n",
            "  inflating: train/4908.png          \n",
            "  inflating: train/4909.png          \n",
            "  inflating: train/491.png           \n",
            "  inflating: train/4910.png          \n",
            "  inflating: train/4911.png          \n",
            "  inflating: train/4912.png          \n",
            "  inflating: train/4913.png          \n",
            "  inflating: train/4914.png          \n",
            "  inflating: train/4915.png          \n",
            "  inflating: train/4916.png          \n",
            "  inflating: train/4917.png          \n",
            "  inflating: train/4918.png          \n",
            "  inflating: train/4919.png          \n",
            "  inflating: train/492.png           \n",
            "  inflating: train/4920.png          \n",
            "  inflating: train/4921.png          \n",
            "  inflating: train/4922.png          \n",
            "  inflating: train/4923.png          \n",
            "  inflating: train/4924.png          \n",
            "  inflating: train/4925.png          \n",
            "  inflating: train/4926.png          \n",
            "  inflating: train/4927.png          \n",
            "  inflating: train/4928.png          \n",
            "  inflating: train/4929.png          \n",
            "  inflating: train/493.png           \n",
            "  inflating: train/4930.png          \n",
            "  inflating: train/4931.png          \n",
            "  inflating: train/4932.png          \n",
            "  inflating: train/4933.png          \n",
            "  inflating: train/4934.png          \n",
            "  inflating: train/4935.png          \n",
            "  inflating: train/4936.png          \n",
            "  inflating: train/4937.png          \n",
            "  inflating: train/4938.png          \n",
            "  inflating: train/4939.png          \n",
            "  inflating: train/494.png           \n",
            "  inflating: train/4940.png          \n",
            "  inflating: train/4941.png          \n",
            "  inflating: train/4942.png          \n",
            "  inflating: train/4943.png          \n",
            "  inflating: train/4944.png          \n",
            "  inflating: train/4945.png          \n",
            "  inflating: train/4946.png          \n",
            "  inflating: train/4947.png          \n",
            "  inflating: train/4948.png          \n",
            "  inflating: train/4949.png          \n",
            "  inflating: train/495.png           \n",
            "  inflating: train/4950.png          \n",
            "  inflating: train/4951.png          \n",
            "  inflating: train/4952.png          \n",
            "  inflating: train/4953.png          \n",
            "  inflating: train/4954.png          \n",
            "  inflating: train/4955.png          \n",
            "  inflating: train/4956.png          \n",
            "  inflating: train/4957.png          \n",
            "  inflating: train/4958.png          \n",
            "  inflating: train/4959.png          \n",
            "  inflating: train/496.png           \n",
            "  inflating: train/4960.png          \n",
            "  inflating: train/4961.png          \n",
            "  inflating: train/4962.png          \n",
            "  inflating: train/4963.png          \n",
            "  inflating: train/4964.png          \n",
            "  inflating: train/4965.png          \n",
            "  inflating: train/4966.png          \n",
            "  inflating: train/4967.png          \n",
            "  inflating: train/4968.png          \n",
            "  inflating: train/4969.png          \n",
            "  inflating: train/497.png           \n",
            "  inflating: train/4970.png          \n",
            "  inflating: train/4971.png          \n",
            "  inflating: train/4972.png          \n",
            "  inflating: train/4973.png          \n",
            "  inflating: train/4974.png          \n",
            "  inflating: train/4975.png          \n",
            "  inflating: train/4976.png          \n",
            "  inflating: train/4977.png          \n",
            "  inflating: train/4978.png          \n",
            "  inflating: train/4979.png          \n",
            "  inflating: train/498.png           \n",
            "  inflating: train/4980.png          \n",
            "  inflating: train/4981.png          \n",
            "  inflating: train/4982.png          \n",
            "  inflating: train/4983.png          \n",
            "  inflating: train/4984.png          \n",
            "  inflating: train/4985.png          \n",
            "  inflating: train/4986.png          \n",
            "  inflating: train/4987.png          \n",
            "  inflating: train/4988.png          \n",
            "  inflating: train/4989.png          \n",
            "  inflating: train/499.png           \n",
            "  inflating: train/4990.png          \n",
            "  inflating: train/4991.png          \n",
            "  inflating: train/4992.png          \n",
            "  inflating: train/4993.png          \n",
            "  inflating: train/4994.png          \n",
            "  inflating: train/4995.png          \n",
            "  inflating: train/4996.png          \n",
            "  inflating: train/4997.png          \n",
            "  inflating: train/4998.png          \n",
            "  inflating: train/4999.png          \n",
            "  inflating: train/5.png             \n",
            "  inflating: train/50.png            \n",
            "  inflating: train/500.png           \n",
            "  inflating: train/5000.png          \n",
            "  inflating: train/5001.png          \n",
            "  inflating: train/5002.png          \n",
            "  inflating: train/5003.png          \n",
            "  inflating: train/5004.png          \n",
            "  inflating: train/5005.png          \n",
            "  inflating: train/5006.png          \n",
            "  inflating: train/5007.png          \n",
            "  inflating: train/5008.png          \n",
            "  inflating: train/5009.png          \n",
            "  inflating: train/501.png           \n",
            "  inflating: train/5010.png          \n",
            "  inflating: train/5011.png          \n",
            "  inflating: train/5012.png          \n",
            "  inflating: train/5013.png          \n",
            "  inflating: train/5014.png          \n",
            "  inflating: train/5015.png          \n",
            "  inflating: train/5016.png          \n",
            "  inflating: train/5017.png          \n",
            "  inflating: train/5018.png          \n",
            "  inflating: train/5019.png          \n",
            "  inflating: train/502.png           \n",
            "  inflating: train/5020.png          \n",
            "  inflating: train/5021.png          \n",
            "  inflating: train/5022.png          \n",
            "  inflating: train/5023.png          \n",
            "  inflating: train/5024.png          \n",
            "  inflating: train/5025.png          \n",
            "  inflating: train/5026.png          \n",
            "  inflating: train/5027.png          \n",
            "  inflating: train/5028.png          \n",
            "  inflating: train/5029.png          \n",
            "  inflating: train/503.png           \n",
            "  inflating: train/5030.png          \n",
            "  inflating: train/5031.png          \n",
            "  inflating: train/5032.png          \n",
            "  inflating: train/5033.png          \n",
            "  inflating: train/5034.png          \n",
            "  inflating: train/5035.png          \n",
            "  inflating: train/5036.png          \n",
            "  inflating: train/5037.png          \n",
            "  inflating: train/5038.png          \n",
            "  inflating: train/5039.png          \n",
            "  inflating: train/504.png           \n",
            "  inflating: train/5040.png          \n",
            "  inflating: train/5041.png          \n",
            "  inflating: train/5042.png          \n",
            "  inflating: train/5043.png          \n",
            "  inflating: train/5044.png          \n",
            "  inflating: train/5045.png          \n",
            "  inflating: train/5046.png          \n",
            "  inflating: train/5047.png          \n",
            "  inflating: train/5048.png          \n",
            "  inflating: train/5049.png          \n",
            "  inflating: train/505.png           \n",
            "  inflating: train/5050.png          \n",
            "  inflating: train/5051.png          \n",
            "  inflating: train/5052.png          \n",
            "  inflating: train/5053.png          \n",
            "  inflating: train/5054.png          \n",
            "  inflating: train/5055.png          \n",
            "  inflating: train/5056.png          \n",
            "  inflating: train/5057.png          \n",
            "  inflating: train/5058.png          \n",
            "  inflating: train/5059.png          \n",
            "  inflating: train/506.png           \n",
            "  inflating: train/5060.png          \n",
            "  inflating: train/5061.png          \n",
            "  inflating: train/5062.png          \n",
            "  inflating: train/5063.png          \n",
            "  inflating: train/5064.png          \n",
            "  inflating: train/5065.png          \n",
            "  inflating: train/5066.png          \n",
            "  inflating: train/5067.png          \n",
            "  inflating: train/5068.png          \n",
            "  inflating: train/5069.png          \n",
            "  inflating: train/507.png           \n",
            "  inflating: train/5070.png          \n",
            "  inflating: train/5071.png          \n",
            "  inflating: train/5072.png          \n",
            "  inflating: train/5073.png          \n",
            "  inflating: train/5074.png          \n",
            "  inflating: train/5075.png          \n",
            "  inflating: train/5076.png          \n",
            "  inflating: train/5077.png          \n",
            "  inflating: train/5078.png          \n",
            "  inflating: train/5079.png          \n",
            "  inflating: train/508.png           \n",
            "  inflating: train/5080.png          \n",
            "  inflating: train/5081.png          \n",
            "  inflating: train/5082.png          \n",
            "  inflating: train/5083.png          \n",
            "  inflating: train/5084.png          \n",
            "  inflating: train/5085.png          \n",
            "  inflating: train/5086.png          \n",
            "  inflating: train/5087.png          \n",
            "  inflating: train/5088.png          \n",
            "  inflating: train/5089.png          \n",
            "  inflating: train/509.png           \n",
            "  inflating: train/5090.png          \n",
            "  inflating: train/5091.png          \n",
            "  inflating: train/5092.png          \n",
            "  inflating: train/5093.png          \n",
            "  inflating: train/5094.png          \n",
            "  inflating: train/5095.png          \n",
            "  inflating: train/5096.png          \n",
            "  inflating: train/5097.png          \n",
            "  inflating: train/5098.png          \n",
            "  inflating: train/5099.png          \n",
            "  inflating: train/51.png            \n",
            "  inflating: train/510.png           \n",
            "  inflating: train/5100.png          \n",
            "  inflating: train/5101.png          \n",
            "  inflating: train/5102.png          \n",
            "  inflating: train/5103.png          \n",
            "  inflating: train/5104.png          \n",
            "  inflating: train/5105.png          \n",
            "  inflating: train/5106.png          \n",
            "  inflating: train/5107.png          \n",
            "  inflating: train/5108.png          \n",
            "  inflating: train/5109.png          \n",
            "  inflating: train/511.png           \n",
            "  inflating: train/5110.png          \n",
            "  inflating: train/5111.png          \n",
            "  inflating: train/5112.png          \n",
            "  inflating: train/5113.png          \n",
            "  inflating: train/5114.png          \n",
            "  inflating: train/5115.png          \n",
            "  inflating: train/5116.png          \n",
            "  inflating: train/5117.png          \n",
            "  inflating: train/5118.png          \n",
            "  inflating: train/5119.png          \n",
            "  inflating: train/512.png           \n",
            "  inflating: train/5120.png          \n",
            "  inflating: train/5121.png          \n",
            "  inflating: train/5122.png          \n",
            "  inflating: train/5123.png          \n",
            "  inflating: train/5124.png          \n",
            "  inflating: train/5125.png          \n",
            "  inflating: train/5126.png          \n",
            "  inflating: train/5127.png          \n",
            "  inflating: train/5128.png          \n",
            "  inflating: train/5129.png          \n",
            "  inflating: train/513.png           \n",
            "  inflating: train/5130.png          \n",
            "  inflating: train/5131.png          \n",
            "  inflating: train/5132.png          \n",
            "  inflating: train/5133.png          \n",
            "  inflating: train/5134.png          \n",
            "  inflating: train/5135.png          \n",
            "  inflating: train/5136.png          \n",
            "  inflating: train/5137.png          \n",
            "  inflating: train/5138.png          \n",
            "  inflating: train/5139.png          \n",
            "  inflating: train/514.png           \n",
            "  inflating: train/5140.png          \n",
            "  inflating: train/5141.png          \n",
            "  inflating: train/5142.png          \n",
            "  inflating: train/5143.png          \n",
            "  inflating: train/5144.png          \n",
            "  inflating: train/5145.png          \n",
            "  inflating: train/5146.png          \n",
            "  inflating: train/5147.png          \n",
            "  inflating: train/5148.png          \n",
            "  inflating: train/5149.png          \n",
            "  inflating: train/515.png           \n",
            "  inflating: train/5150.png          \n",
            "  inflating: train/5151.png          \n",
            "  inflating: train/5152.png          \n",
            "  inflating: train/5153.png          \n",
            "  inflating: train/5154.png          \n",
            "  inflating: train/5155.png          \n",
            "  inflating: train/5156.png          \n",
            "  inflating: train/5157.png          \n",
            "  inflating: train/5158.png          \n",
            "  inflating: train/5159.png          \n",
            "  inflating: train/516.png           \n",
            "  inflating: train/5160.png          \n",
            "  inflating: train/5161.png          \n",
            "  inflating: train/5162.png          \n",
            "  inflating: train/5163.png          \n",
            "  inflating: train/5164.png          \n",
            "  inflating: train/5165.png          \n",
            "  inflating: train/5166.png          \n",
            "  inflating: train/5167.png          \n",
            "  inflating: train/5168.png          \n",
            "  inflating: train/5169.png          \n",
            "  inflating: train/517.png           \n",
            "  inflating: train/5170.png          \n",
            "  inflating: train/5171.png          \n",
            "  inflating: train/5172.png          \n",
            "  inflating: train/5173.png          \n",
            "  inflating: train/5174.png          \n",
            "  inflating: train/5175.png          \n",
            "  inflating: train/5176.png          \n",
            "  inflating: train/5177.png          \n",
            "  inflating: train/5178.png          \n",
            "  inflating: train/5179.png          \n",
            "  inflating: train/518.png           \n",
            "  inflating: train/5180.png          \n",
            "  inflating: train/5181.png          \n",
            "  inflating: train/5182.png          \n",
            "  inflating: train/5183.png          \n",
            "  inflating: train/5184.png          \n",
            "  inflating: train/5185.png          \n",
            "  inflating: train/5186.png          \n",
            "  inflating: train/5187.png          \n",
            "  inflating: train/5188.png          \n",
            "  inflating: train/5189.png          \n",
            "  inflating: train/519.png           \n",
            "  inflating: train/5190.png          \n",
            "  inflating: train/5191.png          \n",
            "  inflating: train/5192.png          \n",
            "  inflating: train/5193.png          \n",
            "  inflating: train/5194.png          \n",
            "  inflating: train/5195.png          \n",
            "  inflating: train/5196.png          \n",
            "  inflating: train/5197.png          \n",
            "  inflating: train/5198.png          \n",
            "  inflating: train/5199.png          \n",
            "  inflating: train/52.png            \n",
            "  inflating: train/520.png           \n",
            "  inflating: train/5200.png          \n",
            "  inflating: train/5201.png          \n",
            "  inflating: train/5202.png          \n",
            "  inflating: train/5203.png          \n",
            "  inflating: train/5204.png          \n",
            "  inflating: train/5205.png          \n",
            "  inflating: train/5206.png          \n",
            "  inflating: train/5207.png          \n",
            "  inflating: train/5208.png          \n",
            "  inflating: train/5209.png          \n",
            "  inflating: train/521.png           \n",
            "  inflating: train/5210.png          \n",
            "  inflating: train/5211.png          \n",
            "  inflating: train/5212.png          \n",
            "  inflating: train/5213.png          \n",
            "  inflating: train/5214.png          \n",
            "  inflating: train/5215.png          \n",
            "  inflating: train/5216.png          \n",
            "  inflating: train/5217.png          \n",
            "  inflating: train/5218.png          \n",
            "  inflating: train/5219.png          \n",
            "  inflating: train/522.png           \n",
            "  inflating: train/5220.png          \n",
            "  inflating: train/5221.png          \n",
            "  inflating: train/5222.png          \n",
            "  inflating: train/5223.png          \n",
            "  inflating: train/5224.png          \n",
            "  inflating: train/5225.png          \n",
            "  inflating: train/5226.png          \n",
            "  inflating: train/5227.png          \n",
            "  inflating: train/5228.png          \n",
            "  inflating: train/5229.png          \n",
            "  inflating: train/523.png           \n",
            "  inflating: train/5230.png          \n",
            "  inflating: train/5231.png          \n",
            "  inflating: train/5232.png          \n",
            "  inflating: train/5233.png          \n",
            "  inflating: train/5234.png          \n",
            "  inflating: train/5235.png          \n",
            "  inflating: train/5236.png          \n",
            "  inflating: train/5237.png          \n",
            "  inflating: train/5238.png          \n",
            "  inflating: train/5239.png          \n",
            "  inflating: train/524.png           \n",
            "  inflating: train/5240.png          \n",
            "  inflating: train/5241.png          \n",
            "  inflating: train/5242.png          \n",
            "  inflating: train/5243.png          \n",
            "  inflating: train/5244.png          \n",
            "  inflating: train/5245.png          \n",
            "  inflating: train/5246.png          \n",
            "  inflating: train/5247.png          \n",
            "  inflating: train/5248.png          \n",
            "  inflating: train/5249.png          \n",
            "  inflating: train/525.png           \n",
            "  inflating: train/5250.png          \n",
            "  inflating: train/5251.png          \n",
            "  inflating: train/5252.png          \n",
            "  inflating: train/5253.png          \n",
            "  inflating: train/5254.png          \n",
            "  inflating: train/5255.png          \n",
            "  inflating: train/5256.png          \n",
            "  inflating: train/5257.png          \n",
            "  inflating: train/5258.png          \n",
            "  inflating: train/5259.png          \n",
            "  inflating: train/526.png           \n",
            "  inflating: train/5260.png          \n",
            "  inflating: train/5261.png          \n",
            "  inflating: train/5262.png          \n",
            "  inflating: train/5263.png          \n",
            "  inflating: train/5264.png          \n",
            "  inflating: train/5265.png          \n",
            "  inflating: train/5266.png          \n",
            "  inflating: train/5267.png          \n",
            "  inflating: train/5268.png          \n",
            "  inflating: train/5269.png          \n",
            "  inflating: train/527.png           \n",
            "  inflating: train/5270.png          \n",
            "  inflating: train/5271.png          \n",
            "  inflating: train/5272.png          \n",
            "  inflating: train/5273.png          \n",
            "  inflating: train/5274.png          \n",
            "  inflating: train/5275.png          \n",
            "  inflating: train/5276.png          \n",
            "  inflating: train/5277.png          \n",
            "  inflating: train/5278.png          \n",
            "  inflating: train/5279.png          \n",
            "  inflating: train/528.png           \n",
            "  inflating: train/5280.png          \n",
            "  inflating: train/5281.png          \n",
            "  inflating: train/5282.png          \n",
            "  inflating: train/5283.png          \n",
            "  inflating: train/5284.png          \n",
            "  inflating: train/5285.png          \n",
            "  inflating: train/5286.png          \n",
            "  inflating: train/5287.png          \n",
            "  inflating: train/5288.png          \n",
            "  inflating: train/5289.png          \n",
            "  inflating: train/529.png           \n",
            "  inflating: train/5290.png          \n",
            "  inflating: train/5291.png          \n",
            "  inflating: train/5292.png          \n",
            "  inflating: train/5293.png          \n",
            "  inflating: train/5294.png          \n",
            "  inflating: train/5295.png          \n",
            "  inflating: train/5296.png          \n",
            "  inflating: train/5297.png          \n",
            "  inflating: train/5298.png          \n",
            "  inflating: train/5299.png          \n",
            "  inflating: train/53.png            \n",
            "  inflating: train/530.png           \n",
            "  inflating: train/5300.png          \n",
            "  inflating: train/5301.png          \n",
            "  inflating: train/5302.png          \n",
            "  inflating: train/5303.png          \n",
            "  inflating: train/5304.png          \n",
            "  inflating: train/5305.png          \n",
            "  inflating: train/5306.png          \n",
            "  inflating: train/5307.png          \n",
            "  inflating: train/5308.png          \n",
            "  inflating: train/5309.png          \n",
            "  inflating: train/531.png           \n",
            "  inflating: train/5310.png          \n",
            "  inflating: train/5311.png          \n",
            "  inflating: train/5312.png          \n",
            "  inflating: train/5313.png          \n",
            "  inflating: train/5314.png          \n",
            "  inflating: train/5315.png          \n",
            "  inflating: train/5316.png          \n",
            "  inflating: train/5317.png          \n",
            "  inflating: train/5318.png          \n",
            "  inflating: train/5319.png          \n",
            "  inflating: train/532.png           \n",
            "  inflating: train/5320.png          \n",
            "  inflating: train/5321.png          \n",
            "  inflating: train/5322.png          \n",
            "  inflating: train/5323.png          \n",
            "  inflating: train/5324.png          \n",
            "  inflating: train/5325.png          \n",
            "  inflating: train/5326.png          \n",
            "  inflating: train/5327.png          \n",
            "  inflating: train/5328.png          \n",
            "  inflating: train/5329.png          \n",
            "  inflating: train/533.png           \n",
            "  inflating: train/5330.png          \n",
            "  inflating: train/5331.png          \n",
            "  inflating: train/5332.png          \n",
            "  inflating: train/5333.png          \n",
            "  inflating: train/5334.png          \n",
            "  inflating: train/5335.png          \n",
            "  inflating: train/5336.png          \n",
            "  inflating: train/5337.png          \n",
            "  inflating: train/5338.png          \n",
            "  inflating: train/5339.png          \n",
            "  inflating: train/534.png           \n",
            "  inflating: train/5340.png          \n",
            "  inflating: train/5341.png          \n",
            "  inflating: train/5342.png          \n",
            "  inflating: train/5343.png          \n",
            "  inflating: train/5344.png          \n",
            "  inflating: train/5345.png          \n",
            "  inflating: train/5346.png          \n",
            "  inflating: train/5347.png          \n",
            "  inflating: train/5348.png          \n",
            "  inflating: train/5349.png          \n",
            "  inflating: train/535.png           \n",
            "  inflating: train/5350.png          \n",
            "  inflating: train/5351.png          \n",
            "  inflating: train/5352.png          \n",
            "  inflating: train/5353.png          \n",
            "  inflating: train/5354.png          \n",
            "  inflating: train/5355.png          \n",
            "  inflating: train/5356.png          \n",
            "  inflating: train/5357.png          \n",
            "  inflating: train/5358.png          \n",
            "  inflating: train/5359.png          \n",
            "  inflating: train/536.png           \n",
            "  inflating: train/5360.png          \n",
            "  inflating: train/5361.png          \n",
            "  inflating: train/5362.png          \n",
            "  inflating: train/5363.png          \n",
            "  inflating: train/5364.png          \n",
            "  inflating: train/5365.png          \n",
            "  inflating: train/5366.png          \n",
            "  inflating: train/5367.png          \n",
            "  inflating: train/5368.png          \n",
            "  inflating: train/5369.png          \n",
            "  inflating: train/537.png           \n",
            "  inflating: train/5370.png          \n",
            "  inflating: train/5371.png          \n",
            "  inflating: train/5372.png          \n",
            "  inflating: train/5373.png          \n",
            "  inflating: train/5374.png          \n",
            "  inflating: train/5375.png          \n",
            "  inflating: train/5376.png          \n",
            "  inflating: train/5377.png          \n",
            "  inflating: train/5378.png          \n",
            "  inflating: train/5379.png          \n",
            "  inflating: train/538.png           \n",
            "  inflating: train/5380.png          \n",
            "  inflating: train/5381.png          \n",
            "  inflating: train/5382.png          \n",
            "  inflating: train/5383.png          \n",
            "  inflating: train/5384.png          \n",
            "  inflating: train/5385.png          \n",
            "  inflating: train/5386.png          \n",
            "  inflating: train/5387.png          \n",
            "  inflating: train/5388.png          \n",
            "  inflating: train/5389.png          \n",
            "  inflating: train/539.png           \n",
            "  inflating: train/5390.png          \n",
            "  inflating: train/5391.png          \n",
            "  inflating: train/5392.png          \n",
            "  inflating: train/5393.png          \n",
            "  inflating: train/5394.png          \n",
            "  inflating: train/5395.png          \n",
            "  inflating: train/5396.png          \n",
            "  inflating: train/5397.png          \n",
            "  inflating: train/5398.png          \n",
            "  inflating: train/5399.png          \n",
            "  inflating: train/54.png            \n",
            "  inflating: train/540.png           \n",
            "  inflating: train/5400.png          \n",
            "  inflating: train/5401.png          \n",
            "  inflating: train/5402.png          \n",
            "  inflating: train/5403.png          \n",
            "  inflating: train/5404.png          \n",
            "  inflating: train/5405.png          \n",
            "  inflating: train/5406.png          \n",
            "  inflating: train/5407.png          \n",
            "  inflating: train/5408.png          \n",
            "  inflating: train/5409.png          \n",
            "  inflating: train/541.png           \n",
            "  inflating: train/5410.png          \n",
            "  inflating: train/5411.png          \n",
            "  inflating: train/5412.png          \n",
            "  inflating: train/5413.png          \n",
            "  inflating: train/5414.png          \n",
            "  inflating: train/5415.png          \n",
            "  inflating: train/5416.png          \n",
            "  inflating: train/5417.png          \n",
            "  inflating: train/5418.png          \n",
            "  inflating: train/5419.png          \n",
            "  inflating: train/542.png           \n",
            "  inflating: train/5420.png          \n",
            "  inflating: train/5421.png          \n",
            "  inflating: train/5422.png          \n",
            "  inflating: train/5423.png          \n",
            "  inflating: train/5424.png          \n",
            "  inflating: train/5425.png          \n",
            "  inflating: train/5426.png          \n",
            "  inflating: train/5427.png          \n",
            "  inflating: train/5428.png          \n",
            "  inflating: train/5429.png          \n",
            "  inflating: train/543.png           \n",
            "  inflating: train/5430.png          \n",
            "  inflating: train/5431.png          \n",
            "  inflating: train/5432.png          \n",
            "  inflating: train/5433.png          \n",
            "  inflating: train/5434.png          \n",
            "  inflating: train/5435.png          \n",
            "  inflating: train/5436.png          \n",
            "  inflating: train/5437.png          \n",
            "  inflating: train/5438.png          \n",
            "  inflating: train/5439.png          \n",
            "  inflating: train/544.png           \n",
            "  inflating: train/5440.png          \n",
            "  inflating: train/5441.png          \n",
            "  inflating: train/5442.png          \n",
            "  inflating: train/5443.png          \n",
            "  inflating: train/5444.png          \n",
            "  inflating: train/5445.png          \n",
            "  inflating: train/5446.png          \n",
            "  inflating: train/5447.png          \n",
            "  inflating: train/5448.png          \n",
            "  inflating: train/5449.png          \n",
            "  inflating: train/545.png           \n",
            "  inflating: train/5450.png          \n",
            "  inflating: train/5451.png          \n",
            "  inflating: train/5452.png          \n",
            "  inflating: train/5453.png          \n",
            "  inflating: train/5454.png          \n",
            "  inflating: train/5455.png          \n",
            "  inflating: train/5456.png          \n",
            "  inflating: train/5457.png          \n",
            "  inflating: train/5458.png          \n",
            "  inflating: train/5459.png          \n",
            "  inflating: train/546.png           \n",
            "  inflating: train/5460.png          \n",
            "  inflating: train/5461.png          \n",
            "  inflating: train/5462.png          \n",
            "  inflating: train/5463.png          \n",
            "  inflating: train/5464.png          \n",
            "  inflating: train/5465.png          \n",
            "  inflating: train/5466.png          \n",
            "  inflating: train/5467.png          \n",
            "  inflating: train/5468.png          \n",
            "  inflating: train/5469.png          \n",
            "  inflating: train/547.png           \n",
            "  inflating: train/5470.png          \n",
            "  inflating: train/5471.png          \n",
            "  inflating: train/5472.png          \n",
            "  inflating: train/5473.png          \n",
            "  inflating: train/5474.png          \n",
            "  inflating: train/5475.png          \n",
            "  inflating: train/5476.png          \n",
            "  inflating: train/5477.png          \n",
            "  inflating: train/5478.png          \n",
            "  inflating: train/5479.png          \n",
            "  inflating: train/548.png           \n",
            "  inflating: train/5480.png          \n",
            "  inflating: train/5481.png          \n",
            "  inflating: train/5482.png          \n",
            "  inflating: train/5483.png          \n",
            "  inflating: train/5484.png          \n",
            "  inflating: train/5485.png          \n",
            "  inflating: train/5486.png          \n",
            "  inflating: train/5487.png          \n",
            "  inflating: train/5488.png          \n",
            "  inflating: train/5489.png          \n",
            "  inflating: train/549.png           \n",
            "  inflating: train/5490.png          \n",
            "  inflating: train/5491.png          \n",
            "  inflating: train/5492.png          \n",
            "  inflating: train/5493.png          \n",
            "  inflating: train/5494.png          \n",
            "  inflating: train/5495.png          \n",
            "  inflating: train/5496.png          \n",
            "  inflating: train/5497.png          \n",
            "  inflating: train/5498.png          \n",
            "  inflating: train/5499.png          \n",
            "  inflating: train/55.png            \n",
            "  inflating: train/550.png           \n",
            "  inflating: train/5500.png          \n",
            "  inflating: train/5501.png          \n",
            "  inflating: train/5502.png          \n",
            "  inflating: train/5503.png          \n",
            "  inflating: train/5504.png          \n",
            "  inflating: train/5505.png          \n",
            "  inflating: train/5506.png          \n",
            "  inflating: train/5507.png          \n",
            "  inflating: train/5508.png          \n",
            "  inflating: train/5509.png          \n",
            "  inflating: train/551.png           \n",
            "  inflating: train/5510.png          \n",
            "  inflating: train/5511.png          \n",
            "  inflating: train/5512.png          \n",
            "  inflating: train/5513.png          \n",
            "  inflating: train/5514.png          \n",
            "  inflating: train/5515.png          \n",
            "  inflating: train/5516.png          \n",
            "  inflating: train/5517.png          \n",
            "  inflating: train/5518.png          \n",
            "  inflating: train/5519.png          \n",
            "  inflating: train/552.png           \n",
            "  inflating: train/5520.png          \n",
            "  inflating: train/5521.png          \n",
            "  inflating: train/5522.png          \n",
            "  inflating: train/5523.png          \n",
            "  inflating: train/5524.png          \n",
            "  inflating: train/5525.png          \n",
            "  inflating: train/5526.png          \n",
            "  inflating: train/5527.png          \n",
            "  inflating: train/5528.png          \n",
            "  inflating: train/5529.png          \n",
            "  inflating: train/553.png           \n",
            "  inflating: train/5530.png          \n",
            "  inflating: train/5531.png          \n",
            "  inflating: train/5532.png          \n",
            "  inflating: train/5533.png          \n",
            "  inflating: train/5534.png          \n",
            "  inflating: train/5535.png          \n",
            "  inflating: train/5536.png          \n",
            "  inflating: train/5537.png          \n",
            "  inflating: train/5538.png          \n",
            "  inflating: train/5539.png          \n",
            "  inflating: train/554.png           \n",
            "  inflating: train/5540.png          \n",
            "  inflating: train/5541.png          \n",
            "  inflating: train/5542.png          \n",
            "  inflating: train/5543.png          \n",
            "  inflating: train/5544.png          \n",
            "  inflating: train/5545.png          \n",
            "  inflating: train/5546.png          \n",
            "  inflating: train/5547.png          \n",
            "  inflating: train/5548.png          \n",
            "  inflating: train/5549.png          \n",
            "  inflating: train/555.png           \n",
            "  inflating: train/5550.png          \n",
            "  inflating: train/5551.png          \n",
            "  inflating: train/5552.png          \n",
            "  inflating: train/5553.png          \n",
            "  inflating: train/5554.png          \n",
            "  inflating: train/5555.png          \n",
            "  inflating: train/5556.png          \n",
            "  inflating: train/5557.png          \n",
            "  inflating: train/5558.png          \n",
            "  inflating: train/5559.png          \n",
            "  inflating: train/556.png           \n",
            "  inflating: train/5560.png          \n",
            "  inflating: train/5561.png          \n",
            "  inflating: train/5562.png          \n",
            "  inflating: train/5563.png          \n",
            "  inflating: train/5564.png          \n",
            "  inflating: train/5565.png          \n",
            "  inflating: train/5566.png          \n",
            "  inflating: train/5567.png          \n",
            "  inflating: train/5568.png          \n",
            "  inflating: train/5569.png          \n",
            "  inflating: train/557.png           \n",
            "  inflating: train/5570.png          \n",
            "  inflating: train/5571.png          \n",
            "  inflating: train/5572.png          \n",
            "  inflating: train/5573.png          \n",
            "  inflating: train/5574.png          \n",
            "  inflating: train/5575.png          \n",
            "  inflating: train/5576.png          \n",
            "  inflating: train/5577.png          \n",
            "  inflating: train/5578.png          \n",
            "  inflating: train/5579.png          \n",
            "  inflating: train/558.png           \n",
            "  inflating: train/5580.png          \n",
            "  inflating: train/5581.png          \n",
            "  inflating: train/5582.png          \n",
            "  inflating: train/5583.png          \n",
            "  inflating: train/5584.png          \n",
            "  inflating: train/5585.png          \n",
            "  inflating: train/5586.png          \n",
            "  inflating: train/5587.png          \n",
            "  inflating: train/5588.png          \n",
            "  inflating: train/5589.png          \n",
            "  inflating: train/559.png           \n",
            "  inflating: train/5590.png          \n",
            "  inflating: train/5591.png          \n",
            "  inflating: train/5592.png          \n",
            "  inflating: train/5593.png          \n",
            "  inflating: train/5594.png          \n",
            "  inflating: train/5595.png          \n",
            "  inflating: train/5596.png          \n",
            "  inflating: train/5597.png          \n",
            "  inflating: train/5598.png          \n",
            "  inflating: train/5599.png          \n",
            "  inflating: train/56.png            \n",
            "  inflating: train/560.png           \n",
            "  inflating: train/5600.png          \n",
            "  inflating: train/5601.png          \n",
            "  inflating: train/5602.png          \n",
            "  inflating: train/5603.png          \n",
            "  inflating: train/5604.png          \n",
            "  inflating: train/5605.png          \n",
            "  inflating: train/5606.png          \n",
            "  inflating: train/5607.png          \n",
            "  inflating: train/5608.png          \n",
            "  inflating: train/5609.png          \n",
            "  inflating: train/561.png           \n",
            "  inflating: train/5610.png          \n",
            "  inflating: train/5611.png          \n",
            "  inflating: train/5612.png          \n",
            "  inflating: train/5613.png          \n",
            "  inflating: train/5614.png          \n",
            "  inflating: train/5615.png          \n",
            "  inflating: train/5616.png          \n",
            "  inflating: train/5617.png          \n",
            "  inflating: train/5618.png          \n",
            "  inflating: train/5619.png          \n",
            "  inflating: train/562.png           \n",
            "  inflating: train/5620.png          \n",
            "  inflating: train/5621.png          \n",
            "  inflating: train/5622.png          \n",
            "  inflating: train/5623.png          \n",
            "  inflating: train/5624.png          \n",
            "  inflating: train/5625.png          \n",
            "  inflating: train/5626.png          \n",
            "  inflating: train/5627.png          \n",
            "  inflating: train/5628.png          \n",
            "  inflating: train/5629.png          \n",
            "  inflating: train/563.png           \n",
            "  inflating: train/5630.png          \n",
            "  inflating: train/5631.png          \n",
            "  inflating: train/5632.png          \n",
            "  inflating: train/5633.png          \n",
            "  inflating: train/5634.png          \n",
            "  inflating: train/5635.png          \n",
            "  inflating: train/5636.png          \n",
            "  inflating: train/5637.png          \n",
            "  inflating: train/5638.png          \n",
            "  inflating: train/5639.png          \n",
            "  inflating: train/564.png           \n",
            "  inflating: train/5640.png          \n",
            "  inflating: train/5641.png          \n",
            "  inflating: train/5642.png          \n",
            "  inflating: train/5643.png          \n",
            "  inflating: train/5644.png          \n",
            "  inflating: train/5645.png          \n",
            "  inflating: train/5646.png          \n",
            "  inflating: train/5647.png          \n",
            "  inflating: train/5648.png          \n",
            "  inflating: train/5649.png          \n",
            "  inflating: train/565.png           \n",
            "  inflating: train/5650.png          \n",
            "  inflating: train/5651.png          \n",
            "  inflating: train/5652.png          \n",
            "  inflating: train/5653.png          \n",
            "  inflating: train/5654.png          \n",
            "  inflating: train/5655.png          \n",
            "  inflating: train/5656.png          \n",
            "  inflating: train/5657.png          \n",
            "  inflating: train/5658.png          \n",
            "  inflating: train/5659.png          \n",
            "  inflating: train/566.png           \n",
            "  inflating: train/5660.png          \n",
            "  inflating: train/5661.png          \n",
            "  inflating: train/5662.png          \n",
            "  inflating: train/5663.png          \n",
            "  inflating: train/5664.png          \n",
            "  inflating: train/5665.png          \n",
            "  inflating: train/5666.png          \n",
            "  inflating: train/5667.png          \n",
            "  inflating: train/5668.png          \n",
            "  inflating: train/5669.png          \n",
            "  inflating: train/567.png           \n",
            "  inflating: train/5670.png          \n",
            "  inflating: train/5671.png          \n",
            "  inflating: train/5672.png          \n",
            "  inflating: train/5673.png          \n",
            "  inflating: train/5674.png          \n",
            "  inflating: train/5675.png          \n",
            "  inflating: train/5676.png          \n",
            "  inflating: train/5677.png          \n",
            "  inflating: train/5678.png          \n",
            "  inflating: train/5679.png          \n",
            "  inflating: train/568.png           \n",
            "  inflating: train/5680.png          \n",
            "  inflating: train/5681.png          \n",
            "  inflating: train/5682.png          \n",
            "  inflating: train/5683.png          \n",
            "  inflating: train/5684.png          \n",
            "  inflating: train/5685.png          \n",
            "  inflating: train/5686.png          \n",
            "  inflating: train/5687.png          \n",
            "  inflating: train/5688.png          \n",
            "  inflating: train/5689.png          \n",
            "  inflating: train/569.png           \n",
            "  inflating: train/5690.png          \n",
            "  inflating: train/5691.png          \n",
            "  inflating: train/5692.png          \n",
            "  inflating: train/5693.png          \n",
            "  inflating: train/5694.png          \n",
            "  inflating: train/5695.png          \n",
            "  inflating: train/5696.png          \n",
            "  inflating: train/5697.png          \n",
            "  inflating: train/5698.png          \n",
            "  inflating: train/5699.png          \n",
            "  inflating: train/57.png            \n",
            "  inflating: train/570.png           \n",
            "  inflating: train/5700.png          \n",
            "  inflating: train/5701.png          \n",
            "  inflating: train/5702.png          \n",
            "  inflating: train/5703.png          \n",
            "  inflating: train/5704.png          \n",
            "  inflating: train/5705.png          \n",
            "  inflating: train/5706.png          \n",
            "  inflating: train/5707.png          \n",
            "  inflating: train/5708.png          \n",
            "  inflating: train/5709.png          \n",
            "  inflating: train/571.png           \n",
            "  inflating: train/5710.png          \n",
            "  inflating: train/5711.png          \n",
            "  inflating: train/5712.png          \n",
            "  inflating: train/5713.png          \n",
            "  inflating: train/5714.png          \n",
            "  inflating: train/5715.png          \n",
            "  inflating: train/5716.png          \n",
            "  inflating: train/5717.png          \n",
            "  inflating: train/5718.png          \n",
            "  inflating: train/5719.png          \n",
            "  inflating: train/572.png           \n",
            "  inflating: train/5720.png          \n",
            "  inflating: train/5721.png          \n",
            "  inflating: train/5722.png          \n",
            "  inflating: train/5723.png          \n",
            "  inflating: train/5724.png          \n",
            "  inflating: train/5725.png          \n",
            "  inflating: train/5726.png          \n",
            "  inflating: train/5727.png          \n",
            "  inflating: train/5728.png          \n",
            "  inflating: train/5729.png          \n",
            "  inflating: train/573.png           \n",
            "  inflating: train/5730.png          \n",
            "  inflating: train/5731.png          \n",
            "  inflating: train/5732.png          \n",
            "  inflating: train/5733.png          \n",
            "  inflating: train/5734.png          \n",
            "  inflating: train/5735.png          \n",
            "  inflating: train/5736.png          \n",
            "  inflating: train/5737.png          \n",
            "  inflating: train/5738.png          \n",
            "  inflating: train/5739.png          \n",
            "  inflating: train/574.png           \n",
            "  inflating: train/5740.png          \n",
            "  inflating: train/5741.png          \n",
            "  inflating: train/5742.png          \n",
            "  inflating: train/5743.png          \n",
            "  inflating: train/5744.png          \n",
            "  inflating: train/5745.png          \n",
            "  inflating: train/5746.png          \n",
            "  inflating: train/5747.png          \n",
            "  inflating: train/5748.png          \n",
            "  inflating: train/5749.png          \n",
            "  inflating: train/575.png           \n",
            "  inflating: train/5750.png          \n",
            "  inflating: train/5751.png          \n",
            "  inflating: train/5752.png          \n",
            "  inflating: train/5753.png          \n",
            "  inflating: train/5754.png          \n",
            "  inflating: train/5755.png          \n",
            "  inflating: train/5756.png          \n",
            "  inflating: train/5757.png          \n",
            "  inflating: train/5758.png          \n",
            "  inflating: train/5759.png          \n",
            "  inflating: train/576.png           \n",
            "  inflating: train/5760.png          \n",
            "  inflating: train/5761.png          \n",
            "  inflating: train/5762.png          \n",
            "  inflating: train/5763.png          \n",
            "  inflating: train/5764.png          \n",
            "  inflating: train/5765.png          \n",
            "  inflating: train/5766.png          \n",
            "  inflating: train/5767.png          \n",
            "  inflating: train/5768.png          \n",
            "  inflating: train/5769.png          \n",
            "  inflating: train/577.png           \n",
            "  inflating: train/5770.png          \n",
            "  inflating: train/5771.png          \n",
            "  inflating: train/5772.png          \n",
            "  inflating: train/5773.png          \n",
            "  inflating: train/5774.png          \n",
            "  inflating: train/5775.png          \n",
            "  inflating: train/5776.png          \n",
            "  inflating: train/5777.png          \n",
            "  inflating: train/5778.png          \n",
            "  inflating: train/5779.png          \n",
            "  inflating: train/578.png           \n",
            "  inflating: train/5780.png          \n",
            "  inflating: train/5781.png          \n",
            "  inflating: train/5782.png          \n",
            "  inflating: train/5783.png          \n",
            "  inflating: train/5784.png          \n",
            "  inflating: train/5785.png          \n",
            "  inflating: train/5786.png          \n",
            "  inflating: train/5787.png          \n",
            "  inflating: train/5788.png          \n",
            "  inflating: train/5789.png          \n",
            "  inflating: train/579.png           \n",
            "  inflating: train/5790.png          \n",
            "  inflating: train/5791.png          \n",
            "  inflating: train/5792.png          \n",
            "  inflating: train/5793.png          \n",
            "  inflating: train/5794.png          \n",
            "  inflating: train/5795.png          \n",
            "  inflating: train/5796.png          \n",
            "  inflating: train/5797.png          \n",
            "  inflating: train/5798.png          \n",
            "  inflating: train/5799.png          \n",
            "  inflating: train/58.png            \n",
            "  inflating: train/580.png           \n",
            "  inflating: train/5800.png          \n",
            "  inflating: train/5801.png          \n",
            "  inflating: train/5802.png          \n",
            "  inflating: train/5803.png          \n",
            "  inflating: train/5804.png          \n",
            "  inflating: train/5805.png          \n",
            "  inflating: train/5806.png          \n",
            "  inflating: train/5807.png          \n",
            "  inflating: train/5808.png          \n",
            "  inflating: train/5809.png          \n",
            "  inflating: train/581.png           \n",
            "  inflating: train/5810.png          \n",
            "  inflating: train/5811.png          \n",
            "  inflating: train/5812.png          \n",
            "  inflating: train/5813.png          \n",
            "  inflating: train/5814.png          \n",
            "  inflating: train/5815.png          \n",
            "  inflating: train/5816.png          \n",
            "  inflating: train/5817.png          \n",
            "  inflating: train/5818.png          \n",
            "  inflating: train/5819.png          \n",
            "  inflating: train/582.png           \n",
            "  inflating: train/5820.png          \n",
            "  inflating: train/5821.png          \n",
            "  inflating: train/5822.png          \n",
            "  inflating: train/5823.png          \n",
            "  inflating: train/5824.png          \n",
            "  inflating: train/5825.png          \n",
            "  inflating: train/5826.png          \n",
            "  inflating: train/5827.png          \n",
            "  inflating: train/5828.png          \n",
            "  inflating: train/5829.png          \n",
            "  inflating: train/583.png           \n",
            "  inflating: train/5830.png          \n",
            "  inflating: train/5831.png          \n",
            "  inflating: train/5832.png          \n",
            "  inflating: train/5833.png          \n",
            "  inflating: train/5834.png          \n",
            "  inflating: train/5835.png          \n",
            "  inflating: train/5836.png          \n",
            "  inflating: train/5837.png          \n",
            "  inflating: train/5838.png          \n",
            "  inflating: train/5839.png          \n",
            "  inflating: train/584.png           \n",
            "  inflating: train/5840.png          \n",
            "  inflating: train/5841.png          \n",
            "  inflating: train/5842.png          \n",
            "  inflating: train/5843.png          \n",
            "  inflating: train/5844.png          \n",
            "  inflating: train/5845.png          \n",
            "  inflating: train/5846.png          \n",
            "  inflating: train/5847.png          \n",
            "  inflating: train/5848.png          \n",
            "  inflating: train/5849.png          \n",
            "  inflating: train/585.png           \n",
            "  inflating: train/5850.png          \n",
            "  inflating: train/5851.png          \n",
            "  inflating: train/5852.png          \n",
            "  inflating: train/5853.png          \n",
            "  inflating: train/5854.png          \n",
            "  inflating: train/5855.png          \n",
            "  inflating: train/5856.png          \n",
            "  inflating: train/5857.png          \n",
            "  inflating: train/5858.png          \n",
            "  inflating: train/5859.png          \n",
            "  inflating: train/586.png           \n",
            "  inflating: train/5860.png          \n",
            "  inflating: train/5861.png          \n",
            "  inflating: train/5862.png          \n",
            "  inflating: train/5863.png          \n",
            "  inflating: train/5864.png          \n",
            "  inflating: train/5865.png          \n",
            "  inflating: train/5866.png          \n",
            "  inflating: train/5867.png          \n",
            "  inflating: train/5868.png          \n",
            "  inflating: train/5869.png          \n",
            "  inflating: train/587.png           \n",
            "  inflating: train/5870.png          \n",
            "  inflating: train/5871.png          \n",
            "  inflating: train/5872.png          \n",
            "  inflating: train/5873.png          \n",
            "  inflating: train/5874.png          \n",
            "  inflating: train/5875.png          \n",
            "  inflating: train/5876.png          \n",
            "  inflating: train/5877.png          \n",
            "  inflating: train/5878.png          \n",
            "  inflating: train/5879.png          \n",
            "  inflating: train/588.png           \n",
            "  inflating: train/5880.png          \n",
            "  inflating: train/5881.png          \n",
            "  inflating: train/5882.png          \n",
            "  inflating: train/5883.png          \n",
            "  inflating: train/5884.png          \n",
            "  inflating: train/5885.png          \n",
            "  inflating: train/5886.png          \n",
            "  inflating: train/5887.png          \n",
            "  inflating: train/5888.png          \n",
            "  inflating: train/5889.png          \n",
            "  inflating: train/589.png           \n",
            "  inflating: train/5890.png          \n",
            "  inflating: train/5891.png          \n",
            "  inflating: train/5892.png          \n",
            "  inflating: train/5893.png          \n",
            "  inflating: train/5894.png          \n",
            "  inflating: train/5895.png          \n",
            "  inflating: train/5896.png          \n",
            "  inflating: train/5897.png          \n",
            "  inflating: train/5898.png          \n",
            "  inflating: train/5899.png          \n",
            "  inflating: train/59.png            \n",
            "  inflating: train/590.png           \n",
            "  inflating: train/5900.png          \n",
            "  inflating: train/5901.png          \n",
            "  inflating: train/5902.png          \n",
            "  inflating: train/5903.png          \n",
            "  inflating: train/5904.png          \n",
            "  inflating: train/5905.png          \n",
            "  inflating: train/5906.png          \n",
            "  inflating: train/5907.png          \n",
            "  inflating: train/5908.png          \n",
            "  inflating: train/5909.png          \n",
            "  inflating: train/591.png           \n",
            "  inflating: train/5910.png          \n",
            "  inflating: train/5911.png          \n",
            "  inflating: train/5912.png          \n",
            "  inflating: train/5913.png          \n",
            "  inflating: train/5914.png          \n",
            "  inflating: train/5915.png          \n",
            "  inflating: train/5916.png          \n",
            "  inflating: train/5917.png          \n",
            "  inflating: train/5918.png          \n",
            "  inflating: train/5919.png          \n",
            "  inflating: train/592.png           \n",
            "  inflating: train/5920.png          \n",
            "  inflating: train/5921.png          \n",
            "  inflating: train/5922.png          \n",
            "  inflating: train/5923.png          \n",
            "  inflating: train/5924.png          \n",
            "  inflating: train/5925.png          \n",
            "  inflating: train/5926.png          \n",
            "  inflating: train/5927.png          \n",
            "  inflating: train/5928.png          \n",
            "  inflating: train/5929.png          \n",
            "  inflating: train/593.png           \n",
            "  inflating: train/5930.png          \n",
            "  inflating: train/5931.png          \n",
            "  inflating: train/5932.png          \n",
            "  inflating: train/5933.png          \n",
            "  inflating: train/5934.png          \n",
            "  inflating: train/5935.png          \n",
            "  inflating: train/5936.png          \n",
            "  inflating: train/5937.png          \n",
            "  inflating: train/5938.png          \n",
            "  inflating: train/5939.png          \n",
            "  inflating: train/594.png           \n",
            "  inflating: train/5940.png          \n",
            "  inflating: train/5941.png          \n",
            "  inflating: train/5942.png          \n",
            "  inflating: train/5943.png          \n",
            "  inflating: train/5944.png          \n",
            "  inflating: train/5945.png          \n",
            "  inflating: train/5946.png          \n",
            "  inflating: train/5947.png          \n",
            "  inflating: train/5948.png          \n",
            "  inflating: train/5949.png          \n",
            "  inflating: train/595.png           \n",
            "  inflating: train/5950.png          \n",
            "  inflating: train/5951.png          \n",
            "  inflating: train/5952.png          \n",
            "  inflating: train/5953.png          \n",
            "  inflating: train/5954.png          \n",
            "  inflating: train/5955.png          \n",
            "  inflating: train/5956.png          \n",
            "  inflating: train/5957.png          \n",
            "  inflating: train/5958.png          \n",
            "  inflating: train/5959.png          \n",
            "  inflating: train/596.png           \n",
            "  inflating: train/5960.png          \n",
            "  inflating: train/5961.png          \n",
            "  inflating: train/5962.png          \n",
            "  inflating: train/5963.png          \n",
            "  inflating: train/5964.png          \n",
            "  inflating: train/5965.png          \n",
            "  inflating: train/5966.png          \n",
            "  inflating: train/5967.png          \n",
            "  inflating: train/5968.png          \n",
            "  inflating: train/5969.png          \n",
            "  inflating: train/597.png           \n",
            "  inflating: train/5970.png          \n",
            "  inflating: train/5971.png          \n",
            "  inflating: train/5972.png          \n",
            "  inflating: train/5973.png          \n",
            "  inflating: train/5974.png          \n",
            "  inflating: train/5975.png          \n",
            "  inflating: train/5976.png          \n",
            "  inflating: train/5977.png          \n",
            "  inflating: train/5978.png          \n",
            "  inflating: train/5979.png          \n",
            "  inflating: train/598.png           \n",
            "  inflating: train/5980.png          \n",
            "  inflating: train/5981.png          \n",
            "  inflating: train/5982.png          \n",
            "  inflating: train/5983.png          \n",
            "  inflating: train/5984.png          \n",
            "  inflating: train/5985.png          \n",
            "  inflating: train/5986.png          \n",
            "  inflating: train/5987.png          \n",
            "  inflating: train/5988.png          \n",
            "  inflating: train/5989.png          \n",
            "  inflating: train/599.png           \n",
            "  inflating: train/5990.png          \n",
            "  inflating: train/5991.png          \n",
            "  inflating: train/5992.png          \n",
            "  inflating: train/5993.png          \n",
            "  inflating: train/5994.png          \n",
            "  inflating: train/5995.png          \n",
            "  inflating: train/5996.png          \n",
            "  inflating: train/5997.png          \n",
            "  inflating: train/5998.png          \n",
            "  inflating: train/5999.png          \n",
            "  inflating: train/6.png             \n",
            "  inflating: train/60.png            \n",
            "  inflating: train/600.png           \n",
            "  inflating: train/6000.png          \n",
            "  inflating: train/6001.png          \n",
            "  inflating: train/6002.png          \n",
            "  inflating: train/6003.png          \n",
            "  inflating: train/6004.png          \n",
            "  inflating: train/6005.png          \n",
            "  inflating: train/6006.png          \n",
            "  inflating: train/6007.png          \n",
            "  inflating: train/6008.png          \n",
            "  inflating: train/6009.png          \n",
            "  inflating: train/601.png           \n",
            "  inflating: train/6010.png          \n",
            "  inflating: train/6011.png          \n",
            "  inflating: train/6012.png          \n",
            "  inflating: train/6013.png          \n",
            "  inflating: train/6014.png          \n",
            "  inflating: train/6015.png          \n",
            "  inflating: train/6016.png          \n",
            "  inflating: train/6017.png          \n",
            "  inflating: train/6018.png          \n",
            "  inflating: train/6019.png          \n",
            "  inflating: train/602.png           \n",
            "  inflating: train/6020.png          \n",
            "  inflating: train/6021.png          \n",
            "  inflating: train/6022.png          \n",
            "  inflating: train/6023.png          \n",
            "  inflating: train/6024.png          \n",
            "  inflating: train/6025.png          \n",
            "  inflating: train/6026.png          \n",
            "  inflating: train/6027.png          \n",
            "  inflating: train/6028.png          \n",
            "  inflating: train/6029.png          \n",
            "  inflating: train/603.png           \n",
            "  inflating: train/6030.png          \n",
            "  inflating: train/6031.png          \n",
            "  inflating: train/6032.png          \n",
            "  inflating: train/6033.png          \n",
            "  inflating: train/6034.png          \n",
            "  inflating: train/6035.png          \n",
            "  inflating: train/6036.png          \n",
            "  inflating: train/6037.png          \n",
            "  inflating: train/6038.png          \n",
            "  inflating: train/6039.png          \n",
            "  inflating: train/604.png           \n",
            "  inflating: train/6040.png          \n",
            "  inflating: train/6041.png          \n",
            "  inflating: train/6042.png          \n",
            "  inflating: train/6043.png          \n",
            "  inflating: train/6044.png          \n",
            "  inflating: train/6045.png          \n",
            "  inflating: train/6046.png          \n",
            "  inflating: train/6047.png          \n",
            "  inflating: train/6048.png          \n",
            "  inflating: train/6049.png          \n",
            "  inflating: train/605.png           \n",
            "  inflating: train/6050.png          \n",
            "  inflating: train/6051.png          \n",
            "  inflating: train/6052.png          \n",
            "  inflating: train/6053.png          \n",
            "  inflating: train/6054.png          \n",
            "  inflating: train/6055.png          \n",
            "  inflating: train/6056.png          \n",
            "  inflating: train/6057.png          \n",
            "  inflating: train/6058.png          \n",
            "  inflating: train/6059.png          \n",
            "  inflating: train/606.png           \n",
            "  inflating: train/6060.png          \n",
            "  inflating: train/6061.png          \n",
            "  inflating: train/6062.png          \n",
            "  inflating: train/6063.png          \n",
            "  inflating: train/6064.png          \n",
            "  inflating: train/6065.png          \n",
            "  inflating: train/6066.png          \n",
            "  inflating: train/6067.png          \n",
            "  inflating: train/6068.png          \n",
            "  inflating: train/6069.png          \n",
            "  inflating: train/607.png           \n",
            "  inflating: train/6070.png          \n",
            "  inflating: train/6071.png          \n",
            "  inflating: train/6072.png          \n",
            "  inflating: train/6073.png          \n",
            "  inflating: train/6074.png          \n",
            "  inflating: train/6075.png          \n",
            "  inflating: train/6076.png          \n",
            "  inflating: train/6077.png          \n",
            "  inflating: train/6078.png          \n",
            "  inflating: train/6079.png          \n",
            "  inflating: train/608.png           \n",
            "  inflating: train/6080.png          \n",
            "  inflating: train/6081.png          \n",
            "  inflating: train/6082.png          \n",
            "  inflating: train/6083.png          \n",
            "  inflating: train/6084.png          \n",
            "  inflating: train/6085.png          \n",
            "  inflating: train/6086.png          \n",
            "  inflating: train/6087.png          \n",
            "  inflating: train/6088.png          \n",
            "  inflating: train/6089.png          \n",
            "  inflating: train/609.png           \n",
            "  inflating: train/6090.png          \n",
            "  inflating: train/6091.png          \n",
            "  inflating: train/6092.png          \n",
            "  inflating: train/6093.png          \n",
            "  inflating: train/6094.png          \n",
            "  inflating: train/6095.png          \n",
            "  inflating: train/6096.png          \n",
            "  inflating: train/6097.png          \n",
            "  inflating: train/6098.png          \n",
            "  inflating: train/6099.png          \n",
            "  inflating: train/61.png            \n",
            "  inflating: train/610.png           \n",
            "  inflating: train/6100.png          \n",
            "  inflating: train/6101.png          \n",
            "  inflating: train/6102.png          \n",
            "  inflating: train/6103.png          \n",
            "  inflating: train/6104.png          \n",
            "  inflating: train/6105.png          \n",
            "  inflating: train/6106.png          \n",
            "  inflating: train/6107.png          \n",
            "  inflating: train/6108.png          \n",
            "  inflating: train/6109.png          \n",
            "  inflating: train/611.png           \n",
            "  inflating: train/6110.png          \n",
            "  inflating: train/6111.png          \n",
            "  inflating: train/6112.png          \n",
            "  inflating: train/6113.png          \n",
            "  inflating: train/6114.png          \n",
            "  inflating: train/6115.png          \n",
            "  inflating: train/6116.png          \n",
            "  inflating: train/6117.png          \n",
            "  inflating: train/6118.png          \n",
            "  inflating: train/6119.png          \n",
            "  inflating: train/612.png           \n",
            "  inflating: train/6120.png          \n",
            "  inflating: train/6121.png          \n",
            "  inflating: train/6122.png          \n",
            "  inflating: train/6123.png          \n",
            "  inflating: train/6124.png          \n",
            "  inflating: train/6125.png          \n",
            "  inflating: train/6126.png          \n",
            "  inflating: train/6127.png          \n",
            "  inflating: train/6128.png          \n",
            "  inflating: train/6129.png          \n",
            "  inflating: train/613.png           \n",
            "  inflating: train/6130.png          \n",
            "  inflating: train/6131.png          \n",
            "  inflating: train/6132.png          \n",
            "  inflating: train/6133.png          \n",
            "  inflating: train/6134.png          \n",
            "  inflating: train/6135.png          \n",
            "  inflating: train/6136.png          \n",
            "  inflating: train/6137.png          \n",
            "  inflating: train/6138.png          \n",
            "  inflating: train/6139.png          \n",
            "  inflating: train/614.png           \n",
            "  inflating: train/6140.png          \n",
            "  inflating: train/6141.png          \n",
            "  inflating: train/6142.png          \n",
            "  inflating: train/6143.png          \n",
            "  inflating: train/6144.png          \n",
            "  inflating: train/6145.png          \n",
            "  inflating: train/6146.png          \n",
            "  inflating: train/6147.png          \n",
            "  inflating: train/6148.png          \n",
            "  inflating: train/6149.png          \n",
            "  inflating: train/615.png           \n",
            "  inflating: train/6150.png          \n",
            "  inflating: train/6151.png          \n",
            "  inflating: train/6152.png          \n",
            "  inflating: train/6153.png          \n",
            "  inflating: train/6154.png          \n",
            "  inflating: train/6155.png          \n",
            "  inflating: train/6156.png          \n",
            "  inflating: train/6157.png          \n",
            "  inflating: train/6158.png          \n",
            "  inflating: train/6159.png          \n",
            "  inflating: train/616.png           \n",
            "  inflating: train/6160.png          \n",
            "  inflating: train/6161.png          \n",
            "  inflating: train/6162.png          \n",
            "  inflating: train/6163.png          \n",
            "  inflating: train/6164.png          \n",
            "  inflating: train/6165.png          \n",
            "  inflating: train/6166.png          \n",
            "  inflating: train/6167.png          \n",
            "  inflating: train/6168.png          \n",
            "  inflating: train/6169.png          \n",
            "  inflating: train/617.png           \n",
            "  inflating: train/6170.png          \n",
            "  inflating: train/6171.png          \n",
            "  inflating: train/6172.png          \n",
            "  inflating: train/6173.png          \n",
            "  inflating: train/6174.png          \n",
            "  inflating: train/6175.png          \n",
            "  inflating: train/6176.png          \n",
            "  inflating: train/6177.png          \n",
            "  inflating: train/6178.png          \n",
            "  inflating: train/6179.png          \n",
            "  inflating: train/618.png           \n",
            "  inflating: train/6180.png          \n",
            "  inflating: train/6181.png          \n",
            "  inflating: train/6182.png          \n",
            "  inflating: train/6183.png          \n",
            "  inflating: train/6184.png          \n",
            "  inflating: train/6185.png          \n",
            "  inflating: train/6186.png          \n",
            "  inflating: train/6187.png          \n",
            "  inflating: train/6188.png          \n",
            "  inflating: train/6189.png          \n",
            "  inflating: train/619.png           \n",
            "  inflating: train/6190.png          \n",
            "  inflating: train/6191.png          \n",
            "  inflating: train/6192.png          \n",
            "  inflating: train/6193.png          \n",
            "  inflating: train/6194.png          \n",
            "  inflating: train/6195.png          \n",
            "  inflating: train/6196.png          \n",
            "  inflating: train/6197.png          \n",
            "  inflating: train/6198.png          \n",
            "  inflating: train/6199.png          \n",
            "  inflating: train/62.png            \n",
            "  inflating: train/620.png           \n",
            "  inflating: train/6200.png          \n",
            "  inflating: train/6201.png          \n",
            "  inflating: train/6202.png          \n",
            "  inflating: train/6203.png          \n",
            "  inflating: train/6204.png          \n",
            "  inflating: train/6205.png          \n",
            "  inflating: train/6206.png          \n",
            "  inflating: train/6207.png          \n",
            "  inflating: train/6208.png          \n",
            "  inflating: train/6209.png          \n",
            "  inflating: train/621.png           \n",
            "  inflating: train/6210.png          \n",
            "  inflating: train/6211.png          \n",
            "  inflating: train/6212.png          \n",
            "  inflating: train/6213.png          \n",
            "  inflating: train/6214.png          \n",
            "  inflating: train/6215.png          \n",
            "  inflating: train/6216.png          \n",
            "  inflating: train/6217.png          \n",
            "  inflating: train/6218.png          \n",
            "  inflating: train/6219.png          \n",
            "  inflating: train/622.png           \n",
            "  inflating: train/6220.png          \n",
            "  inflating: train/6221.png          \n",
            "  inflating: train/6222.png          \n",
            "  inflating: train/6223.png          \n",
            "  inflating: train/6224.png          \n",
            "  inflating: train/6225.png          \n",
            "  inflating: train/6226.png          \n",
            "  inflating: train/6227.png          \n",
            "  inflating: train/6228.png          \n",
            "  inflating: train/6229.png          \n",
            "  inflating: train/623.png           \n",
            "  inflating: train/6230.png          \n",
            "  inflating: train/6231.png          \n",
            "  inflating: train/6232.png          \n",
            "  inflating: train/6233.png          \n",
            "  inflating: train/6234.png          \n",
            "  inflating: train/6235.png          \n",
            "  inflating: train/6236.png          \n",
            "  inflating: train/6237.png          \n",
            "  inflating: train/6238.png          \n",
            "  inflating: train/6239.png          \n",
            "  inflating: train/624.png           \n",
            "  inflating: train/6240.png          \n",
            "  inflating: train/6241.png          \n",
            "  inflating: train/6242.png          \n",
            "  inflating: train/6243.png          \n",
            "  inflating: train/6244.png          \n",
            "  inflating: train/6245.png          \n",
            "  inflating: train/6246.png          \n",
            "  inflating: train/6247.png          \n",
            "  inflating: train/6248.png          \n",
            "  inflating: train/6249.png          \n",
            "  inflating: train/625.png           \n",
            "  inflating: train/6250.png          \n",
            "  inflating: train/6251.png          \n",
            "  inflating: train/6252.png          \n",
            "  inflating: train/6253.png          \n",
            "  inflating: train/6254.png          \n",
            "  inflating: train/6255.png          \n",
            "  inflating: train/6256.png          \n",
            "  inflating: train/6257.png          \n",
            "  inflating: train/6258.png          \n",
            "  inflating: train/6259.png          \n",
            "  inflating: train/626.png           \n",
            "  inflating: train/6260.png          \n",
            "  inflating: train/6261.png          \n",
            "  inflating: train/6262.png          \n",
            "  inflating: train/6263.png          \n",
            "  inflating: train/6264.png          \n",
            "  inflating: train/6265.png          \n",
            "  inflating: train/6266.png          \n",
            "  inflating: train/6267.png          \n",
            "  inflating: train/6268.png          \n",
            "  inflating: train/6269.png          \n",
            "  inflating: train/627.png           \n",
            "  inflating: train/6270.png          \n",
            "  inflating: train/6271.png          \n",
            "  inflating: train/6272.png          \n",
            "  inflating: train/6273.png          \n",
            "  inflating: train/6274.png          \n",
            "  inflating: train/6275.png          \n",
            "  inflating: train/6276.png          \n",
            "  inflating: train/6277.png          \n",
            "  inflating: train/6278.png          \n",
            "  inflating: train/6279.png          \n",
            "  inflating: train/628.png           \n",
            "  inflating: train/6280.png          \n",
            "  inflating: train/6281.png          \n",
            "  inflating: train/6282.png          \n",
            "  inflating: train/6283.png          \n",
            "  inflating: train/6284.png          \n",
            "  inflating: train/6285.png          \n",
            "  inflating: train/6286.png          \n",
            "  inflating: train/6287.png          \n",
            "  inflating: train/6288.png          \n",
            "  inflating: train/6289.png          \n",
            "  inflating: train/629.png           \n",
            "  inflating: train/6290.png          \n",
            "  inflating: train/6291.png          \n",
            "  inflating: train/6292.png          \n",
            "  inflating: train/6293.png          \n",
            "  inflating: train/6294.png          \n",
            "  inflating: train/6295.png          \n",
            "  inflating: train/6296.png          \n",
            "  inflating: train/6297.png          \n",
            "  inflating: train/6298.png          \n",
            "  inflating: train/6299.png          \n",
            "  inflating: train/63.png            \n",
            "  inflating: train/630.png           \n",
            "  inflating: train/6300.png          \n",
            "  inflating: train/6301.png          \n",
            "  inflating: train/6302.png          \n",
            "  inflating: train/6303.png          \n",
            "  inflating: train/6304.png          \n",
            "  inflating: train/6305.png          \n",
            "  inflating: train/6306.png          \n",
            "  inflating: train/6307.png          \n",
            "  inflating: train/6308.png          \n",
            "  inflating: train/6309.png          \n",
            "  inflating: train/631.png           \n",
            "  inflating: train/6310.png          \n",
            "  inflating: train/6311.png          \n",
            "  inflating: train/6312.png          \n",
            "  inflating: train/6313.png          \n",
            "  inflating: train/6314.png          \n",
            "  inflating: train/6315.png          \n",
            "  inflating: train/6316.png          \n",
            "  inflating: train/6317.png          \n",
            "  inflating: train/6318.png          \n",
            "  inflating: train/6319.png          \n",
            "  inflating: train/632.png           \n",
            "  inflating: train/6320.png          \n",
            "  inflating: train/6321.png          \n",
            "  inflating: train/6322.png          \n",
            "  inflating: train/6323.png          \n",
            "  inflating: train/6324.png          \n",
            "  inflating: train/6325.png          \n",
            "  inflating: train/6326.png          \n",
            "  inflating: train/6327.png          \n",
            "  inflating: train/6328.png          \n",
            "  inflating: train/6329.png          \n",
            "  inflating: train/633.png           \n",
            "  inflating: train/6330.png          \n",
            "  inflating: train/6331.png          \n",
            "  inflating: train/6332.png          \n",
            "  inflating: train/6333.png          \n",
            "  inflating: train/6334.png          \n",
            "  inflating: train/6335.png          \n",
            "  inflating: train/6336.png          \n",
            "  inflating: train/6337.png          \n",
            "  inflating: train/6338.png          \n",
            "  inflating: train/6339.png          \n",
            "  inflating: train/634.png           \n",
            "  inflating: train/6340.png          \n",
            "  inflating: train/6341.png          \n",
            "  inflating: train/6342.png          \n",
            "  inflating: train/6343.png          \n",
            "  inflating: train/6344.png          \n",
            "  inflating: train/6345.png          \n",
            "  inflating: train/6346.png          \n",
            "  inflating: train/6347.png          \n",
            "  inflating: train/6348.png          \n",
            "  inflating: train/6349.png          \n",
            "  inflating: train/635.png           \n",
            "  inflating: train/6350.png          \n",
            "  inflating: train/6351.png          \n",
            "  inflating: train/6352.png          \n",
            "  inflating: train/6353.png          \n",
            "  inflating: train/6354.png          \n",
            "  inflating: train/6355.png          \n",
            "  inflating: train/6356.png          \n",
            "  inflating: train/6357.png          \n",
            "  inflating: train/6358.png          \n",
            "  inflating: train/6359.png          \n",
            "  inflating: train/636.png           \n",
            "  inflating: train/6360.png          \n",
            "  inflating: train/6361.png          \n",
            "  inflating: train/6362.png          \n",
            "  inflating: train/6363.png          \n",
            "  inflating: train/6364.png          \n",
            "  inflating: train/6365.png          \n",
            "  inflating: train/6366.png          \n",
            "  inflating: train/6367.png          \n",
            "  inflating: train/6368.png          \n",
            "  inflating: train/6369.png          \n",
            "  inflating: train/637.png           \n",
            "  inflating: train/6370.png          \n",
            "  inflating: train/6371.png          \n",
            "  inflating: train/6372.png          \n",
            "  inflating: train/6373.png          \n",
            "  inflating: train/6374.png          \n",
            "  inflating: train/6375.png          \n",
            "  inflating: train/6376.png          \n",
            "  inflating: train/6377.png          \n",
            "  inflating: train/6378.png          \n",
            "  inflating: train/6379.png          \n",
            "  inflating: train/638.png           \n",
            "  inflating: train/6380.png          \n",
            "  inflating: train/6381.png          \n",
            "  inflating: train/6382.png          \n",
            "  inflating: train/6383.png          \n",
            "  inflating: train/6384.png          \n",
            "  inflating: train/6385.png          \n",
            "  inflating: train/6386.png          \n",
            "  inflating: train/6387.png          \n",
            "  inflating: train/6388.png          \n",
            "  inflating: train/6389.png          \n",
            "  inflating: train/639.png           \n",
            "  inflating: train/6390.png          \n",
            "  inflating: train/6391.png          \n",
            "  inflating: train/6392.png          \n",
            "  inflating: train/6393.png          \n",
            "  inflating: train/6394.png          \n",
            "  inflating: train/6395.png          \n",
            "  inflating: train/6396.png          \n",
            "  inflating: train/6397.png          \n",
            "  inflating: train/6398.png          \n",
            "  inflating: train/6399.png          \n",
            "  inflating: train/64.png            \n",
            "  inflating: train/640.png           \n",
            "  inflating: train/6400.png          \n",
            "  inflating: train/6401.png          \n",
            "  inflating: train/6402.png          \n",
            "  inflating: train/6403.png          \n",
            "  inflating: train/6404.png          \n",
            "  inflating: train/6405.png          \n",
            "  inflating: train/6406.png          \n",
            "  inflating: train/6407.png          \n",
            "  inflating: train/6408.png          \n",
            "  inflating: train/6409.png          \n",
            "  inflating: train/641.png           \n",
            "  inflating: train/6410.png          \n",
            "  inflating: train/6411.png          \n",
            "  inflating: train/6412.png          \n",
            "  inflating: train/6413.png          \n",
            "  inflating: train/6414.png          \n",
            "  inflating: train/6415.png          \n",
            "  inflating: train/6416.png          \n",
            "  inflating: train/6417.png          \n",
            "  inflating: train/6418.png          \n",
            "  inflating: train/6419.png          \n",
            "  inflating: train/642.png           \n",
            "  inflating: train/6420.png          \n",
            "  inflating: train/6421.png          \n",
            "  inflating: train/6422.png          \n",
            "  inflating: train/6423.png          \n",
            "  inflating: train/6424.png          \n",
            "  inflating: train/6425.png          \n",
            "  inflating: train/6426.png          \n",
            "  inflating: train/6427.png          \n",
            "  inflating: train/6428.png          \n",
            "  inflating: train/6429.png          \n",
            "  inflating: train/643.png           \n",
            "  inflating: train/6430.png          \n",
            "  inflating: train/6431.png          \n",
            "  inflating: train/6432.png          \n",
            "  inflating: train/6433.png          \n",
            "  inflating: train/6434.png          \n",
            "  inflating: train/6435.png          \n",
            "  inflating: train/6436.png          \n",
            "  inflating: train/6437.png          \n",
            "  inflating: train/6438.png          \n",
            "  inflating: train/6439.png          \n",
            "  inflating: train/644.png           \n",
            "  inflating: train/6440.png          \n",
            "  inflating: train/6441.png          \n",
            "  inflating: train/6442.png          \n",
            "  inflating: train/6443.png          \n",
            "  inflating: train/6444.png          \n",
            "  inflating: train/6445.png          \n",
            "  inflating: train/6446.png          \n",
            "  inflating: train/6447.png          \n",
            "  inflating: train/6448.png          \n",
            "  inflating: train/6449.png          \n",
            "  inflating: train/645.png           \n",
            "  inflating: train/6450.png          \n",
            "  inflating: train/6451.png          \n",
            "  inflating: train/6452.png          \n",
            "  inflating: train/6453.png          \n",
            "  inflating: train/6454.png          \n",
            "  inflating: train/6455.png          \n",
            "  inflating: train/6456.png          \n",
            "  inflating: train/6457.png          \n",
            "  inflating: train/6458.png          \n",
            "  inflating: train/6459.png          \n",
            "  inflating: train/646.png           \n",
            "  inflating: train/6460.png          \n",
            "  inflating: train/6461.png          \n",
            "  inflating: train/6462.png          \n",
            "  inflating: train/6463.png          \n",
            "  inflating: train/6464.png          \n",
            "  inflating: train/6465.png          \n",
            "  inflating: train/6466.png          \n",
            "  inflating: train/6467.png          \n",
            "  inflating: train/6468.png          \n",
            "  inflating: train/6469.png          \n",
            "  inflating: train/647.png           \n",
            "  inflating: train/6470.png          \n",
            "  inflating: train/6471.png          \n",
            "  inflating: train/6472.png          \n",
            "  inflating: train/6473.png          \n",
            "  inflating: train/6474.png          \n",
            "  inflating: train/6475.png          \n",
            "  inflating: train/6476.png          \n",
            "  inflating: train/6477.png          \n",
            "  inflating: train/6478.png          \n",
            "  inflating: train/6479.png          \n",
            "  inflating: train/648.png           \n",
            "  inflating: train/6480.png          \n",
            "  inflating: train/6481.png          \n",
            "  inflating: train/6482.png          \n",
            "  inflating: train/6483.png          \n",
            "  inflating: train/6484.png          \n",
            "  inflating: train/6485.png          \n",
            "  inflating: train/6486.png          \n",
            "  inflating: train/6487.png          \n",
            "  inflating: train/6488.png          \n",
            "  inflating: train/6489.png          \n",
            "  inflating: train/649.png           \n",
            "  inflating: train/6490.png          \n",
            "  inflating: train/6491.png          \n",
            "  inflating: train/6492.png          \n",
            "  inflating: train/6493.png          \n",
            "  inflating: train/6494.png          \n",
            "  inflating: train/6495.png          \n",
            "  inflating: train/6496.png          \n",
            "  inflating: train/6497.png          \n",
            "  inflating: train/6498.png          \n",
            "  inflating: train/6499.png          \n",
            "  inflating: train/65.png            \n",
            "  inflating: train/650.png           \n",
            "  inflating: train/6500.png          \n",
            "  inflating: train/6501.png          \n",
            "  inflating: train/6502.png          \n",
            "  inflating: train/6503.png          \n",
            "  inflating: train/6504.png          \n",
            "  inflating: train/6505.png          \n",
            "  inflating: train/6506.png          \n",
            "  inflating: train/6507.png          \n",
            "  inflating: train/6508.png          \n",
            "  inflating: train/6509.png          \n",
            "  inflating: train/651.png           \n",
            "  inflating: train/6510.png          \n",
            "  inflating: train/6511.png          \n",
            "  inflating: train/6512.png          \n",
            "  inflating: train/6513.png          \n",
            "  inflating: train/6514.png          \n",
            "  inflating: train/6515.png          \n",
            "  inflating: train/6516.png          \n",
            "  inflating: train/6517.png          \n",
            "  inflating: train/6518.png          \n",
            "  inflating: train/6519.png          \n",
            "  inflating: train/652.png           \n",
            "  inflating: train/6520.png          \n",
            "  inflating: train/6521.png          \n",
            "  inflating: train/6522.png          \n",
            "  inflating: train/6523.png          \n",
            "  inflating: train/6524.png          \n",
            "  inflating: train/6525.png          \n",
            "  inflating: train/6526.png          \n",
            "  inflating: train/6527.png          \n",
            "  inflating: train/6528.png          \n",
            "  inflating: train/6529.png          \n",
            "  inflating: train/653.png           \n",
            "  inflating: train/6530.png          \n",
            "  inflating: train/6531.png          \n",
            "  inflating: train/6532.png          \n",
            "  inflating: train/6533.png          \n",
            "  inflating: train/6534.png          \n",
            "  inflating: train/6535.png          \n",
            "  inflating: train/6536.png          \n",
            "  inflating: train/6537.png          \n",
            "  inflating: train/6538.png          \n",
            "  inflating: train/6539.png          \n",
            "  inflating: train/654.png           \n",
            "  inflating: train/6540.png          \n",
            "  inflating: train/6541.png          \n",
            "  inflating: train/6542.png          \n",
            "  inflating: train/6543.png          \n",
            "  inflating: train/6544.png          \n",
            "  inflating: train/6545.png          \n",
            "  inflating: train/6546.png          \n",
            "  inflating: train/6547.png          \n",
            "  inflating: train/6548.png          \n",
            "  inflating: train/6549.png          \n",
            "  inflating: train/655.png           \n",
            "  inflating: train/6550.png          \n",
            "  inflating: train/6551.png          \n",
            "  inflating: train/6552.png          \n",
            "  inflating: train/6553.png          \n",
            "  inflating: train/6554.png          \n",
            "  inflating: train/6555.png          \n",
            "  inflating: train/6556.png          \n",
            "  inflating: train/6557.png          \n",
            "  inflating: train/6558.png          \n",
            "  inflating: train/6559.png          \n",
            "  inflating: train/656.png           \n",
            "  inflating: train/6560.png          \n",
            "  inflating: train/6561.png          \n",
            "  inflating: train/6562.png          \n",
            "  inflating: train/6563.png          \n",
            "  inflating: train/6564.png          \n",
            "  inflating: train/6565.png          \n",
            "  inflating: train/6566.png          \n",
            "  inflating: train/6567.png          \n",
            "  inflating: train/6568.png          \n",
            "  inflating: train/6569.png          \n",
            "  inflating: train/657.png           \n",
            "  inflating: train/6570.png          \n",
            "  inflating: train/6571.png          \n",
            "  inflating: train/6572.png          \n",
            "  inflating: train/6573.png          \n",
            "  inflating: train/6574.png          \n",
            "  inflating: train/6575.png          \n",
            "  inflating: train/6576.png          \n",
            "  inflating: train/6577.png          \n",
            "  inflating: train/6578.png          \n",
            "  inflating: train/6579.png          \n",
            "  inflating: train/658.png           \n",
            "  inflating: train/6580.png          \n",
            "  inflating: train/6581.png          \n",
            "  inflating: train/6582.png          \n",
            "  inflating: train/6583.png          \n",
            "  inflating: train/6584.png          \n",
            "  inflating: train/6585.png          \n",
            "  inflating: train/6586.png          \n",
            "  inflating: train/6587.png          \n",
            "  inflating: train/6588.png          \n",
            "  inflating: train/6589.png          \n",
            "  inflating: train/659.png           \n",
            "  inflating: train/6590.png          \n",
            "  inflating: train/6591.png          \n",
            "  inflating: train/6592.png          \n",
            "  inflating: train/6593.png          \n",
            "  inflating: train/6594.png          \n",
            "  inflating: train/6595.png          \n",
            "  inflating: train/6596.png          \n",
            "  inflating: train/6597.png          \n",
            "  inflating: train/6598.png          \n",
            "  inflating: train/6599.png          \n",
            "  inflating: train/66.png            \n",
            "  inflating: train/660.png           \n",
            "  inflating: train/6600.png          \n",
            "  inflating: train/6601.png          \n",
            "  inflating: train/6602.png          \n",
            "  inflating: train/6603.png          \n",
            "  inflating: train/6604.png          \n",
            "  inflating: train/6605.png          \n",
            "  inflating: train/6606.png          \n",
            "  inflating: train/6607.png          \n",
            "  inflating: train/6608.png          \n",
            "  inflating: train/6609.png          \n",
            "  inflating: train/661.png           \n",
            "  inflating: train/6610.png          \n",
            "  inflating: train/6611.png          \n",
            "  inflating: train/6612.png          \n",
            "  inflating: train/6613.png          \n",
            "  inflating: train/6614.png          \n",
            "  inflating: train/6615.png          \n",
            "  inflating: train/6616.png          \n",
            "  inflating: train/6617.png          \n",
            "  inflating: train/6618.png          \n",
            "  inflating: train/6619.png          \n",
            "  inflating: train/662.png           \n",
            "  inflating: train/6620.png          \n",
            "  inflating: train/6621.png          \n",
            "  inflating: train/6622.png          \n",
            "  inflating: train/6623.png          \n",
            "  inflating: train/6624.png          \n",
            "  inflating: train/6625.png          \n",
            "  inflating: train/6626.png          \n",
            "  inflating: train/6627.png          \n",
            "  inflating: train/6628.png          \n",
            "  inflating: train/6629.png          \n",
            "  inflating: train/663.png           \n",
            "  inflating: train/6630.png          \n",
            "  inflating: train/6631.png          \n",
            "  inflating: train/6632.png          \n",
            "  inflating: train/6633.png          \n",
            "  inflating: train/6634.png          \n",
            "  inflating: train/6635.png          \n",
            "  inflating: train/6636.png          \n",
            "  inflating: train/6637.png          \n",
            "  inflating: train/6638.png          \n",
            "  inflating: train/6639.png          \n",
            "  inflating: train/664.png           \n",
            "  inflating: train/6640.png          \n",
            "  inflating: train/6641.png          \n",
            "  inflating: train/6642.png          \n",
            "  inflating: train/6643.png          \n",
            "  inflating: train/6644.png          \n",
            "  inflating: train/6645.png          \n",
            "  inflating: train/6646.png          \n",
            "  inflating: train/6647.png          \n",
            "  inflating: train/6648.png          \n",
            "  inflating: train/6649.png          \n",
            "  inflating: train/665.png           \n",
            "  inflating: train/6650.png          \n",
            "  inflating: train/6651.png          \n",
            "  inflating: train/6652.png          \n",
            "  inflating: train/6653.png          \n",
            "  inflating: train/6654.png          \n",
            "  inflating: train/6655.png          \n",
            "  inflating: train/6656.png          \n",
            "  inflating: train/6657.png          \n",
            "  inflating: train/6658.png          \n",
            "  inflating: train/6659.png          \n",
            "  inflating: train/666.png           \n",
            "  inflating: train/6660.png          \n",
            "  inflating: train/6661.png          \n",
            "  inflating: train/6662.png          \n",
            "  inflating: train/6663.png          \n",
            "  inflating: train/6664.png          \n",
            "  inflating: train/6665.png          \n",
            "  inflating: train/6666.png          \n",
            "  inflating: train/6667.png          \n",
            "  inflating: train/6668.png          \n",
            "  inflating: train/6669.png          \n",
            "  inflating: train/667.png           \n",
            "  inflating: train/6670.png          \n",
            "  inflating: train/6671.png          \n",
            "  inflating: train/6672.png          \n",
            "  inflating: train/6673.png          \n",
            "  inflating: train/6674.png          \n",
            "  inflating: train/6675.png          \n",
            "  inflating: train/6676.png          \n",
            "  inflating: train/6677.png          \n",
            "  inflating: train/6678.png          \n",
            "  inflating: train/6679.png          \n",
            "  inflating: train/668.png           \n",
            "  inflating: train/6680.png          \n",
            "  inflating: train/6681.png          \n",
            "  inflating: train/6682.png          \n",
            "  inflating: train/6683.png          \n",
            "  inflating: train/6684.png          \n",
            "  inflating: train/6685.png          \n",
            "  inflating: train/6686.png          \n",
            "  inflating: train/6687.png          \n",
            "  inflating: train/6688.png          \n",
            "  inflating: train/6689.png          \n",
            "  inflating: train/669.png           \n",
            "  inflating: train/6690.png          \n",
            "  inflating: train/6691.png          \n",
            "  inflating: train/6692.png          \n",
            "  inflating: train/6693.png          \n",
            "  inflating: train/6694.png          \n",
            "  inflating: train/6695.png          \n",
            "  inflating: train/6696.png          \n",
            "  inflating: train/6697.png          \n",
            "  inflating: train/6698.png          \n",
            "  inflating: train/6699.png          \n",
            "  inflating: train/67.png            \n",
            "  inflating: train/670.png           \n",
            "  inflating: train/6700.png          \n",
            "  inflating: train/6701.png          \n",
            "  inflating: train/6702.png          \n",
            "  inflating: train/6703.png          \n",
            "  inflating: train/6704.png          \n",
            "  inflating: train/6705.png          \n",
            "  inflating: train/6706.png          \n",
            "  inflating: train/6707.png          \n",
            "  inflating: train/6708.png          \n",
            "  inflating: train/6709.png          \n",
            "  inflating: train/671.png           \n",
            "  inflating: train/6710.png          \n",
            "  inflating: train/6711.png          \n",
            "  inflating: train/6712.png          \n",
            "  inflating: train/6713.png          \n",
            "  inflating: train/6714.png          \n",
            "  inflating: train/6715.png          \n",
            "  inflating: train/6716.png          \n",
            "  inflating: train/6717.png          \n",
            "  inflating: train/6718.png          \n",
            "  inflating: train/6719.png          \n",
            "  inflating: train/672.png           \n",
            "  inflating: train/6720.png          \n",
            "  inflating: train/6721.png          \n",
            "  inflating: train/6722.png          \n",
            "  inflating: train/6723.png          \n",
            "  inflating: train/6724.png          \n",
            "  inflating: train/6725.png          \n",
            "  inflating: train/6726.png          \n",
            "  inflating: train/6727.png          \n",
            "  inflating: train/6728.png          \n",
            "  inflating: train/6729.png          \n",
            "  inflating: train/673.png           \n",
            "  inflating: train/6730.png          \n",
            "  inflating: train/6731.png          \n",
            "  inflating: train/6732.png          \n",
            "  inflating: train/6733.png          \n",
            "  inflating: train/6734.png          \n",
            "  inflating: train/6735.png          \n",
            "  inflating: train/6736.png          \n",
            "  inflating: train/6737.png          \n",
            "  inflating: train/6738.png          \n",
            "  inflating: train/6739.png          \n",
            "  inflating: train/674.png           \n",
            "  inflating: train/6740.png          \n",
            "  inflating: train/6741.png          \n",
            "  inflating: train/6742.png          \n",
            "  inflating: train/6743.png          \n",
            "  inflating: train/6744.png          \n",
            "  inflating: train/6745.png          \n",
            "  inflating: train/6746.png          \n",
            "  inflating: train/6747.png          \n",
            "  inflating: train/6748.png          \n",
            "  inflating: train/6749.png          \n",
            "  inflating: train/675.png           \n",
            "  inflating: train/6750.png          \n",
            "  inflating: train/6751.png          \n",
            "  inflating: train/6752.png          \n",
            "  inflating: train/6753.png          \n",
            "  inflating: train/6754.png          \n",
            "  inflating: train/6755.png          \n",
            "  inflating: train/6756.png          \n",
            "  inflating: train/6757.png          \n",
            "  inflating: train/6758.png          \n",
            "  inflating: train/6759.png          \n",
            "  inflating: train/676.png           \n",
            "  inflating: train/6760.png          \n",
            "  inflating: train/6761.png          \n",
            "  inflating: train/6762.png          \n",
            "  inflating: train/6763.png          \n",
            "  inflating: train/6764.png          \n",
            "  inflating: train/6765.png          \n",
            "  inflating: train/6766.png          \n",
            "  inflating: train/6767.png          \n",
            "  inflating: train/6768.png          \n",
            "  inflating: train/6769.png          \n",
            "  inflating: train/677.png           \n",
            "  inflating: train/6770.png          \n",
            "  inflating: train/6771.png          \n",
            "  inflating: train/6772.png          \n",
            "  inflating: train/6773.png          \n",
            "  inflating: train/6774.png          \n",
            "  inflating: train/6775.png          \n",
            "  inflating: train/6776.png          \n",
            "  inflating: train/6777.png          \n",
            "  inflating: train/6778.png          \n",
            "  inflating: train/6779.png          \n",
            "  inflating: train/678.png           \n",
            "  inflating: train/6780.png          \n",
            "  inflating: train/6781.png          \n",
            "  inflating: train/6782.png          \n",
            "  inflating: train/6783.png          \n",
            "  inflating: train/6784.png          \n",
            "  inflating: train/6785.png          \n",
            "  inflating: train/6786.png          \n",
            "  inflating: train/6787.png          \n",
            "  inflating: train/6788.png          \n",
            "  inflating: train/6789.png          \n",
            "  inflating: train/679.png           \n",
            "  inflating: train/6790.png          \n",
            "  inflating: train/6791.png          \n",
            "  inflating: train/6792.png          \n",
            "  inflating: train/6793.png          \n",
            "  inflating: train/6794.png          \n",
            "  inflating: train/6795.png          \n",
            "  inflating: train/6796.png          \n",
            "  inflating: train/6797.png          \n",
            "  inflating: train/6798.png          \n",
            "  inflating: train/6799.png          \n",
            "  inflating: train/68.png            \n",
            "  inflating: train/680.png           \n",
            "  inflating: train/6800.png          \n",
            "  inflating: train/6801.png          \n",
            "  inflating: train/6802.png          \n",
            "  inflating: train/6803.png          \n",
            "  inflating: train/6804.png          \n",
            "  inflating: train/6805.png          \n",
            "  inflating: train/6806.png          \n",
            "  inflating: train/6807.png          \n",
            "  inflating: train/6808.png          \n",
            "  inflating: train/6809.png          \n",
            "  inflating: train/681.png           \n",
            "  inflating: train/6810.png          \n",
            "  inflating: train/6811.png          \n",
            "  inflating: train/6812.png          \n",
            "  inflating: train/6813.png          \n",
            "  inflating: train/6814.png          \n",
            "  inflating: train/6815.png          \n",
            "  inflating: train/6816.png          \n",
            "  inflating: train/6817.png          \n",
            "  inflating: train/6818.png          \n",
            "  inflating: train/6819.png          \n",
            "  inflating: train/682.png           \n",
            "  inflating: train/6820.png          \n",
            "  inflating: train/6821.png          \n",
            "  inflating: train/6822.png          \n",
            "  inflating: train/6823.png          \n",
            "  inflating: train/6824.png          \n",
            "  inflating: train/6825.png          \n",
            "  inflating: train/6826.png          \n",
            "  inflating: train/6827.png          \n",
            "  inflating: train/6828.png          \n",
            "  inflating: train/6829.png          \n",
            "  inflating: train/683.png           \n",
            "  inflating: train/6830.png          \n",
            "  inflating: train/6831.png          \n",
            "  inflating: train/6832.png          \n",
            "  inflating: train/6833.png          \n",
            "  inflating: train/6834.png          \n",
            "  inflating: train/6835.png          \n",
            "  inflating: train/6836.png          \n",
            "  inflating: train/6837.png          \n",
            "  inflating: train/6838.png          \n",
            "  inflating: train/6839.png          \n",
            "  inflating: train/684.png           \n",
            "  inflating: train/6840.png          \n",
            "  inflating: train/6841.png          \n",
            "  inflating: train/6842.png          \n",
            "  inflating: train/6843.png          \n",
            "  inflating: train/6844.png          \n",
            "  inflating: train/6845.png          \n",
            "  inflating: train/6846.png          \n",
            "  inflating: train/6847.png          \n",
            "  inflating: train/6848.png          \n",
            "  inflating: train/6849.png          \n",
            "  inflating: train/685.png           \n",
            "  inflating: train/6850.png          \n",
            "  inflating: train/6851.png          \n",
            "  inflating: train/6852.png          \n",
            "  inflating: train/6853.png          \n",
            "  inflating: train/6854.png          \n",
            "  inflating: train/6855.png          \n",
            "  inflating: train/6856.png          \n",
            "  inflating: train/6857.png          \n",
            "  inflating: train/6858.png          \n",
            "  inflating: train/6859.png          \n",
            "  inflating: train/686.png           \n",
            "  inflating: train/6860.png          \n",
            "  inflating: train/6861.png          \n",
            "  inflating: train/6862.png          \n",
            "  inflating: train/6863.png          \n",
            "  inflating: train/6864.png          \n",
            "  inflating: train/6865.png          \n",
            "  inflating: train/6866.png          \n",
            "  inflating: train/6867.png          \n",
            "  inflating: train/6868.png          \n",
            "  inflating: train/6869.png          \n",
            "  inflating: train/687.png           \n",
            "  inflating: train/6870.png          \n",
            "  inflating: train/6871.png          \n",
            "  inflating: train/6872.png          \n",
            "  inflating: train/6873.png          \n",
            "  inflating: train/6874.png          \n",
            "  inflating: train/6875.png          \n",
            "  inflating: train/6876.png          \n",
            "  inflating: train/6877.png          \n",
            "  inflating: train/6878.png          \n",
            "  inflating: train/6879.png          \n",
            "  inflating: train/688.png           \n",
            "  inflating: train/6880.png          \n",
            "  inflating: train/6881.png          \n",
            "  inflating: train/6882.png          \n",
            "  inflating: train/6883.png          \n",
            "  inflating: train/6884.png          \n",
            "  inflating: train/6885.png          \n",
            "  inflating: train/6886.png          \n",
            "  inflating: train/6887.png          \n",
            "  inflating: train/6888.png          \n",
            "  inflating: train/6889.png          \n",
            "  inflating: train/689.png           \n",
            "  inflating: train/6890.png          \n",
            "  inflating: train/6891.png          \n",
            "  inflating: train/6892.png          \n",
            "  inflating: train/6893.png          \n",
            "  inflating: train/6894.png          \n",
            "  inflating: train/6895.png          \n",
            "  inflating: train/6896.png          \n",
            "  inflating: train/6897.png          \n",
            "  inflating: train/6898.png          \n",
            "  inflating: train/6899.png          \n",
            "  inflating: train/69.png            \n",
            "  inflating: train/690.png           \n",
            "  inflating: train/6900.png          \n",
            "  inflating: train/6901.png          \n",
            "  inflating: train/6902.png          \n",
            "  inflating: train/6903.png          \n",
            "  inflating: train/6904.png          \n",
            "  inflating: train/6905.png          \n",
            "  inflating: train/6906.png          \n",
            "  inflating: train/6907.png          \n",
            "  inflating: train/6908.png          \n",
            "  inflating: train/6909.png          \n",
            "  inflating: train/691.png           \n",
            "  inflating: train/6910.png          \n",
            "  inflating: train/6911.png          \n",
            "  inflating: train/6912.png          \n",
            "  inflating: train/6913.png          \n",
            "  inflating: train/6914.png          \n",
            "  inflating: train/6915.png          \n",
            "  inflating: train/6916.png          \n",
            "  inflating: train/6917.png          \n",
            "  inflating: train/6918.png          \n",
            "  inflating: train/6919.png          \n",
            "  inflating: train/692.png           \n",
            "  inflating: train/6920.png          \n",
            "  inflating: train/6921.png          \n",
            "  inflating: train/6922.png          \n",
            "  inflating: train/6923.png          \n",
            "  inflating: train/6924.png          \n",
            "  inflating: train/6925.png          \n",
            "  inflating: train/6926.png          \n",
            "  inflating: train/6927.png          \n",
            "  inflating: train/6928.png          \n",
            "  inflating: train/6929.png          \n",
            "  inflating: train/693.png           \n",
            "  inflating: train/6930.png          \n",
            "  inflating: train/6931.png          \n",
            "  inflating: train/6932.png          \n",
            "  inflating: train/6933.png          \n",
            "  inflating: train/6934.png          \n",
            "  inflating: train/6935.png          \n",
            "  inflating: train/6936.png          \n",
            "  inflating: train/6937.png          \n",
            "  inflating: train/6938.png          \n",
            "  inflating: train/6939.png          \n",
            "  inflating: train/694.png           \n",
            "  inflating: train/6940.png          \n",
            "  inflating: train/6941.png          \n",
            "  inflating: train/6942.png          \n",
            "  inflating: train/6943.png          \n",
            "  inflating: train/6944.png          \n",
            "  inflating: train/6945.png          \n",
            "  inflating: train/6946.png          \n",
            "  inflating: train/6947.png          \n",
            "  inflating: train/6948.png          \n",
            "  inflating: train/6949.png          \n",
            "  inflating: train/695.png           \n",
            "  inflating: train/6950.png          \n",
            "  inflating: train/6951.png          \n",
            "  inflating: train/6952.png          \n",
            "  inflating: train/6953.png          \n",
            "  inflating: train/6954.png          \n",
            "  inflating: train/6955.png          \n",
            "  inflating: train/6956.png          \n",
            "  inflating: train/6957.png          \n",
            "  inflating: train/6958.png          \n",
            "  inflating: train/6959.png          \n",
            "  inflating: train/696.png           \n",
            "  inflating: train/6960.png          \n",
            "  inflating: train/6961.png          \n",
            "  inflating: train/6962.png          \n",
            "  inflating: train/6963.png          \n",
            "  inflating: train/6964.png          \n",
            "  inflating: train/6965.png          \n",
            "  inflating: train/6966.png          \n",
            "  inflating: train/6967.png          \n",
            "  inflating: train/6968.png          \n",
            "  inflating: train/6969.png          \n",
            "  inflating: train/697.png           \n",
            "  inflating: train/6970.png          \n",
            "  inflating: train/6971.png          \n",
            "  inflating: train/6972.png          \n",
            "  inflating: train/6973.png          \n",
            "  inflating: train/6974.png          \n",
            "  inflating: train/6975.png          \n",
            "  inflating: train/6976.png          \n",
            "  inflating: train/6977.png          \n",
            "  inflating: train/6978.png          \n",
            "  inflating: train/6979.png          \n",
            "  inflating: train/698.png           \n",
            "  inflating: train/6980.png          \n",
            "  inflating: train/6981.png          \n",
            "  inflating: train/6982.png          \n",
            "  inflating: train/6983.png          \n",
            "  inflating: train/6984.png          \n",
            "  inflating: train/6985.png          \n",
            "  inflating: train/6986.png          \n",
            "  inflating: train/6987.png          \n",
            "  inflating: train/6988.png          \n",
            "  inflating: train/6989.png          \n",
            "  inflating: train/699.png           \n",
            "  inflating: train/6990.png          \n",
            "  inflating: train/6991.png          \n",
            "  inflating: train/6992.png          \n",
            "  inflating: train/6993.png          \n",
            "  inflating: train/6994.png          \n",
            "  inflating: train/6995.png          \n",
            "  inflating: train/6996.png          \n",
            "  inflating: train/6997.png          \n",
            "  inflating: train/6998.png          \n",
            "  inflating: train/6999.png          \n",
            "  inflating: train/7.png             \n",
            "  inflating: train/70.png            \n",
            "  inflating: train/700.png           \n",
            "  inflating: train/7000.png          \n",
            "  inflating: train/7001.png          \n",
            "  inflating: train/7002.png          \n",
            "  inflating: train/7003.png          \n",
            "  inflating: train/7004.png          \n",
            "  inflating: train/7005.png          \n",
            "  inflating: train/7006.png          \n",
            "  inflating: train/7007.png          \n",
            "  inflating: train/7008.png          \n",
            "  inflating: train/7009.png          \n",
            "  inflating: train/701.png           \n",
            "  inflating: train/7010.png          \n",
            "  inflating: train/7011.png          \n",
            "  inflating: train/7012.png          \n",
            "  inflating: train/7013.png          \n",
            "  inflating: train/7014.png          \n",
            "  inflating: train/7015.png          \n",
            "  inflating: train/7016.png          \n",
            "  inflating: train/7017.png          \n",
            "  inflating: train/7018.png          \n",
            "  inflating: train/7019.png          \n",
            "  inflating: train/702.png           \n",
            "  inflating: train/7020.png          \n",
            "  inflating: train/7021.png          \n",
            "  inflating: train/7022.png          \n",
            "  inflating: train/7023.png          \n",
            "  inflating: train/7024.png          \n",
            "  inflating: train/7025.png          \n",
            "  inflating: train/7026.png          \n",
            "  inflating: train/7027.png          \n",
            "  inflating: train/7028.png          \n",
            "  inflating: train/7029.png          \n",
            "  inflating: train/703.png           \n",
            "  inflating: train/7030.png          \n",
            "  inflating: train/7031.png          \n",
            "  inflating: train/7032.png          \n",
            "  inflating: train/7033.png          \n",
            "  inflating: train/7034.png          \n",
            "  inflating: train/7035.png          \n",
            "  inflating: train/7036.png          \n",
            "  inflating: train/7037.png          \n",
            "  inflating: train/7038.png          \n",
            "  inflating: train/7039.png          \n",
            "  inflating: train/704.png           \n",
            "  inflating: train/7040.png          \n",
            "  inflating: train/7041.png          \n",
            "  inflating: train/7042.png          \n",
            "  inflating: train/7043.png          \n",
            "  inflating: train/7044.png          \n",
            "  inflating: train/7045.png          \n",
            "  inflating: train/7046.png          \n",
            "  inflating: train/7047.png          \n",
            "  inflating: train/7048.png          \n",
            "  inflating: train/7049.png          \n",
            "  inflating: train/705.png           \n",
            "  inflating: train/7050.png          \n",
            "  inflating: train/7051.png          \n",
            "  inflating: train/7052.png          \n",
            "  inflating: train/7053.png          \n",
            "  inflating: train/7054.png          \n",
            "  inflating: train/7055.png          \n",
            "  inflating: train/7056.png          \n",
            "  inflating: train/7057.png          \n",
            "  inflating: train/7058.png          \n",
            "  inflating: train/7059.png          \n",
            "  inflating: train/706.png           \n",
            "  inflating: train/7060.png          \n",
            "  inflating: train/7061.png          \n",
            "  inflating: train/7062.png          \n",
            "  inflating: train/7063.png          \n",
            "  inflating: train/7064.png          \n",
            "  inflating: train/7065.png          \n",
            "  inflating: train/7066.png          \n",
            "  inflating: train/7067.png          \n",
            "  inflating: train/7068.png          \n",
            "  inflating: train/7069.png          \n",
            "  inflating: train/707.png           \n",
            "  inflating: train/7070.png          \n",
            "  inflating: train/7071.png          \n",
            "  inflating: train/7072.png          \n",
            "  inflating: train/7073.png          \n",
            "  inflating: train/7074.png          \n",
            "  inflating: train/7075.png          \n",
            "  inflating: train/7076.png          \n",
            "  inflating: train/7077.png          \n",
            "  inflating: train/7078.png          \n",
            "  inflating: train/7079.png          \n",
            "  inflating: train/708.png           \n",
            "  inflating: train/7080.png          \n",
            "  inflating: train/7081.png          \n",
            "  inflating: train/7082.png          \n",
            "  inflating: train/7083.png          \n",
            "  inflating: train/7084.png          \n",
            "  inflating: train/7085.png          \n",
            "  inflating: train/7086.png          \n",
            "  inflating: train/7087.png          \n",
            "  inflating: train/7088.png          \n",
            "  inflating: train/7089.png          \n",
            "  inflating: train/709.png           \n",
            "  inflating: train/7090.png          \n",
            "  inflating: train/7091.png          \n",
            "  inflating: train/7092.png          \n",
            "  inflating: train/7093.png          \n",
            "  inflating: train/7094.png          \n",
            "  inflating: train/7095.png          \n",
            "  inflating: train/7096.png          \n",
            "  inflating: train/7097.png          \n",
            "  inflating: train/7098.png          \n",
            "  inflating: train/7099.png          \n",
            "  inflating: train/71.png            \n",
            "  inflating: train/710.png           \n",
            "  inflating: train/7100.png          \n",
            "  inflating: train/7101.png          \n",
            "  inflating: train/7102.png          \n",
            "  inflating: train/7103.png          \n",
            "  inflating: train/7104.png          \n",
            "  inflating: train/7105.png          \n",
            "  inflating: train/7106.png          \n",
            "  inflating: train/7107.png          \n",
            "  inflating: train/7108.png          \n",
            "  inflating: train/7109.png          \n",
            "  inflating: train/711.png           \n",
            "  inflating: train/7110.png          \n",
            "  inflating: train/7111.png          \n",
            "  inflating: train/7112.png          \n",
            "  inflating: train/7113.png          \n",
            "  inflating: train/7114.png          \n",
            "  inflating: train/7115.png          \n",
            "  inflating: train/7116.png          \n",
            "  inflating: train/7117.png          \n",
            "  inflating: train/7118.png          \n",
            "  inflating: train/7119.png          \n",
            "  inflating: train/712.png           \n",
            "  inflating: train/7120.png          \n",
            "  inflating: train/7121.png          \n",
            "  inflating: train/7122.png          \n",
            "  inflating: train/7123.png          \n",
            "  inflating: train/7124.png          \n",
            "  inflating: train/7125.png          \n",
            "  inflating: train/7126.png          \n",
            "  inflating: train/7127.png          \n",
            "  inflating: train/7128.png          \n",
            "  inflating: train/7129.png          \n",
            "  inflating: train/713.png           \n",
            "  inflating: train/7130.png          \n",
            "  inflating: train/7131.png          \n",
            "  inflating: train/7132.png          \n",
            "  inflating: train/7133.png          \n",
            "  inflating: train/7134.png          \n",
            "  inflating: train/7135.png          \n",
            "  inflating: train/7136.png          \n",
            "  inflating: train/7137.png          \n",
            "  inflating: train/7138.png          \n",
            "  inflating: train/7139.png          \n",
            "  inflating: train/714.png           \n",
            "  inflating: train/7140.png          \n",
            "  inflating: train/7141.png          \n",
            "  inflating: train/7142.png          \n",
            "  inflating: train/7143.png          \n",
            "  inflating: train/7144.png          \n",
            "  inflating: train/7145.png          \n",
            "  inflating: train/7146.png          \n",
            "  inflating: train/7147.png          \n",
            "  inflating: train/7148.png          \n",
            "  inflating: train/7149.png          \n",
            "  inflating: train/715.png           \n",
            "  inflating: train/7150.png          \n",
            "  inflating: train/7151.png          \n",
            "  inflating: train/7152.png          \n",
            "  inflating: train/7153.png          \n",
            "  inflating: train/7154.png          \n",
            "  inflating: train/7155.png          \n",
            "  inflating: train/7156.png          \n",
            "  inflating: train/7157.png          \n",
            "  inflating: train/7158.png          \n",
            "  inflating: train/7159.png          \n",
            "  inflating: train/716.png           \n",
            "  inflating: train/7160.png          \n",
            "  inflating: train/7161.png          \n",
            "  inflating: train/7162.png          \n",
            "  inflating: train/7163.png          \n",
            "  inflating: train/7164.png          \n",
            "  inflating: train/7165.png          \n",
            "  inflating: train/7166.png          \n",
            "  inflating: train/7167.png          \n",
            "  inflating: train/7168.png          \n",
            "  inflating: train/7169.png          \n",
            "  inflating: train/717.png           \n",
            "  inflating: train/7170.png          \n",
            "  inflating: train/7171.png          \n",
            "  inflating: train/7172.png          \n",
            "  inflating: train/7173.png          \n",
            "  inflating: train/7174.png          \n",
            "  inflating: train/7175.png          \n",
            "  inflating: train/7176.png          \n",
            "  inflating: train/7177.png          \n",
            "  inflating: train/7178.png          \n",
            "  inflating: train/7179.png          \n",
            "  inflating: train/718.png           \n",
            "  inflating: train/7180.png          \n",
            "  inflating: train/7181.png          \n",
            "  inflating: train/7182.png          \n",
            "  inflating: train/7183.png          \n",
            "  inflating: train/7184.png          \n",
            "  inflating: train/7185.png          \n",
            "  inflating: train/7186.png          \n",
            "  inflating: train/7187.png          \n",
            "  inflating: train/7188.png          \n",
            "  inflating: train/7189.png          \n",
            "  inflating: train/719.png           \n",
            "  inflating: train/7190.png          \n",
            "  inflating: train/7191.png          \n",
            "  inflating: train/7192.png          \n",
            "  inflating: train/7193.png          \n",
            "  inflating: train/7194.png          \n",
            "  inflating: train/7195.png          \n",
            "  inflating: train/7196.png          \n",
            "  inflating: train/7197.png          \n",
            "  inflating: train/7198.png          \n",
            "  inflating: train/7199.png          \n",
            "  inflating: train/72.png            \n",
            "  inflating: train/720.png           \n",
            "  inflating: train/7200.png          \n",
            "  inflating: train/7201.png          \n",
            "  inflating: train/7202.png          \n",
            "  inflating: train/7203.png          \n",
            "  inflating: train/7204.png          \n",
            "  inflating: train/7205.png          \n",
            "  inflating: train/7206.png          \n",
            "  inflating: train/7207.png          \n",
            "  inflating: train/7208.png          \n",
            "  inflating: train/7209.png          \n",
            "  inflating: train/721.png           \n",
            "  inflating: train/7210.png          \n",
            "  inflating: train/7211.png          \n",
            "  inflating: train/7212.png          \n",
            "  inflating: train/7213.png          \n",
            "  inflating: train/7214.png          \n",
            "  inflating: train/7215.png          \n",
            "  inflating: train/7216.png          \n",
            "  inflating: train/7217.png          \n",
            "  inflating: train/7218.png          \n",
            "  inflating: train/7219.png          \n",
            "  inflating: train/722.png           \n",
            "  inflating: train/7220.png          \n",
            "  inflating: train/7221.png          \n",
            "  inflating: train/7222.png          \n",
            "  inflating: train/7223.png          \n",
            "  inflating: train/7224.png          \n",
            "  inflating: train/7225.png          \n",
            "  inflating: train/7226.png          \n",
            "  inflating: train/7227.png          \n",
            "  inflating: train/7228.png          \n",
            "  inflating: train/7229.png          \n",
            "  inflating: train/723.png           \n",
            "  inflating: train/7230.png          \n",
            "  inflating: train/7231.png          \n",
            "  inflating: train/7232.png          \n",
            "  inflating: train/7233.png          \n",
            "  inflating: train/7234.png          \n",
            "  inflating: train/7235.png          \n",
            "  inflating: train/7236.png          \n",
            "  inflating: train/7237.png          \n",
            "  inflating: train/7238.png          \n",
            "  inflating: train/7239.png          \n",
            "  inflating: train/724.png           \n",
            "  inflating: train/7240.png          \n",
            "  inflating: train/7241.png          \n",
            "  inflating: train/7242.png          \n",
            "  inflating: train/7243.png          \n",
            "  inflating: train/7244.png          \n",
            "  inflating: train/7245.png          \n",
            "  inflating: train/7246.png          \n",
            "  inflating: train/7247.png          \n",
            "  inflating: train/7248.png          \n",
            "  inflating: train/7249.png          \n",
            "  inflating: train/725.png           \n",
            "  inflating: train/7250.png          \n",
            "  inflating: train/7251.png          \n",
            "  inflating: train/7252.png          \n",
            "  inflating: train/7253.png          \n",
            "  inflating: train/7254.png          \n",
            "  inflating: train/7255.png          \n",
            "  inflating: train/7256.png          \n",
            "  inflating: train/7257.png          \n",
            "  inflating: train/7258.png          \n",
            "  inflating: train/7259.png          \n",
            "  inflating: train/726.png           \n",
            "  inflating: train/7260.png          \n",
            "  inflating: train/7261.png          \n",
            "  inflating: train/7262.png          \n",
            "  inflating: train/7263.png          \n",
            "  inflating: train/7264.png          \n",
            "  inflating: train/7265.png          \n",
            "  inflating: train/7266.png          \n",
            "  inflating: train/7267.png          \n",
            "  inflating: train/7268.png          \n",
            "  inflating: train/7269.png          \n",
            "  inflating: train/727.png           \n",
            "  inflating: train/7270.png          \n",
            "  inflating: train/7271.png          \n",
            "  inflating: train/7272.png          \n",
            "  inflating: train/7273.png          \n",
            "  inflating: train/7274.png          \n",
            "  inflating: train/7275.png          \n",
            "  inflating: train/7276.png          \n",
            "  inflating: train/7277.png          \n",
            "  inflating: train/7278.png          \n",
            "  inflating: train/7279.png          \n",
            "  inflating: train/728.png           \n",
            "  inflating: train/7280.png          \n",
            "  inflating: train/7281.png          \n",
            "  inflating: train/7282.png          \n",
            "  inflating: train/7283.png          \n",
            "  inflating: train/7284.png          \n",
            "  inflating: train/7285.png          \n",
            "  inflating: train/7286.png          \n",
            "  inflating: train/7287.png          \n",
            "  inflating: train/7288.png          \n",
            "  inflating: train/7289.png          \n",
            "  inflating: train/729.png           \n",
            "  inflating: train/7290.png          \n",
            "  inflating: train/7291.png          \n",
            "  inflating: train/7292.png          \n",
            "  inflating: train/7293.png          \n",
            "  inflating: train/7294.png          \n",
            "  inflating: train/7295.png          \n",
            "  inflating: train/7296.png          \n",
            "  inflating: train/7297.png          \n",
            "  inflating: train/7298.png          \n",
            "  inflating: train/7299.png          \n",
            "  inflating: train/73.png            \n",
            "  inflating: train/730.png           \n",
            "  inflating: train/7300.png          \n",
            "  inflating: train/7301.png          \n",
            "  inflating: train/7302.png          \n",
            "  inflating: train/7303.png          \n",
            "  inflating: train/7304.png          \n",
            "  inflating: train/7305.png          \n",
            "  inflating: train/7306.png          \n",
            "  inflating: train/7307.png          \n",
            "  inflating: train/7308.png          \n",
            "  inflating: train/7309.png          \n",
            "  inflating: train/731.png           \n",
            "  inflating: train/7310.png          \n",
            "  inflating: train/7311.png          \n",
            "  inflating: train/7312.png          \n",
            "  inflating: train/7313.png          \n",
            "  inflating: train/7314.png          \n",
            "  inflating: train/7315.png          \n",
            "  inflating: train/7316.png          \n",
            "  inflating: train/7317.png          \n",
            "  inflating: train/7318.png          \n",
            "  inflating: train/7319.png          \n",
            "  inflating: train/732.png           \n",
            "  inflating: train/7320.png          \n",
            "  inflating: train/7321.png          \n",
            "  inflating: train/7322.png          \n",
            "  inflating: train/7323.png          \n",
            "  inflating: train/7324.png          \n",
            "  inflating: train/7325.png          \n",
            "  inflating: train/7326.png          \n",
            "  inflating: train/7327.png          \n",
            "  inflating: train/7328.png          \n",
            "  inflating: train/7329.png          \n",
            "  inflating: train/733.png           \n",
            "  inflating: train/7330.png          \n",
            "  inflating: train/7331.png          \n",
            "  inflating: train/7332.png          \n",
            "  inflating: train/7333.png          \n",
            "  inflating: train/7334.png          \n",
            "  inflating: train/7335.png          \n",
            "  inflating: train/7336.png          \n",
            "  inflating: train/7337.png          \n",
            "  inflating: train/7338.png          \n",
            "  inflating: train/7339.png          \n",
            "  inflating: train/734.png           \n",
            "  inflating: train/7340.png          \n",
            "  inflating: train/7341.png          \n",
            "  inflating: train/7342.png          \n",
            "  inflating: train/7343.png          \n",
            "  inflating: train/7344.png          \n",
            "  inflating: train/7345.png          \n",
            "  inflating: train/7346.png          \n",
            "  inflating: train/7347.png          \n",
            "  inflating: train/7348.png          \n",
            "  inflating: train/7349.png          \n",
            "  inflating: train/735.png           \n",
            "  inflating: train/7350.png          \n",
            "  inflating: train/7351.png          \n",
            "  inflating: train/7352.png          \n",
            "  inflating: train/7353.png          \n",
            "  inflating: train/7354.png          \n",
            "  inflating: train/7355.png          \n",
            "  inflating: train/7356.png          \n",
            "  inflating: train/7357.png          \n",
            "  inflating: train/7358.png          \n",
            "  inflating: train/7359.png          \n",
            "  inflating: train/736.png           \n",
            "  inflating: train/7360.png          \n",
            "  inflating: train/7361.png          \n",
            "  inflating: train/7362.png          \n",
            "  inflating: train/7363.png          \n",
            "  inflating: train/7364.png          \n",
            "  inflating: train/7365.png          \n",
            "  inflating: train/7366.png          \n",
            "  inflating: train/7367.png          \n",
            "  inflating: train/7368.png          \n",
            "  inflating: train/7369.png          \n",
            "  inflating: train/737.png           \n",
            "  inflating: train/7370.png          \n",
            "  inflating: train/7371.png          \n",
            "  inflating: train/7372.png          \n",
            "  inflating: train/7373.png          \n",
            "  inflating: train/7374.png          \n",
            "  inflating: train/7375.png          \n",
            "  inflating: train/7376.png          \n",
            "  inflating: train/7377.png          \n",
            "  inflating: train/7378.png          \n",
            "  inflating: train/7379.png          \n",
            "  inflating: train/738.png           \n",
            "  inflating: train/7380.png          \n",
            "  inflating: train/7381.png          \n",
            "  inflating: train/7382.png          \n",
            "  inflating: train/7383.png          \n",
            "  inflating: train/7384.png          \n",
            "  inflating: train/7385.png          \n",
            "  inflating: train/7386.png          \n",
            "  inflating: train/7387.png          \n",
            "  inflating: train/7388.png          \n",
            "  inflating: train/7389.png          \n",
            "  inflating: train/739.png           \n",
            "  inflating: train/7390.png          \n",
            "  inflating: train/7391.png          \n",
            "  inflating: train/7392.png          \n",
            "  inflating: train/7393.png          \n",
            "  inflating: train/7394.png          \n",
            "  inflating: train/7395.png          \n",
            "  inflating: train/7396.png          \n",
            "  inflating: train/7397.png          \n",
            "  inflating: train/7398.png          \n",
            "  inflating: train/7399.png          \n",
            "  inflating: train/74.png            \n",
            "  inflating: train/740.png           \n",
            "  inflating: train/7400.png          \n",
            "  inflating: train/7401.png          \n",
            "  inflating: train/7402.png          \n",
            "  inflating: train/7403.png          \n",
            "  inflating: train/7404.png          \n",
            "  inflating: train/7405.png          \n",
            "  inflating: train/7406.png          \n",
            "  inflating: train/7407.png          \n",
            "  inflating: train/7408.png          \n",
            "  inflating: train/7409.png          \n",
            "  inflating: train/741.png           \n",
            "  inflating: train/7410.png          \n",
            "  inflating: train/7411.png          \n",
            "  inflating: train/7412.png          \n",
            "  inflating: train/7413.png          \n",
            "  inflating: train/7414.png          \n",
            "  inflating: train/7415.png          \n",
            "  inflating: train/7416.png          \n",
            "  inflating: train/7417.png          \n",
            "  inflating: train/7418.png          \n",
            "  inflating: train/7419.png          \n",
            "  inflating: train/742.png           \n",
            "  inflating: train/7420.png          \n",
            "  inflating: train/7421.png          \n",
            "  inflating: train/7422.png          \n",
            "  inflating: train/7423.png          \n",
            "  inflating: train/7424.png          \n",
            "  inflating: train/7425.png          \n",
            "  inflating: train/7426.png          \n",
            "  inflating: train/7427.png          \n",
            "  inflating: train/7428.png          \n",
            "  inflating: train/7429.png          \n",
            "  inflating: train/743.png           \n",
            "  inflating: train/7430.png          \n",
            "  inflating: train/7431.png          \n",
            "  inflating: train/7432.png          \n",
            "  inflating: train/7433.png          \n",
            "  inflating: train/7434.png          \n",
            "  inflating: train/7435.png          \n",
            "  inflating: train/7436.png          \n",
            "  inflating: train/7437.png          \n",
            "  inflating: train/7438.png          \n",
            "  inflating: train/7439.png          \n",
            "  inflating: train/744.png           \n",
            "  inflating: train/7440.png          \n",
            "  inflating: train/7441.png          \n",
            "  inflating: train/7442.png          \n",
            "  inflating: train/7443.png          \n",
            "  inflating: train/7444.png          \n",
            "  inflating: train/7445.png          \n",
            "  inflating: train/7446.png          \n",
            "  inflating: train/7447.png          \n",
            "  inflating: train/7448.png          \n",
            "  inflating: train/7449.png          \n",
            "  inflating: train/745.png           \n",
            "  inflating: train/7450.png          \n",
            "  inflating: train/7451.png          \n",
            "  inflating: train/7452.png          \n",
            "  inflating: train/7453.png          \n",
            "  inflating: train/7454.png          \n",
            "  inflating: train/7455.png          \n",
            "  inflating: train/7456.png          \n",
            "  inflating: train/7457.png          \n",
            "  inflating: train/7458.png          \n",
            "  inflating: train/7459.png          \n",
            "  inflating: train/746.png           \n",
            "  inflating: train/7460.png          \n",
            "  inflating: train/7461.png          \n",
            "  inflating: train/7462.png          \n",
            "  inflating: train/7463.png          \n",
            "  inflating: train/7464.png          \n",
            "  inflating: train/7465.png          \n",
            "  inflating: train/7466.png          \n",
            "  inflating: train/7467.png          \n",
            "  inflating: train/7468.png          \n",
            "  inflating: train/7469.png          \n",
            "  inflating: train/747.png           \n",
            "  inflating: train/7470.png          \n",
            "  inflating: train/7471.png          \n",
            "  inflating: train/7472.png          \n",
            "  inflating: train/7473.png          \n",
            "  inflating: train/7474.png          \n",
            "  inflating: train/7475.png          \n",
            "  inflating: train/7476.png          \n",
            "  inflating: train/7477.png          \n",
            "  inflating: train/7478.png          \n",
            "  inflating: train/7479.png          \n",
            "  inflating: train/748.png           \n",
            "  inflating: train/7480.png          \n",
            "  inflating: train/7481.png          \n",
            "  inflating: train/7482.png          \n",
            "  inflating: train/7483.png          \n",
            "  inflating: train/7484.png          \n",
            "  inflating: train/7485.png          \n",
            "  inflating: train/7486.png          \n",
            "  inflating: train/7487.png          \n",
            "  inflating: train/7488.png          \n",
            "  inflating: train/7489.png          \n",
            "  inflating: train/749.png           \n",
            "  inflating: train/7490.png          \n",
            "  inflating: train/7491.png          \n",
            "  inflating: train/7492.png          \n",
            "  inflating: train/7493.png          \n",
            "  inflating: train/7494.png          \n",
            "  inflating: train/7495.png          \n",
            "  inflating: train/7496.png          \n",
            "  inflating: train/7497.png          \n",
            "  inflating: train/7498.png          \n",
            "  inflating: train/7499.png          \n",
            "  inflating: train/75.png            \n",
            "  inflating: train/750.png           \n",
            "  inflating: train/7500.png          \n",
            "  inflating: train/7501.png          \n",
            "  inflating: train/7502.png          \n",
            "  inflating: train/7503.png          \n",
            "  inflating: train/7504.png          \n",
            "  inflating: train/7505.png          \n",
            "  inflating: train/7506.png          \n",
            "  inflating: train/7507.png          \n",
            "  inflating: train/7508.png          \n",
            "  inflating: train/7509.png          \n",
            "  inflating: train/751.png           \n",
            "  inflating: train/7510.png          \n",
            "  inflating: train/7511.png          \n",
            "  inflating: train/7512.png          \n",
            "  inflating: train/7513.png          \n",
            "  inflating: train/7514.png          \n",
            "  inflating: train/7515.png          \n",
            "  inflating: train/7516.png          \n",
            "  inflating: train/7517.png          \n",
            "  inflating: train/7518.png          \n",
            "  inflating: train/7519.png          \n",
            "  inflating: train/752.png           \n",
            "  inflating: train/7520.png          \n",
            "  inflating: train/7521.png          \n",
            "  inflating: train/7522.png          \n",
            "  inflating: train/7523.png          \n",
            "  inflating: train/7524.png          \n",
            "  inflating: train/7525.png          \n",
            "  inflating: train/7526.png          \n",
            "  inflating: train/7527.png          \n",
            "  inflating: train/7528.png          \n",
            "  inflating: train/7529.png          \n",
            "  inflating: train/753.png           \n",
            "  inflating: train/7530.png          \n",
            "  inflating: train/7531.png          \n",
            "  inflating: train/7532.png          \n",
            "  inflating: train/7533.png          \n",
            "  inflating: train/7534.png          \n",
            "  inflating: train/7535.png          \n",
            "  inflating: train/7536.png          \n",
            "  inflating: train/7537.png          \n",
            "  inflating: train/7538.png          \n",
            "  inflating: train/7539.png          \n",
            "  inflating: train/754.png           \n",
            "  inflating: train/7540.png          \n",
            "  inflating: train/7541.png          \n",
            "  inflating: train/7542.png          \n",
            "  inflating: train/7543.png          \n",
            "  inflating: train/7544.png          \n",
            "  inflating: train/7545.png          \n",
            "  inflating: train/7546.png          \n",
            "  inflating: train/7547.png          \n",
            "  inflating: train/7548.png          \n",
            "  inflating: train/7549.png          \n",
            "  inflating: train/755.png           \n",
            "  inflating: train/7550.png          \n",
            "  inflating: train/7551.png          \n",
            "  inflating: train/7552.png          \n",
            "  inflating: train/7553.png          \n",
            "  inflating: train/7554.png          \n",
            "  inflating: train/7555.png          \n",
            "  inflating: train/7556.png          \n",
            "  inflating: train/7557.png          \n",
            "  inflating: train/7558.png          \n",
            "  inflating: train/7559.png          \n",
            "  inflating: train/756.png           \n",
            "  inflating: train/7560.png          \n",
            "  inflating: train/757.png           \n",
            "  inflating: train/758.png           \n",
            "  inflating: train/759.png           \n",
            "  inflating: train/76.png            \n",
            "  inflating: train/760.png           \n",
            "  inflating: train/761.png           \n",
            "  inflating: train/762.png           \n",
            "  inflating: train/763.png           \n",
            "  inflating: train/764.png           \n",
            "  inflating: train/765.png           \n",
            "  inflating: train/766.png           \n",
            "  inflating: train/767.png           \n",
            "  inflating: train/768.png           \n",
            "  inflating: train/769.png           \n",
            "  inflating: train/77.png            \n",
            "  inflating: train/770.png           \n",
            "  inflating: train/771.png           \n",
            "  inflating: train/772.png           \n",
            "  inflating: train/773.png           \n",
            "  inflating: train/774.png           \n",
            "  inflating: train/775.png           \n",
            "  inflating: train/776.png           \n",
            "  inflating: train/777.png           \n",
            "  inflating: train/778.png           \n",
            "  inflating: train/779.png           \n",
            "  inflating: train/78.png            \n",
            "  inflating: train/780.png           \n",
            "  inflating: train/781.png           \n",
            "  inflating: train/782.png           \n",
            "  inflating: train/783.png           \n",
            "  inflating: train/784.png           \n",
            "  inflating: train/785.png           \n",
            "  inflating: train/786.png           \n",
            "  inflating: train/787.png           \n",
            "  inflating: train/788.png           \n",
            "  inflating: train/789.png           \n",
            "  inflating: train/79.png            \n",
            "  inflating: train/790.png           \n",
            "  inflating: train/791.png           \n",
            "  inflating: train/792.png           \n",
            "  inflating: train/793.png           \n",
            "  inflating: train/794.png           \n",
            "  inflating: train/795.png           \n",
            "  inflating: train/796.png           \n",
            "  inflating: train/797.png           \n",
            "  inflating: train/798.png           \n",
            "  inflating: train/799.png           \n",
            "  inflating: train/8.png             \n",
            "  inflating: train/80.png            \n",
            "  inflating: train/800.png           \n",
            "  inflating: train/801.png           \n",
            "  inflating: train/802.png           \n",
            "  inflating: train/803.png           \n",
            "  inflating: train/804.png           \n",
            "  inflating: train/805.png           \n",
            "  inflating: train/806.png           \n",
            "  inflating: train/807.png           \n",
            "  inflating: train/808.png           \n",
            "  inflating: train/809.png           \n",
            "  inflating: train/81.png            \n",
            "  inflating: train/810.png           \n",
            "  inflating: train/811.png           \n",
            "  inflating: train/812.png           \n",
            "  inflating: train/813.png           \n",
            "  inflating: train/814.png           \n",
            "  inflating: train/815.png           \n",
            "  inflating: train/816.png           \n",
            "  inflating: train/817.png           \n",
            "  inflating: train/818.png           \n",
            "  inflating: train/819.png           \n",
            "  inflating: train/82.png            \n",
            "  inflating: train/820.png           \n",
            "  inflating: train/821.png           \n",
            "  inflating: train/822.png           \n",
            "  inflating: train/823.png           \n",
            "  inflating: train/824.png           \n",
            "  inflating: train/825.png           \n",
            "  inflating: train/826.png           \n",
            "  inflating: train/827.png           \n",
            "  inflating: train/828.png           \n",
            "  inflating: train/829.png           \n",
            "  inflating: train/83.png            \n",
            "  inflating: train/830.png           \n",
            "  inflating: train/831.png           \n",
            "  inflating: train/832.png           \n",
            "  inflating: train/833.png           \n",
            "  inflating: train/834.png           \n",
            "  inflating: train/835.png           \n",
            "  inflating: train/836.png           \n",
            "  inflating: train/837.png           \n",
            "  inflating: train/838.png           \n",
            "  inflating: train/839.png           \n",
            "  inflating: train/84.png            \n",
            "  inflating: train/840.png           \n",
            "  inflating: train/841.png           \n",
            "  inflating: train/842.png           \n",
            "  inflating: train/843.png           \n",
            "  inflating: train/844.png           \n",
            "  inflating: train/845.png           \n",
            "  inflating: train/846.png           \n",
            "  inflating: train/847.png           \n",
            "  inflating: train/848.png           \n",
            "  inflating: train/849.png           \n",
            "  inflating: train/85.png            \n",
            "  inflating: train/850.png           \n",
            "  inflating: train/851.png           \n",
            "  inflating: train/852.png           \n",
            "  inflating: train/853.png           \n",
            "  inflating: train/854.png           \n",
            "  inflating: train/855.png           \n",
            "  inflating: train/856.png           \n",
            "  inflating: train/857.png           \n",
            "  inflating: train/858.png           \n",
            "  inflating: train/859.png           \n",
            "  inflating: train/86.png            \n",
            "  inflating: train/860.png           \n",
            "  inflating: train/861.png           \n",
            "  inflating: train/862.png           \n",
            "  inflating: train/863.png           \n",
            "  inflating: train/864.png           \n",
            "  inflating: train/865.png           \n",
            "  inflating: train/866.png           \n",
            "  inflating: train/867.png           \n",
            "  inflating: train/868.png           \n",
            "  inflating: train/869.png           \n",
            "  inflating: train/87.png            \n",
            "  inflating: train/870.png           \n",
            "  inflating: train/871.png           \n",
            "  inflating: train/872.png           \n",
            "  inflating: train/873.png           \n",
            "  inflating: train/874.png           \n",
            "  inflating: train/875.png           \n",
            "  inflating: train/876.png           \n",
            "  inflating: train/877.png           \n",
            "  inflating: train/878.png           \n",
            "  inflating: train/879.png           \n",
            "  inflating: train/88.png            \n",
            "  inflating: train/880.png           \n",
            "  inflating: train/881.png           \n",
            "  inflating: train/882.png           \n",
            "  inflating: train/883.png           \n",
            "  inflating: train/884.png           \n",
            "  inflating: train/885.png           \n",
            "  inflating: train/886.png           \n",
            "  inflating: train/887.png           \n",
            "  inflating: train/888.png           \n",
            "  inflating: train/889.png           \n",
            "  inflating: train/89.png            \n",
            "  inflating: train/890.png           \n",
            "  inflating: train/891.png           \n",
            "  inflating: train/892.png           \n",
            "  inflating: train/893.png           \n",
            "  inflating: train/894.png           \n",
            "  inflating: train/895.png           \n",
            "  inflating: train/896.png           \n",
            "  inflating: train/897.png           \n",
            "  inflating: train/898.png           \n",
            "  inflating: train/899.png           \n",
            "  inflating: train/9.png             \n",
            "  inflating: train/90.png            \n",
            "  inflating: train/900.png           \n",
            "  inflating: train/901.png           \n",
            "  inflating: train/902.png           \n",
            "  inflating: train/903.png           \n",
            "  inflating: train/904.png           \n",
            "  inflating: train/905.png           \n",
            "  inflating: train/906.png           \n",
            "  inflating: train/907.png           \n",
            "  inflating: train/908.png           \n",
            "  inflating: train/909.png           \n",
            "  inflating: train/91.png            \n",
            "  inflating: train/910.png           \n",
            "  inflating: train/911.png           \n",
            "  inflating: train/912.png           \n",
            "  inflating: train/913.png           \n",
            "  inflating: train/914.png           \n",
            "  inflating: train/915.png           \n",
            "  inflating: train/916.png           \n",
            "  inflating: train/917.png           \n",
            "  inflating: train/918.png           \n",
            "  inflating: train/919.png           \n",
            "  inflating: train/92.png            \n",
            "  inflating: train/920.png           \n",
            "  inflating: train/921.png           \n",
            "  inflating: train/922.png           \n",
            "  inflating: train/923.png           \n",
            "  inflating: train/924.png           \n",
            "  inflating: train/925.png           \n",
            "  inflating: train/926.png           \n",
            "  inflating: train/927.png           \n",
            "  inflating: train/928.png           \n",
            "  inflating: train/929.png           \n",
            "  inflating: train/93.png            \n",
            "  inflating: train/930.png           \n",
            "  inflating: train/931.png           \n",
            "  inflating: train/932.png           \n",
            "  inflating: train/933.png           \n",
            "  inflating: train/934.png           \n",
            "  inflating: train/935.png           \n",
            "  inflating: train/936.png           \n",
            "  inflating: train/937.png           \n",
            "  inflating: train/938.png           \n",
            "  inflating: train/939.png           \n",
            "  inflating: train/94.png            \n",
            "  inflating: train/940.png           \n",
            "  inflating: train/941.png           \n",
            "  inflating: train/942.png           \n",
            "  inflating: train/943.png           \n",
            "  inflating: train/944.png           \n",
            "  inflating: train/945.png           \n",
            "  inflating: train/946.png           \n",
            "  inflating: train/947.png           \n",
            "  inflating: train/948.png           \n",
            "  inflating: train/949.png           \n",
            "  inflating: train/95.png            \n",
            "  inflating: train/950.png           \n",
            "  inflating: train/951.png           \n",
            "  inflating: train/952.png           \n",
            "  inflating: train/953.png           \n",
            "  inflating: train/954.png           \n",
            "  inflating: train/955.png           \n",
            "  inflating: train/956.png           \n",
            "  inflating: train/957.png           \n",
            "  inflating: train/958.png           \n",
            "  inflating: train/959.png           \n",
            "  inflating: train/96.png            \n",
            "  inflating: train/960.png           \n",
            "  inflating: train/961.png           \n",
            "  inflating: train/962.png           \n",
            "  inflating: train/963.png           \n",
            "  inflating: train/964.png           \n",
            "  inflating: train/965.png           \n",
            "  inflating: train/966.png           \n",
            "  inflating: train/967.png           \n",
            "  inflating: train/968.png           \n",
            "  inflating: train/969.png           \n",
            "  inflating: train/97.png            \n",
            "  inflating: train/970.png           \n",
            "  inflating: train/971.png           \n",
            "  inflating: train/972.png           \n",
            "  inflating: train/973.png           \n",
            "  inflating: train/974.png           \n",
            "  inflating: train/975.png           \n",
            "  inflating: train/976.png           \n",
            "  inflating: train/977.png           \n",
            "  inflating: train/978.png           \n",
            "  inflating: train/979.png           \n",
            "  inflating: train/98.png            \n",
            "  inflating: train/980.png           \n",
            "  inflating: train/981.png           \n",
            "  inflating: train/982.png           \n",
            "  inflating: train/983.png           \n",
            "  inflating: train/984.png           \n",
            "  inflating: train/985.png           \n",
            "  inflating: train/986.png           \n",
            "  inflating: train/987.png           \n",
            "  inflating: train/988.png           \n",
            "  inflating: train/989.png           \n",
            "  inflating: train/99.png            \n",
            "  inflating: train/990.png           \n",
            "  inflating: train/991.png           \n",
            "  inflating: train/992.png           \n",
            "  inflating: train/993.png           \n",
            "  inflating: train/994.png           \n",
            "  inflating: train/995.png           \n",
            "  inflating: train/996.png           \n",
            "  inflating: train/997.png           \n",
            "  inflating: train/998.png           \n",
            "  inflating: train/999.png           \n"
          ]
        }
      ],
      "source": [
        "!unzip deep-learning-for-msc-2022-23.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hxVhJb_20sq2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('example.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CH7o6GohUwZq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "use_cuda = True\n",
        "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "j2RFDmsO0_bI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, self.df.iloc[idx, 0])\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = self.df.iloc[idx, 1]\n",
        "        return image, label\n",
        "\n",
        "# Define image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomPerspective(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Load custom train dataset using the defined class\n",
        "train_dataset = CustomDataset('train.csv', 'train', transform=transform)\n",
        "\n",
        "# Load custom test dataset using the defined class\n",
        "test_dataset = CustomDataset('example.csv', 'test', transform=transform)\n",
        "\n",
        "# Create DataLoader for batching and shuffling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJIyMNaNKGgp",
        "outputId": "21557277-3008-4af9-de0b-a872c62bf46b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          ...,\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
              " \n",
              "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          ...,\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
              " \n",
              "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          ...,\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "          [-1., -1., -1.,  ..., -1., -1., -1.]]]), 0)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kWuFsgOGKbXo"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_data, val_data = random_split(train_dataset, [train_size, val_size])\n",
        "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "val_dataloader = DataLoader(val_data, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1R_VNGhuJVXS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vep2UZJHPrHl"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import torch.nn as nn\n",
        "'''model = nn.Sequential(collections.OrderedDict([\n",
        "          ('conv1', nn.Conv2d(3,1024,3,padding=1)),\n",
        "          ('batch1',nn.Batchnorm2d(1024)),\n",
        "          ('relu1', nn.ReLU()),\n",
        "\n",
        "          ('conv2', nn.Conv2d(1024,512,3,padding=1)),\n",
        "          ('batch2',nn.Batchnorm2d(512)),\n",
        "          ('relu2', nn.ReLU()),\n",
        "          ('conv3', nn.Conv2d(512,256,3,padding=1)),\n",
        "          ('batch3',nn.Batchnorm2d(256)),\n",
        "          ('relu3', nn.ReLU()),\n",
        "          ('conv4', nn.Conv2d(256,128,3,padding=1)),\n",
        "          ('batch4',nn.Batchnorm2d(128)),\n",
        "          ('relu4', nn.ReLU()),\n",
        "          ('conv5', nn.Conv2d(128,64,3,padding=1)),\n",
        "          ('batch5',nn.Batchnorm2d(64))\n",
        "          ('relu5', nn.ReLU()),\n",
        "\n",
        "          # Put in a linear layers ...\n",
        "          ('flatten', nn.Flatten()),                                    \n",
        "          ('fc1', nn.Linear(64*100*100,1024)),\n",
        "          ('relu6', nn.ReLU()),\n",
        "          ('fc2', nn.Linear(1024,4)),\n",
        "          nn.Dropout(0.5),\n",
        "        ]))'''\n",
        "model = nn.Sequential(collections.OrderedDict([\n",
        "    ('conv1', nn.Conv2d(3, 32, kernel_size=3, padding=1)),\n",
        "    ('batch1', nn.BatchNorm2d(32)),\n",
        "    ('relu1', nn.ReLU()),\n",
        "    #('maxpool1', nn.MaxPool2d(kernel_size=2)),\n",
        "\n",
        "    ('conv2', nn.Conv2d(32, 64, kernel_size=3, padding=1)),\n",
        "    ('batch2', nn.BatchNorm2d(64)),\n",
        "    ('relu2', nn.ReLU()),\n",
        "    #('maxpool2', nn.MaxPool2d(kernel_size=2)),\n",
        "\n",
        "    ('conv3', nn.Conv2d(64, 128, kernel_size=3, padding=1)),\n",
        "    ('batch3', nn.BatchNorm2d(128)),\n",
        "    ('relu3', nn.ReLU()),\n",
        "    #('maxpool3', nn.MaxPool2d(kernel_size=2)),\n",
        "\n",
        "    ('conv4', nn.Conv2d(128, 256, kernel_size=3, padding=1)),\n",
        "    ('batch4', nn.BatchNorm2d(256)),\n",
        "    ('relu4', nn.ReLU()),\n",
        "    #('maxpool4', nn.MaxPool2d(kernel_size=2)),\n",
        "\n",
        "     ('conv5', nn.Conv2d(256, 64, kernel_size=3, padding=1)),\n",
        "    ('batch5', nn.BatchNorm2d(64)),\n",
        "    ('relu5', nn.ReLU()),\n",
        "    #('maxpool5', nn.MaxPool2d(kernel_size=2)),\n",
        "\n",
        "    ('conv6', nn.Conv2d(64, 32, kernel_size=3, padding=1)),\n",
        "    ('batch6', nn.BatchNorm2d(32)),\n",
        "    ('relu6', nn.ReLU()),\n",
        "    #('maxpool6', nn.MaxPool2d(kernel_size=2)),\n",
        "\n",
        "    ('flatten', nn.Flatten()),\n",
        "    ('fc1', nn.Linear(32 * 100 * 100, 1024)),\n",
        "    ('relu7', nn.ReLU()),\n",
        "    ('dropout', nn.Dropout(0.5)),\n",
        "    ('fc2', nn.Linear(1024, 4))\n",
        "]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRH-OPqASBaB",
        "outputId": "3ae24e62-d39e-479f-99d3-03e667bc4f43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CNN Network Model:\n",
            "Sequential(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (batch1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu1): ReLU()\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (batch2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu2): ReLU()\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (batch3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu3): ReLU()\n",
            "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (batch4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu4): ReLU()\n",
            "  (conv5): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (batch5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu5): ReLU()\n",
            "  (conv6): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (batch6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu6): ReLU()\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (fc1): Linear(in_features=320000, out_features=1024, bias=True)\n",
            "  (relu7): ReLU()\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc2): Linear(in_features=1024, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nCNN Network Model:\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iVKVYiQeUe2A"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "epoch_print_gap = 1\n",
        "def training_loop(n_epochs, optimizer, model, device, loss_fn, train_loader,test_loader):\n",
        "    model = model.to(device)\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:\n",
        "            outputs = model(imgs.to(device))\n",
        "            loss = loss_fn(outputs, labels.to(device))\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            loss_train += loss.item()\n",
        "            \n",
        "        if epoch == 1 or epoch % epoch_print_gap == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch, float(loss_train)))\n",
        "        model.eval()\n",
        "        model = model.to(device)\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output = model(data)\n",
        "                test_loss += F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
        "                pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        test_loss /= len(test_loader.dataset)\n",
        "\n",
        "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            test_loss, correct, len(test_loader.dataset),\n",
        "            100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "def test_loop(model, device, test_loader):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer2 = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.001, betas=(0.9, 0.999))"
      ],
      "metadata": {
        "id": "99O6kz9NGhPO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "raFYiUg5SIPD",
        "outputId": "fc13b126-3533-47d4-a23e-29326b8a5ae1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-7907df5783c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m training_loop(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-469f5077a2f4>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(n_epochs, optimizer, model, device, loss_fn, train_loader, test_loader)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "n_epochs = 10\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001,momentum = 0.9)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = n_epochs, \n",
        "    optimizer = optimizer2,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    device= device,\n",
        "    train_loader = train_dataloader,\n",
        "    test_loader = val_dataloader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XbGysJeAGrVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9M2ULrPNVPTX"
      },
      "outputs": [],
      "source": [
        "test_loop(model = model, device = device, test_loader = val_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckhbP2FHV-g8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "# Define the transforms for the train and test datasets\n",
        "train_transform = transforms.Compose([\n",
        "    \n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    #transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    \n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    #transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the train and test datasets\n",
        "train_dataset = CustomDataset('train.csv', 'train', transform=train_transform)\n",
        "train_dataloader2 = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Load the pre-trained ResNet18 model\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "# Replace the last layer of the model to fit the number of classes in your dataset\n",
        "num_classes = 4\n",
        "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, betas=(0.9,0.999),weight_decay=0.0001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.train()\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_dataloader2):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # Print every 100 batches\n",
        "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
        "            running_loss = 0.0\n",
        "\n",
        "# Evaluate the model on the test dataset and store the predicted labels in a list\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gseeP8WRTD02",
        "outputId": "a7901181-25f2-46cf-82f6-d43ee8e6161f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 0.407\n",
            "[1,   200] loss: 0.196\n",
            "[2,   100] loss: 0.081\n",
            "[2,   200] loss: 0.083\n",
            "[3,   100] loss: 0.048\n",
            "[3,   200] loss: 0.042\n",
            "[4,   100] loss: 0.039\n",
            "[4,   200] loss: 0.035\n",
            "[5,   100] loss: 0.022\n",
            "[5,   200] loss: 0.028\n",
            "[6,   100] loss: 0.017\n",
            "[6,   200] loss: 0.026\n",
            "[7,   100] loss: 0.015\n",
            "[7,   200] loss: 0.018\n",
            "[8,   100] loss: 0.009\n",
            "[8,   200] loss: 0.014\n",
            "[9,   200] loss: 0.018\n",
            "[10,   100] loss: 0.019\n",
            "[10,   200] loss: 0.019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4KYXZuLQrjz4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loop(model = model, device = device, test_loader = val_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "DOFMXAUIue1h",
        "outputId": "bf2d5567-f846-46a9-cd7d-3bf81c7a031c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-c92465d34618>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test_loop' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "class CustomtestDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, self.df.iloc[idx, 0])\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, img_name\n",
        "\n",
        "test_dataset = CustomtestDataset('example.csv','test',test_transform)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Make predictions on test dataset\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    predicted_labels = []\n",
        "    f_names = []\n",
        "    for inputs,names in test_dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        predicted_labels += preds.tolist()\n",
        "        f_names+=[i.split('/')[-1] for i in names]"
      ],
      "metadata": {
        "id": "5CBYiVPhTV6o"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.unique(predicted_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdafzD5cfe2H",
        "outputId": "336f0719-b1cb-4c8c-925c-50373f9a9f58"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pretrained=pd.read_csv('example.csv')\n",
        "pretrained['Filename'] = f_names\n",
        "pretrained['Label'] = predicted_labels"
      ],
      "metadata": {
        "id": "D6OQ858oi8iK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained.to_csv('pretrained.csv')"
      ],
      "metadata": {
        "id": "FNeKoxdslrJX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ray"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuZogoMOA73b",
        "outputId": "65caa716-16dc-4adc-80b7-2458a9339e5a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ray\n",
            "  Downloading ray-2.3.1-cp39-cp39-manylinux2014_x86_64.whl (58.6 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m58.6/58.6 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.9/dist-packages (from ray) (22.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from ray) (2.27.1)\n",
            "Collecting virtualenv>=20.0.24\n",
            "  Downloading virtualenv-20.21.0-py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.9/dist-packages (from ray) (1.51.3)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from ray) (1.0.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from ray) (3.10.1)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.9/dist-packages (from ray) (3.19.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from ray) (6.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.9/dist-packages (from ray) (4.3.3)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.9/dist-packages (from ray) (1.22.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/dist-packages (from ray) (8.1.3)\n",
            "Collecting aiosignal\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting frozenlist\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distlib<1,>=0.3.6\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m468.5/468.5 KB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs<4,>=2.4 in /usr/local/lib/python3.9/dist-packages (from virtualenv>=20.0.24->ray) (3.1.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema->ray) (0.19.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->ray) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->ray) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->ray) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->ray) (2022.12.7)\n",
            "Installing collected packages: distlib, virtualenv, frozenlist, aiosignal, ray\n",
            "Successfully installed aiosignal-1.3.1 distlib-0.3.6 frozenlist-1.3.3 ray-2.3.1 virtualenv-20.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "# Define your training function\n",
        "def train_model(config):\n",
        "    model = torchvision.models.resnet18(pretrained=True)\n",
        "    train_transform = transforms.Compose([\n",
        "    \n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    #transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        \n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        #transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "# Replace the last layer of the model to fit the number of classes in your dataset\n",
        "    num_classes = 4\n",
        "    model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"], betas = (0.9,0.999),weight_decay=config[\"weight_decay\"])\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    train_dataset2 = CustomDataset('/content/train.csv', '/content/train', transform=train_transform)\n",
        "    train_size = int(0.8 * len(train_dataset2))\n",
        "    val_size = len(train_dataset2) - train_size\n",
        "    train_data, val_data = random_split(train_dataset2, [train_size, val_size])\n",
        "    train_loader = DataLoader(train_data, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "    val_loader = DataLoader(val_data, batch_size=config[\"batch_size\"], shuffle=False)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    for epoch in range(20):\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            if i % 100 == 99:  # Print every 100 batches\n",
        "                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
        "                running_loss = 0.0\n",
        "        \n",
        "        # Evaluate on validation set\n",
        "        with torch.no_grad():\n",
        "            total_loss = 0\n",
        "            total_correct = 0\n",
        "            total_samples = 0\n",
        "            for inputs, targets in val_loader:\n",
        "                inputs,targets = inputs.to(device),targets.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "                total_loss += loss.item() * inputs.size(0)\n",
        "                total_correct += (outputs.argmax(1) == targets).sum().item()\n",
        "                total_samples += inputs.size(0)\n",
        "            val_loss = total_loss / total_samples\n",
        "            val_acc = total_correct / total_samples\n",
        "\n",
        "        # Report the validation metric for this epoch\n",
        "        tune.report(val_loss=val_loss, val_acc=val_acc)\n",
        "    \n",
        "    # Return the final validation metric\n",
        "    return {\"val_loss\": val_loss, \"val_acc\": val_acc}\n",
        "\n",
        "# Set up the configuration dictionary\n",
        "config = {\n",
        "    \"lr\": tune.choice([1e-2, 1e-3,1e-4]),\n",
        "    \"weight_decay\": tune.choice([1e-4, 1e-1,1e-2,1e-3]),\n",
        "    \"batch_size\": tune.choice([16,32, 64]),\n",
        "    \"num_epochs\": 10\n",
        "}\n",
        "\n",
        "# Set up the Ray Tune scheduler and reporter\n",
        "scheduler = ASHAScheduler(\n",
        "    metric=\"val_acc\",\n",
        "    mode=\"max\",\n",
        "    max_t=10,\n",
        "    grace_period=1,\n",
        "    reduction_factor=2\n",
        ")\n",
        "reporter = CLIReporter(metric_columns=[\"val_loss\", \"val_acc\", \"training_iteration\"])\n",
        "\n",
        "# Start the Ray Tune search\n",
        "result = tune.run(\n",
        "    train_model,\n",
        "    resources_per_trial={\"cpu\": 2,\"gpu\":1},\n",
        "    config=config,\n",
        "    num_samples=10,\n",
        "    scheduler=scheduler,\n",
        "    progress_reporter=reporter\n",
        ")\n",
        "\n",
        "# Print the best hyperparameters found\n",
        "best_trial = result.get_best_trial(\"val_acc\", \"max\", \"last\")\n",
        "print(\"Best trial config: {}\".format(best_trial.config))\n",
        "print(\"Best trial final validation loss: {}\".format(best_trial.last_result[\"val_loss\"]))\n",
        "print(\"Best trial final validation accuracy: {}\".format(best_trial.last_result[\"val_acc\"]))"
      ],
      "metadata": {
        "id": "OVUjj7TM4ueP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eb48ed17-a7f3-4860-bc07-215e63968547"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-03-26 09:57:59,473\tWARNING callback.py:108 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Status ==\n",
            "Current time: 2023-03-26 09:57:59 (running for 00:00:00.16)\n",
            "Memory usage on this node: 1.4/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_model pid=7402)\u001b[0m /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\u001b[2m\u001b[36m(train_model pid=7402)\u001b[0m   warnings.warn(\n",
            "\u001b[2m\u001b[36m(train_model pid=7402)\u001b[0m /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\u001b[2m\u001b[36m(train_model pid=7402)\u001b[0m   warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Status ==\n",
            "Current time: 2023-03-26 09:58:08 (running for 00:00:08.53)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 09:58:13 (running for 00:00:13.54)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 09:58:18 (running for 00:00:18.54)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 09:58:23 (running for 00:00:23.56)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"trialProgress\">\n",
              "  <h3>Trial Progress</h3>\n",
              "  <table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>hostname    </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip    </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  val_acc</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_model_b08dd_00000</td><td>2023-03-26_10-00-58</td><td>True  </td><td>                </td><td>89e17e4f4a054329b8e480dd72ee6ba8</td><td>8dd8dad0ce47</td><td style=\"text-align: right;\">                        10</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 7402</td><td style=\"text-align: right;\">            175.374 </td><td style=\"text-align: right;\">           16.8467</td><td style=\"text-align: right;\">      175.374 </td><td style=\"text-align: right;\"> 1679824858</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>b08dd_00000</td><td style=\"text-align: right;\"> 0.906746</td><td style=\"text-align: right;\"> 0.253129 </td><td style=\"text-align: right;\">   0.00538826</td></tr>\n",
              "<tr><td>train_model_b08dd_00001</td><td>2023-03-26_10-04-09</td><td>True  </td><td>                </td><td>a9f2c1ca989a4b00b2b5b7ecb95b7483</td><td>8dd8dad0ce47</td><td style=\"text-align: right;\">                        10</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 8246</td><td style=\"text-align: right;\">            186.265 </td><td style=\"text-align: right;\">           17.6962</td><td style=\"text-align: right;\">      186.265 </td><td style=\"text-align: right;\"> 1679825049</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>b08dd_00001</td><td style=\"text-align: right;\"> 0.979497</td><td style=\"text-align: right;\"> 0.0679228</td><td style=\"text-align: right;\">   0.00527954</td></tr>\n",
              "<tr><td>train_model_b08dd_00002</td><td>2023-03-26_10-04-39</td><td>True  </td><td>                </td><td>5b31efdc48d94068a0778dabcafd3281</td><td>8dd8dad0ce47</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 9148</td><td style=\"text-align: right;\">             25.6816</td><td style=\"text-align: right;\">           25.6816</td><td style=\"text-align: right;\">       25.6816</td><td style=\"text-align: right;\"> 1679825079</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>b08dd_00002</td><td style=\"text-align: right;\"> 0.755952</td><td style=\"text-align: right;\"> 0.722136 </td><td style=\"text-align: right;\">   0.00426817</td></tr>\n",
              "<tr><td>train_model_b08dd_00003</td><td>2023-03-26_10-07-39</td><td>True  </td><td>                </td><td>659c3325b7a04f9a96425b1466e26112</td><td>8dd8dad0ce47</td><td style=\"text-align: right;\">                        10</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 9334</td><td style=\"text-align: right;\">            174.295 </td><td style=\"text-align: right;\">           16.1821</td><td style=\"text-align: right;\">      174.295 </td><td style=\"text-align: right;\"> 1679825259</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>b08dd_00003</td><td style=\"text-align: right;\"> 0.953704</td><td style=\"text-align: right;\"> 0.175405 </td><td style=\"text-align: right;\">   0.00464129</td></tr>\n",
              "<tr><td>train_model_b08dd_00004</td><td>2023-03-26_10-10-27</td><td>True  </td><td>                </td><td>7ca2e93ec7e74af595124a71c4cf1e74</td><td>8dd8dad0ce47</td><td style=\"text-align: right;\">                        10</td><td>172.28.0.12</td><td style=\"text-align: right;\">10179</td><td style=\"text-align: right;\">            164.938 </td><td style=\"text-align: right;\">           16.652 </td><td style=\"text-align: right;\">      164.938 </td><td style=\"text-align: right;\"> 1679825427</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>b08dd_00004</td><td style=\"text-align: right;\"> 0.974868</td><td style=\"text-align: right;\"> 0.100318 </td><td style=\"text-align: right;\">   0.00503731</td></tr>\n",
              "<tr><td>train_model_b08dd_00005</td><td>2023-03-26_10-10-58</td><td>True  </td><td>                </td><td>ddb821ddce5b4042abf9b284c88b35a5</td><td>8dd8dad0ce47</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">10972</td><td style=\"text-align: right;\">             25.6881</td><td style=\"text-align: right;\">           25.6881</td><td style=\"text-align: right;\">       25.6881</td><td style=\"text-align: right;\"> 1679825458</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>b08dd_00005</td><td style=\"text-align: right;\"> 0.787037</td><td style=\"text-align: right;\"> 0.571221 </td><td style=\"text-align: right;\">   0.00611115</td></tr>\n",
              "<tr><td>train_model_b08dd_00006</td><td>2023-03-26_10-11-25</td><td>True  </td><td>                </td><td>5a04901befd14254930c4892a74c1c71</td><td>8dd8dad0ce47</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">11157</td><td style=\"text-align: right;\">             21.7171</td><td style=\"text-align: right;\">           21.7171</td><td style=\"text-align: right;\">       21.7171</td><td style=\"text-align: right;\"> 1679825485</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>b08dd_00006</td><td style=\"text-align: right;\"> 0.804894</td><td style=\"text-align: right;\"> 0.542324 </td><td style=\"text-align: right;\">   0.00676107</td></tr>\n",
              "<tr><td>train_model_b08dd_00007</td><td>2023-03-26_10-11-56</td><td>True  </td><td>                </td><td>c107a6bee20441dbb6a5e44d10b53fc4</td><td>8dd8dad0ce47</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">11323</td><td style=\"text-align: right;\">             26.5777</td><td style=\"text-align: right;\">           26.5777</td><td style=\"text-align: right;\">       26.5777</td><td style=\"text-align: right;\"> 1679825516</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>b08dd_00007</td><td style=\"text-align: right;\"> 0.76918 </td><td style=\"text-align: right;\"> 0.613641 </td><td style=\"text-align: right;\">   0.00414228</td></tr>\n",
              "<tr><td>train_model_b08dd_00008</td><td>2023-03-26_10-14-32</td><td>True  </td><td>                </td><td>60d1f3ccadee48a3b5f4544932af37b2</td><td>8dd8dad0ce47</td><td style=\"text-align: right;\">                         8</td><td>172.28.0.12</td><td style=\"text-align: right;\">11499</td><td style=\"text-align: right;\">            153.312 </td><td style=\"text-align: right;\">           18.266 </td><td style=\"text-align: right;\">      153.312 </td><td style=\"text-align: right;\"> 1679825672</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   8</td><td>b08dd_00008</td><td style=\"text-align: right;\"> 0.960317</td><td style=\"text-align: right;\"> 0.115943 </td><td style=\"text-align: right;\">   0.00409126</td></tr>\n",
              "<tr><td>train_model_b08dd_00009</td><td>2023-03-26_10-15-28</td><td>True  </td><td>                </td><td>638763e809e048deabac02075d3a02e5</td><td>8dd8dad0ce47</td><td style=\"text-align: right;\">                         2</td><td>172.28.0.12</td><td style=\"text-align: right;\">12252</td><td style=\"text-align: right;\">             51.7813</td><td style=\"text-align: right;\">           24.0609</td><td style=\"text-align: right;\">       51.7813</td><td style=\"text-align: right;\"> 1679825728</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   2</td><td>b08dd_00009</td><td style=\"text-align: right;\"> 0.919974</td><td style=\"text-align: right;\"> 0.233204 </td><td style=\"text-align: right;\">   0.00514102</td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</div>\n",
              "<style>\n",
              ".trialProgress {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".trialProgress h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".trialProgress td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Status ==\n",
            "Current time: 2023-03-26 09:58:29 (running for 00:00:29.58)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.484625 |  0.811508 |                    1 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 09:58:34 (running for 00:00:34.60)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.484625 |  0.811508 |                    1 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 09:58:39 (running for 00:00:39.61)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.484625 |  0.811508 |                    1 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 09:58:45 (running for 00:00:46.25)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |    0.44494 |  0.833995 |                    2 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 09:58:50 (running for 00:00:51.26)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |    0.44494 |  0.833995 |                    2 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 09:58:55 (running for 00:00:56.27)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |    0.44494 |  0.833995 |                    2 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 09:59:02 (running for 00:01:03.24)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.347562 |  0.857143 |                    3 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 09:59:07 (running for 00:01:08.25)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.347562 |  0.857143 |                    3 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 09:59:12 (running for 00:01:13.26)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.347562 |  0.857143 |                    3 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 09:59:20 (running for 00:01:21.08)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.376135 |   0.87037 |                    4 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 09:59:25 (running for 00:01:26.09)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.376135 |   0.87037 |                    4 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 09:59:30 (running for 00:01:31.10)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.376135 |   0.87037 |                    4 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 09:59:38 (running for 00:01:38.92)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.299349 |  0.892857 |                    5 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 09:59:43 (running for 00:01:43.93)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.299349 |  0.892857 |                    5 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 09:59:48 (running for 00:01:48.95)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.299349 |  0.892857 |                    5 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 09:59:55 (running for 00:01:56.27)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.249804 |  0.906746 |                    6 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:00:00 (running for 00:02:01.28)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.249804 |  0.906746 |                    6 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:00:05 (running for 00:02:06.29)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.249804 |  0.906746 |                    6 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:00:12 (running for 00:02:13.33)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.271757 |  0.900132 |                    7 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:00:17 (running for 00:02:18.35)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.271757 |  0.900132 |                    7 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:00:22 (running for 00:02:23.35)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.271757 |  0.900132 |                    7 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:00:29 (running for 00:02:30.29)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.280938 |   0.89881 |                    8 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:00:34 (running for 00:02:35.30)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.280938 |   0.89881 |                    8 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:00:39 (running for 00:02:40.31)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.280938 |   0.89881 |                    8 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:00:46 (running for 00:02:47.06)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.244309 |  0.909392 |                    9 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:00:51 (running for 00:02:52.08)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.244309 |  0.909392 |                    9 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:00:56 (running for 00:02:57.09)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status   | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | RUNNING  | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.244309 |  0.909392 |                    9 |\n",
            "| train_model_b08dd_00001 | PENDING  |                  |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING  |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING  |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING  |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING  |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING  |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING  |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING  |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "+-------------------------+----------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_model pid=8246)\u001b[0m /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\u001b[2m\u001b[36m(train_model pid=8246)\u001b[0m   warnings.warn(\n",
            "\u001b[2m\u001b[36m(train_model pid=8246)\u001b[0m /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\u001b[2m\u001b[36m(train_model pid=8246)\u001b[0m   warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Status ==\n",
            "Current time: 2023-03-26 10:01:04 (running for 00:03:04.90)\n",
            "Memory usage on this node: 2.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.253129 |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:01:09 (running for 00:03:09.91)\n",
            "Memory usage on this node: 4.0/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.253129 |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:01:14 (running for 00:03:14.92)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.253129 |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=8246)\u001b[0m [1,   100] loss: 0.380\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:01:19 (running for 00:03:19.93)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.253129 |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:01:24 (running for 00:03:24.94)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.253129 |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:01:31 (running for 00:03:31.82)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |   0.188597 |  0.937169 |                    1 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.253129 |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=8246)\u001b[0m [2,   100] loss: 0.096\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:01:36 (running for 00:03:36.84)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |   0.188597 |  0.937169 |                    1 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.253129 |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:01:41 (running for 00:03:41.85)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.833994708994709 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |   0.188597 |  0.937169 |                    1 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.253129 |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:01:49 (running for 00:03:49.89)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |   0.142681 |  0.948413 |                    2 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.253129 |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=8246)\u001b[0m [3,   100] loss: 0.062\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:01:54 (running for 00:03:54.90)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |   0.142681 |  0.948413 |                    2 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.253129 |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:01:59 (running for 00:03:59.91)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |   0.142681 |  0.948413 |                    2 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.253129 |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:02:07 (running for 00:04:07.98)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |   0.103488 |  0.967593 |                    3 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.253129 |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=8246)\u001b[0m [4,   100] loss: 0.028\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:02:12 (running for 00:04:12.99)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |   0.103488 |  0.967593 |                    3 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.253129 |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:02:17 (running for 00:04:18.00)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.8703703703703703 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |   0.103488 |  0.967593 |                    3 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.253129 |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:02:25 (running for 00:04:26.35)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |   0.105411 |  0.965608 |                    4 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.253129 |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=8246)\u001b[0m [5,   100] loss: 0.026\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:02:30 (running for 00:04:31.36)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |   0.105411 |  0.965608 |                    4 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.253129 |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:02:35 (running for 00:04:36.37)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |   0.105411 |  0.965608 |                    4 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.253129 |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:02:44 (running for 00:04:45.27)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0854408 |  0.968915 |                    5 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=8246)\u001b[0m [6,   100] loss: 0.020\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:02:49 (running for 00:04:50.28)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0854408 |  0.968915 |                    5 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:02:54 (running for 00:04:55.29)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0854408 |  0.968915 |                    5 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:03:03 (running for 00:05:03.66)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |   0.11096  |  0.96627  |                    6 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.253129 |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=8246)\u001b[0m [7,   100] loss: 0.024\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:03:08 (running for 00:05:08.67)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |   0.11096  |  0.96627  |                    6 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.253129 |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:03:13 (running for 00:05:13.68)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |   0.11096  |  0.96627  |                    6 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.253129 |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:03:21 (running for 00:05:21.77)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0858736 |  0.975529 |                    7 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=8246)\u001b[0m [8,   100] loss: 0.015\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:03:26 (running for 00:05:26.78)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0858736 |  0.975529 |                    7 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:03:31 (running for 00:05:31.79)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.8988095238095238 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0858736 |  0.975529 |                    7 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:03:39 (running for 00:05:39.54)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0892656 |  0.966931 |                    8 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=8246)\u001b[0m [9,   100] loss: 0.016\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:03:44 (running for 00:05:44.55)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0892656 |  0.966931 |                    8 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:03:49 (running for 00:05:49.57)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0892656 |  0.966931 |                    8 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:03:56 (running for 00:05:57.04)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |   0.132179 |  0.960317 |                    9 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.253129 |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=8246)\u001b[0m [10,   100] loss: 0.019\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:04:01 (running for 00:06:02.05)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |   0.132179 |  0.960317 |                    9 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.253129 |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:04:06 (running for 00:06:07.06)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (8 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00001 | RUNNING    | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |   0.132179 |  0.960317 |                    9 |\n",
            "| train_model_b08dd_00002 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |   0.253129 |  0.906746 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_model pid=9148)\u001b[0m /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\u001b[2m\u001b[36m(train_model pid=9148)\u001b[0m   warnings.warn(\n",
            "\u001b[2m\u001b[36m(train_model pid=9148)\u001b[0m /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\u001b[2m\u001b[36m(train_model pid=9148)\u001b[0m   warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Status ==\n",
            "Current time: 2023-03-26 10:04:14 (running for 00:06:14.96)\n",
            "Memory usage on this node: 1.7/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00002 | RUNNING    | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:04:19 (running for 00:06:19.97)\n",
            "Memory usage on this node: 4.0/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00002 | RUNNING    | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=9148)\u001b[0m [1,   100] loss: 1.279\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:04:24 (running for 00:06:24.98)\n",
            "Memory usage on this node: 4.0/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00002 | RUNNING    | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=9148)\u001b[0m [1,   200] loss: 0.768\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:04:29 (running for 00:06:29.99)\n",
            "Memory usage on this node: 4.0/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00002 | RUNNING    | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=9148)\u001b[0m [1,   300] loss: 0.858\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:04:34 (running for 00:06:35.00)\n",
            "Memory usage on this node: 4.0/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00002 | RUNNING    | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:04:39 (running for 00:06:40.01)\n",
            "Memory usage on this node: 4.0/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (7 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00002 | RUNNING    | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00003 | PENDING    |                  |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_model pid=9334)\u001b[0m /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\u001b[2m\u001b[36m(train_model pid=9334)\u001b[0m   warnings.warn(\n",
            "\u001b[2m\u001b[36m(train_model pid=9334)\u001b[0m /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\u001b[2m\u001b[36m(train_model pid=9334)\u001b[0m   warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Status ==\n",
            "Current time: 2023-03-26 10:04:45 (running for 00:06:45.95)\n",
            "Memory usage on this node: 1.8/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:04:50 (running for 00:06:50.96)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:04:55 (running for 00:06:55.97)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=9334)\u001b[0m [1,   100] loss: 0.414\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:05:00 (running for 00:07:00.99)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:05:05 (running for 00:07:06.00)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:05:11 (running for 00:07:12.26)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.163725  |  0.939153 |                    1 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=9334)\u001b[0m [2,   100] loss: 0.100\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:05:16 (running for 00:07:17.27)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.163725  |  0.939153 |                    1 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:05:21 (running for 00:07:22.28)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.8912037037037037 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.163725  |  0.939153 |                    1 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:05:29 (running for 00:07:29.80)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.126652  |  0.956349 |                    2 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=9334)\u001b[0m [3,   100] loss: 0.060\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:05:34 (running for 00:07:34.81)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.126652  |  0.956349 |                    2 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:05:39 (running for 00:07:39.82)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.126652  |  0.956349 |                    2 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:05:47 (running for 00:07:47.93)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.123225  |  0.958995 |                    3 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=9334)\u001b[0m [4,   100] loss: 0.038\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:05:52 (running for 00:07:52.94)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.123225  |  0.958995 |                    3 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:05:57 (running for 00:07:57.95)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9179894179894179 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.123225  |  0.958995 |                    3 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:06:05 (running for 00:08:06.30)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.120717  |  0.96164  |                    4 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=9334)\u001b[0m [5,   100] loss: 0.024\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:06:10 (running for 00:08:11.31)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.120717  |  0.96164  |                    4 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:06:15 (running for 00:08:16.32)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.120717  |  0.96164  |                    4 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:06:22 (running for 00:08:23.05)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.100324  |  0.965608 |                    5 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=9334)\u001b[0m [6,   100] loss: 0.026\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:06:27 (running for 00:08:28.07)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.100324  |  0.965608 |                    5 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:06:32 (running for 00:08:33.07)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.100324  |  0.965608 |                    5 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:06:38 (running for 00:08:39.30)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.112727  |  0.964947 |                    6 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=9334)\u001b[0m [7,   100] loss: 0.013\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:06:43 (running for 00:08:44.31)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.112727  |  0.964947 |                    6 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:06:48 (running for 00:08:49.32)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.112727  |  0.964947 |                    6 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:06:55 (running for 00:08:56.04)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.111313  |  0.965608 |                    7 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=9334)\u001b[0m [8,   100] loss: 0.011\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:07:00 (running for 00:09:01.05)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.111313  |  0.965608 |                    7 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:07:05 (running for 00:09:06.06)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9328703703703705 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.111313  |  0.965608 |                    7 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:07:11 (running for 00:09:12.39)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.108189  |  0.965608 |                    8 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=9334)\u001b[0m [9,   100] loss: 0.009\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:07:16 (running for 00:09:17.40)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.108189  |  0.965608 |                    8 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:07:21 (running for 00:09:22.41)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.108189  |  0.965608 |                    8 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:07:28 (running for 00:09:28.59)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.163459  |  0.953042 |                    9 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=9334)\u001b[0m [10,   100] loss: 0.014\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:07:33 (running for 00:09:33.61)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.163459  |  0.953042 |                    9 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:07:38 (running for 00:09:38.63)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (6 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc              |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00003 | RUNNING    | 172.28.0.12:9334 |           32 | 0.0001 |         0.001  |  0.163459  |  0.953042 |                    9 |\n",
            "| train_model_b08dd_00004 | PENDING    |                  |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                  |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                  |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                  |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                  |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                  |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402 |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246 |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148 |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "+-------------------------+------------+------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_model pid=10179)\u001b[0m /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\u001b[2m\u001b[36m(train_model pid=10179)\u001b[0m   warnings.warn(\n",
            "\u001b[2m\u001b[36m(train_model pid=10179)\u001b[0m /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\u001b[2m\u001b[36m(train_model pid=10179)\u001b[0m   warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Status ==\n",
            "Current time: 2023-03-26 10:07:44 (running for 00:09:44.99)\n",
            "Memory usage on this node: 2.5/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:07:49 (running for 00:09:50.00)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:07:54 (running for 00:09:55.01)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:07:59 (running for 00:10:00.02)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:08:07 (running for 00:10:08.12)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.154631  |  0.947751 |                    1 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:08:12 (running for 00:10:13.13)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.154631  |  0.947751 |                    1 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:08:17 (running for 00:10:18.14)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.9484126984126984 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.154631  |  0.947751 |                    1 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:08:22 (running for 00:10:23.42)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.114863  |  0.953704 |                    2 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:08:27 (running for 00:10:28.43)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.114863  |  0.953704 |                    2 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:08:32 (running for 00:10:33.45)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.114863  |  0.953704 |                    2 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:08:38 (running for 00:10:38.72)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.0920556 |  0.968915 |                    3 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:08:43 (running for 00:10:43.72)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.0920556 |  0.968915 |                    3 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:08:48 (running for 00:10:48.73)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9616402116402116 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.0920556 |  0.968915 |                    3 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:08:53 (running for 00:10:54.12)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.134093  |  0.963624 |                    4 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:08:58 (running for 00:10:59.14)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.134093  |  0.963624 |                    4 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:09:03 (running for 00:11:04.16)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.134093  |  0.963624 |                    4 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:09:09 (running for 00:11:10.15)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.0714525 |  0.979497 |                    5 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:09:14 (running for 00:11:15.16)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.0714525 |  0.979497 |                    5 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:09:19 (running for 00:11:20.18)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.0714525 |  0.979497 |                    5 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:09:25 (running for 00:11:26.13)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.0894803 |  0.972884 |                    6 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:09:30 (running for 00:11:31.15)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.0894803 |  0.972884 |                    6 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:09:35 (running for 00:11:36.16)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.0894803 |  0.972884 |                    6 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:09:42 (running for 00:11:42.73)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.0866838 |  0.974868 |                    7 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:09:47 (running for 00:11:47.75)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.0866838 |  0.974868 |                    7 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:09:52 (running for 00:11:52.76)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.0866838 |  0.974868 |                    7 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:09:58 (running for 00:11:59.48)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.0776983 |  0.975529 |                    8 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:10:03 (running for 00:12:04.50)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.0776983 |  0.975529 |                    8 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:10:08 (running for 00:12:09.51)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.0776983 |  0.975529 |                    8 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:10:15 (running for 00:12:16.26)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.101957  |  0.969577 |                    9 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:10:20 (running for 00:12:21.27)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.101957  |  0.969577 |                    9 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:10:25 (running for 00:12:26.29)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (5 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00004 | RUNNING    | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.101957  |  0.969577 |                    9 |\n",
            "| train_model_b08dd_00005 | PENDING    |                   |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_model pid=10972)\u001b[0m /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\u001b[2m\u001b[36m(train_model pid=10972)\u001b[0m   warnings.warn(\n",
            "\u001b[2m\u001b[36m(train_model pid=10972)\u001b[0m /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\u001b[2m\u001b[36m(train_model pid=10972)\u001b[0m   warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Status ==\n",
            "Current time: 2023-03-26 10:10:33 (running for 00:12:34.03)\n",
            "Memory usage on this node: 1.7/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00005 | RUNNING    | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:10:38 (running for 00:12:39.05)\n",
            "Memory usage on this node: 4.0/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00005 | RUNNING    | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=10972)\u001b[0m [1,   100] loss: 1.287\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:10:43 (running for 00:12:44.06)\n",
            "Memory usage on this node: 4.0/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00005 | RUNNING    | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=10972)\u001b[0m [1,   200] loss: 0.806\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:10:48 (running for 00:12:49.07)\n",
            "Memory usage on this node: 4.0/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00005 | RUNNING    | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=10972)\u001b[0m [1,   300] loss: 0.689\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:10:53 (running for 00:12:54.09)\n",
            "Memory usage on this node: 4.0/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00005 | RUNNING    | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:10:58 (running for 00:12:59.10)\n",
            "Memory usage on this node: 4.0/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.9371693121693122\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (4 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00005 | RUNNING    | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |            |           |                      |\n",
            "| train_model_b08dd_00006 | PENDING    |                   |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_model pid=11157)\u001b[0m /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\u001b[2m\u001b[36m(train_model pid=11157)\u001b[0m   warnings.warn(\n",
            "\u001b[2m\u001b[36m(train_model pid=11157)\u001b[0m /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\u001b[2m\u001b[36m(train_model pid=11157)\u001b[0m   warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Status ==\n",
            "Current time: 2023-03-26 10:11:04 (running for 00:13:05.03)\n",
            "Memory usage on this node: 1.6/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00006 | RUNNING    | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:11:09 (running for 00:13:10.04)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00006 | RUNNING    | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:11:14 (running for 00:13:15.05)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00006 | RUNNING    | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=11157)\u001b[0m [1,   100] loss: 0.909\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:11:19 (running for 00:13:20.06)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00006 | RUNNING    | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:11:24 (running for 00:13:25.07)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.8743386243386244\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (3 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00006 | RUNNING    | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |            |           |                      |\n",
            "| train_model_b08dd_00007 | PENDING    |                   |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_model pid=11323)\u001b[0m /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\u001b[2m\u001b[36m(train_model pid=11323)\u001b[0m   warnings.warn(\n",
            "\u001b[2m\u001b[36m(train_model pid=11323)\u001b[0m /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\u001b[2m\u001b[36m(train_model pid=11323)\u001b[0m   warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Status ==\n",
            "Current time: 2023-03-26 10:11:31 (running for 00:13:32.04)\n",
            "Memory usage on this node: 2.5/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00007 | RUNNING    | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:11:36 (running for 00:13:37.06)\n",
            "Memory usage on this node: 4.0/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00007 | RUNNING    | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=11323)\u001b[0m [1,   100] loss: 1.390\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:11:41 (running for 00:13:42.07)\n",
            "Memory usage on this node: 4.0/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00007 | RUNNING    | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=11323)\u001b[0m [1,   200] loss: 0.807\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:11:46 (running for 00:13:47.08)\n",
            "Memory usage on this node: 4.0/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00007 | RUNNING    | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=11323)\u001b[0m [1,   300] loss: 0.776\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:11:51 (running for 00:13:52.09)\n",
            "Memory usage on this node: 4.0/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (2 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00007 | RUNNING    | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |            |           |                      |\n",
            "| train_model_b08dd_00008 | PENDING    |                   |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_model pid=11499)\u001b[0m /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\u001b[2m\u001b[36m(train_model pid=11499)\u001b[0m   warnings.warn(\n",
            "\u001b[2m\u001b[36m(train_model pid=11499)\u001b[0m /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\u001b[2m\u001b[36m(train_model pid=11499)\u001b[0m   warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Status ==\n",
            "Current time: 2023-03-26 10:12:01 (running for 00:14:02.04)\n",
            "Memory usage on this node: 2.7/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.8082010582010581\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00008 | RUNNING    | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:12:06 (running for 00:14:07.06)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.8082010582010581\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00008 | RUNNING    | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:12:11 (running for 00:14:12.07)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.8082010582010581\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00008 | RUNNING    | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=11499)\u001b[0m [1,   100] loss: 0.385\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:12:16 (running for 00:14:17.08)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.8082010582010581\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00008 | RUNNING    | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:12:21 (running for 00:14:22.09)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.8082010582010581\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00008 | RUNNING    | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:12:27 (running for 00:14:28.40)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00008 | RUNNING    | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.152832  |  0.944444 |                    1 |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=11499)\u001b[0m [2,   100] loss: 0.090\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:12:32 (running for 00:14:33.41)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00008 | RUNNING    | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.152832  |  0.944444 |                    1 |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:12:37 (running for 00:14:38.42)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00008 | RUNNING    | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.152832  |  0.944444 |                    1 |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:12:46 (running for 00:14:46.98)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00008 | RUNNING    | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.0994013 |  0.96627  |                    2 |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=11499)\u001b[0m [3,   100] loss: 0.053\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:12:51 (running for 00:14:51.99)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00008 | RUNNING    | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.0994013 |  0.96627  |                    2 |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:12:56 (running for 00:14:57.00)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00008 | RUNNING    | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.0994013 |  0.96627  |                    2 |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:13:04 (running for 00:15:05.36)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00008 | RUNNING    | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.0819294 |  0.969577 |                    3 |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=11499)\u001b[0m [4,   100] loss: 0.021\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:13:09 (running for 00:15:10.37)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00008 | RUNNING    | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.0819294 |  0.969577 |                    3 |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:13:14 (running for 00:15:15.38)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9626322751322751 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00008 | RUNNING    | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.0819294 |  0.969577 |                    3 |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:13:22 (running for 00:15:23.46)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9636243386243386 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00008 | RUNNING    | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.0825714 |  0.970899 |                    4 |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=11499)\u001b[0m [5,   100] loss: 0.024\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:13:27 (running for 00:15:28.47)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9636243386243386 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00008 | RUNNING    | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.0825714 |  0.970899 |                    4 |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:13:32 (running for 00:15:33.48)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9636243386243386 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00008 | RUNNING    | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.0825714 |  0.970899 |                    4 |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:13:42 (running for 00:15:42.85)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9636243386243386 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00008 | RUNNING    | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.0996469 |  0.964947 |                    5 |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=11499)\u001b[0m [6,   100] loss: 0.028\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:13:47 (running for 00:15:47.86)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9636243386243386 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00008 | RUNNING    | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.0996469 |  0.964947 |                    5 |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:13:52 (running for 00:15:52.88)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9636243386243386 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00008 | RUNNING    | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.0996469 |  0.964947 |                    5 |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:14:00 (running for 00:16:01.49)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9636243386243386 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00008 | RUNNING    | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.0854886 |  0.973545 |                    6 |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=11499)\u001b[0m [7,   100] loss: 0.031\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:14:05 (running for 00:16:06.51)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9636243386243386 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00008 | RUNNING    | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.0854886 |  0.973545 |                    6 |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:14:11 (running for 00:16:11.53)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9636243386243386 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00008 | RUNNING    | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.0854886 |  0.973545 |                    6 |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:14:19 (running for 00:16:20.03)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9636243386243386 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00008 | RUNNING    | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.105274  |  0.967593 |                    7 |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=11499)\u001b[0m [8,   100] loss: 0.013\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:14:24 (running for 00:16:25.04)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9636243386243386 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00008 | RUNNING    | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.105274  |  0.967593 |                    7 |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:14:29 (running for 00:16:30.06)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: 0.9662698412698413 | Iter 4.000: 0.9636243386243386 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 PENDING, 1 RUNNING, 8 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00008 | RUNNING    | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.105274  |  0.967593 |                    7 |\n",
            "| train_model_b08dd_00009 | PENDING    |                   |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_model pid=12252)\u001b[0m /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\u001b[2m\u001b[36m(train_model pid=12252)\u001b[0m   warnings.warn(\n",
            "\u001b[2m\u001b[36m(train_model pid=12252)\u001b[0m /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\u001b[2m\u001b[36m(train_model pid=12252)\u001b[0m   warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Status ==\n",
            "Current time: 2023-03-26 10:14:38 (running for 00:16:39.06)\n",
            "Memory usage on this node: 2.3/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9636243386243386 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00009 | RUNNING    | 172.28.0.12:12252 |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "| train_model_b08dd_00008 | TERMINATED | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.115943  |  0.960317 |                    8 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:14:43 (running for 00:16:44.08)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9636243386243386 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00009 | RUNNING    | 172.28.0.12:12252 |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "| train_model_b08dd_00008 | TERMINATED | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.115943  |  0.960317 |                    8 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=12252)\u001b[0m [1,   100] loss: 0.733\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:14:48 (running for 00:16:49.09)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9636243386243386 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00009 | RUNNING    | 172.28.0.12:12252 |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "| train_model_b08dd_00008 | TERMINATED | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.115943  |  0.960317 |                    8 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=12252)\u001b[0m [1,   200] loss: 0.402\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:14:53 (running for 00:16:54.10)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9636243386243386 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00009 | RUNNING    | 172.28.0.12:12252 |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "| train_model_b08dd_00008 | TERMINATED | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.115943  |  0.960317 |                    8 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=12252)\u001b[0m [1,   300] loss: 0.345\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:14:58 (running for 00:16:59.11)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9636243386243386 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00009 | RUNNING    | 172.28.0.12:12252 |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "| train_model_b08dd_00008 | TERMINATED | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.115943  |  0.960317 |                    8 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:15:03 (running for 00:17:04.12)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9636243386243386 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8115079365079365\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00009 | RUNNING    | 172.28.0.12:12252 |           16 | 0.001  |         0.1    |            |           |                      |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "| train_model_b08dd_00008 | TERMINATED | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.115943  |  0.960317 |                    8 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:15:09 (running for 00:17:09.93)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9636243386243386 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8578042328042328\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00009 | RUNNING    | 172.28.0.12:12252 |           16 | 0.001  |         0.1    |  0.277507  |  0.904101 |                    1 |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "| train_model_b08dd_00008 | TERMINATED | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.115943  |  0.960317 |                    8 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=12252)\u001b[0m [2,   100] loss: 0.269\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:15:14 (running for 00:17:14.95)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9636243386243386 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8578042328042328\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00009 | RUNNING    | 172.28.0.12:12252 |           16 | 0.001  |         0.1    |  0.277507  |  0.904101 |                    1 |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "| train_model_b08dd_00008 | TERMINATED | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.115943  |  0.960317 |                    8 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=12252)\u001b[0m [2,   200] loss: 0.332\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:15:19 (running for 00:17:19.95)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9636243386243386 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8578042328042328\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00009 | RUNNING    | 172.28.0.12:12252 |           16 | 0.001  |         0.1    |  0.277507  |  0.904101 |                    1 |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "| train_model_b08dd_00008 | TERMINATED | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.115943  |  0.960317 |                    8 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_model pid=12252)\u001b[0m [2,   300] loss: 0.311\n",
            "== Status ==\n",
            "Current time: 2023-03-26 10:15:24 (running for 00:17:24.97)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=9\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9636243386243386 | Iter 2.000: 0.9537037037037037 | Iter 1.000: 0.8578042328042328\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00009 | RUNNING    | 172.28.0.12:12252 |           16 | 0.001  |         0.1    |  0.277507  |  0.904101 |                    1 |\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "| train_model_b08dd_00008 | TERMINATED | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.115943  |  0.960317 |                    8 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-03-26 10:15:28,492\tINFO tune.py:798 -- Total run time: 1049.03 seconds (1048.98 seconds for the tuning loop).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Status ==\n",
            "Current time: 2023-03-26 10:15:28 (running for 00:17:28.99)\n",
            "Memory usage on this node: 4.1/12.7 GiB \n",
            "Using AsyncHyperBand: num_stopped=10\n",
            "Bracket: Iter 8.000: 0.9656084656084656 | Iter 4.000: 0.9636243386243386 | Iter 2.000: 0.951058201058201 | Iter 1.000: 0.8578042328042328\n",
            "Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.41 GiB heap, 0.0/3.7 GiB objects\n",
            "Result logdir: /root/ray_results/train_model_2023-03-26_09-57-59\n",
            "Number of trials: 10/10 (10 TERMINATED)\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "| Trial name              | status     | loc               |   batch_size |     lr |   weight_decay |   val_loss |   val_acc |   training_iteration |\n",
            "|-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------|\n",
            "| train_model_b08dd_00000 | TERMINATED | 172.28.0.12:7402  |           64 | 0.01   |         0.1    |  0.253129  |  0.906746 |                   10 |\n",
            "| train_model_b08dd_00001 | TERMINATED | 172.28.0.12:8246  |           32 | 0.0001 |         0.0001 |  0.0679228 |  0.979497 |                   10 |\n",
            "| train_model_b08dd_00002 | TERMINATED | 172.28.0.12:9148  |           16 | 0.01   |         0.001  |  0.722136  |  0.755952 |                    1 |\n",
            "| train_model_b08dd_00003 | TERMINATED | 172.28.0.12:9334  |           32 | 0.0001 |         0.001  |  0.175405  |  0.953704 |                   10 |\n",
            "| train_model_b08dd_00004 | TERMINATED | 172.28.0.12:10179 |           64 | 0.0001 |         0.001  |  0.100318  |  0.974868 |                   10 |\n",
            "| train_model_b08dd_00005 | TERMINATED | 172.28.0.12:10972 |           16 | 0.01   |         0.0001 |  0.571221  |  0.787037 |                    1 |\n",
            "| train_model_b08dd_00006 | TERMINATED | 172.28.0.12:11157 |           32 | 0.01   |         0.01   |  0.542324  |  0.804894 |                    1 |\n",
            "| train_model_b08dd_00007 | TERMINATED | 172.28.0.12:11323 |           16 | 0.01   |         0.001  |  0.613641  |  0.76918  |                    1 |\n",
            "| train_model_b08dd_00008 | TERMINATED | 172.28.0.12:11499 |           32 | 0.0001 |         0.1    |  0.115943  |  0.960317 |                    8 |\n",
            "| train_model_b08dd_00009 | TERMINATED | 172.28.0.12:12252 |           16 | 0.001  |         0.1    |  0.233204  |  0.919974 |                    2 |\n",
            "+-------------------------+------------+-------------------+--------------+--------+----------------+------------+-----------+----------------------+\n",
            "\n",
            "\n",
            "Best trial config: {'lr': 0.0001, 'weight_decay': 0.0001, 'batch_size': 32, 'num_epochs': 10}\n",
            "Best trial final validation loss: 0.0679228061566218\n",
            "Best trial final validation accuracy: 0.9794973544973545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MKLwvotSAcTx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}